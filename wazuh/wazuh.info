1514	Wazuh UDP
1515	Wazuh TCP
514	Wazuh UDP
55000	Wazuh API
5000	Logstash TCP input
9200	Elasticsearch HTTP
9300	Elasticsearch TCP transport
5601	Kibana

Integration 
Slack  -mini chat --good  - $
Pagerduty  -- msg routing to different sd team
VirusTotal -- check , if syscheck alerts comes


----- configuring syslog output
<server>IP</server>

/var/ossec/bin/ossec-control enable client-syslog
service wazuh-manager restart


------- Generating automatic reports
every day configure
<ossec_config>
  <reports>
      <category>syscheck</category>
      <title>Daily report: File changes</title>
      <email_to>example@test.com</email_to>
  </reports>
</ossec_config>

<ossec_config>
  <reports>
      <level>10</level>
      <title>Daily report: Alerts with level higher than 10</title>
      <email_to>example@test.com</email_to>
  </reports>
</ossec_config>

------ email notification
<ossec_config>
    <global>
        <email_notification>yes</email_notification>
        <email_to>me@test.com</email_to>
        <smtp_server>mail.test.com..</smtp_server>
        <email_from>wazuh@test.com</email_from>
    </global>
    ...
</ossec_config>

# apt-get install postfix mailutils libsasl2-2 ca-certificates libsasl2-modules
/etc/postfix/main.cf
relayhost = [smtp.gmail.com]:587
smtp_sasl_auth_enable = yes
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtp_sasl_security_options = noanonymous
smtp_tls_CAfile = /etc/ssl/certs/thawte_Primary_Root_CA.pem
smtp_use_tls = yes

# echo [smtp.gmail.com]:587 USERNAME@gmail.com:PASSWORD > /etc/postfix/sasl_passwd
# postmap /etc/postfix/sasl_passwd
# chmod 400 /etc/postfix/sasl_passwd

# chown root:root /etc/postfix/sasl_passwd /etc/postfix/sasl_passwd.db
# chmod 0600 /etc/postfix/sasl_passwd /etc/postfix/sasl_passwd.db

 systemctl reload postfix

 echo "Test mail from postfix" | mail -s "Test Postfix" -r "you@example.com" you@example.com

Configure Wazuh in the /var/ossec/etc/ossec.conf as follows:

<global>
  <email_notification>yes</email_notification>
  <smtp_server>localhost</smtp_server>
  <email_from>USERNAME@gmail.com</email_from>
  <email_to>you@example.com</email_to>
</global>


---------- agent installation and configure  - ------------
# /var/ossec/bin/agent-auth -m 192.168.1.2
vim /Library/Ossec/etc/ossec.conf
<server>10.245.0.46</server>

Otherwise, you can create a self-signed certificate:
openssl req -x509 -batch -nodes -days 365 -newkey rsa:2048 -keyout /var/ossec/etc/sslmanager.key -out /var/ossec/etc/sslmanager.cert

/var/ossec/bin/ossec-authd

agent:
/var/ossec/bin/agent-auth -m server_IP

If you want to add agents with a dynamic IP address (like using any on manage_agents) you must change etc/ossec.conf on the server-side:

(Manager)

<auth>
    <use_source_ip>no</use_source_ip>
</auth>

Launching the authd daemon with default options would allow any agent to register itself, and then connect to a manager. The following options provide some mechanisms to authorize connections:

Use a password to authorize agents  -----------
# echo "TopSecret" > /var/ossec/etc/authd.pass
  # /var/ossec/bin/ossec-authd -P

If you don’t specify a password, then authd will create a password itself and tell you what it is:

(Manager)

  # /var/ossec/bin/ossec-authd -P

(Agent)

# /var/ossec/bin/agent-auth -m 192.168.1.2 -P "abcd1234"

Use SSL to verify hosts
First we are going to create a certificate of authority (CA) that we will use to sign the certificates for the manager and agents. Hosts will receive a copy of this certificate in order to verify the remote certificate:

# openssl req -x509 -new -nodes -newkey rsa:2048 -keyout rootCA.key -out rootCA.pem -batch -subj "/C=US/ST=CA/O=Manager"

Verify manager via SSL
Issue and sign a certificate for the authd server, entering the hostname or the IP address that agents will use to connect to the server. For example, if the server’s IP is 192.168.1.2:

# openssl req -new -nodes -newkey rsa:2048 -keyout sslmanager.key -out sslmanager.csr -subj '/C=US/CN=192.168.1.2'
# openssl x509 -req -days 365 -in sslmanager.csr -CA rootCA.pem -CAkey rootCA.key -out sslmanager.cert -CAcreateserial

Copy the newly created certificate and the key to the manager’s etc folder and start ossec-authd:

(Manager)

# cp sslmanager.cert sslmanager.key /var/ossec/etc
# /var/ossec/bin/ossec-authd
Copy the CA (but not the key) to the agent’s etc folder and run agent-auth:

(Agent)

# cp rootCA.pem /var/ossec/etc
# /var/ossec/bin/agent-auth -m 192.168.1.2 -v /var/ossec/etc/rootCA.pem

Verify agents via SSL (no host validation)

In this example, we are going to create a certificate for agents without specifying their hostname, so that the same certificate can be used by many agents. This verifies that agents have a certificate signed by our CA, no matter where they are connecting from.

Issue and sign a certificate for the agent. Note that we will not enter the common name field:
# openssl req -new -nodes -newkey rsa:2048 -keyout sslagent.key -out sslagent.csr -batch
# openssl x509 -req -days 365 -in sslagent.csr -CA rootCA.pem -CAkey rootCA.key -out sslagent.cert -CAcreateserial

Copy the CA (but not the key) to the manager’s etc folder (if not already there) and start ossec-authd:
(Manager)

# cp rootCA.pem /var/ossec/etc
# /var/ossec/bin/ossec-authd -v /var/ossec/etc/rootCA.pem
Copy the newly created certificate and key to the agent’s etc folder and run agent-auth. For example, if the server’s IP is 192.168.1.2:
(Agent)

# cp sslagent.cert sslagent.key /var/ossec/etc
# /var/ossec/bin/agent-auth -m 192.168.1.2 -x /var/ossec/etc/sslagent.cert -k /var/ossec/etc/sslagent.key

Verify agents via SSL (host validation)

This is an alternative method to the last section. In this case, we will bind the agent’s certificate to the agent IP address as seen by the manager.

Issue and sign a certificate for the agent. Then enter its hostname or IP address into the common name field. For example, if the agent’s IP is 192.168.1.3:
# openssl req -new -nodes -newkey rsa:2048 -keyout sslagent.key -out sslagent.csr -subj '/C=US/CN=192.168.1.3'
# openssl x509 -req -days 365 -in sslagent.csr -CA rootCA.pem -CAkey rootCA.key -out sslagent.cert -CAcreateserial

(Manager)

# cp rootCA.pem /var/ossec/etc
# /var/ossec/bin/ossec-authd -v /var/ossec/etc/rootCA.pem -s
Copy the newly created certificate and key to the agent’s etc folder and run agent-auth. For example, if the server’s IP is 192.168.1.2:
(Agent)

# cp sslagent.cert sslagent.key /var/ossec/etc
# /var/ossec/bin/agent-auth -m 192.168.1.2 -x /var/ossec/etc/sslagent.cert -k /var/ossec/etc/sslagent.key

---------------  Register Agent useng command line ----------------
On the manager, run manage_agents:
# /var/ossec/bin/manage_agents
Now on the agent run manage_agents:
# /var/ossec/bin/manage_agents
Select I to import a key and paste in the key that you extracted on the manager:

Choose your action: I or Q: I
service wazuh-agent restart

in case of reinstalling Manager Server
/var/ossec/bin/manage_agents -n Server1 -a 10.10.10.10 -F 0

----------  Listing Agents ----------

The binary /var/ossec/bin/agent_control allows for the retrieval of a list of the available agents:

# /var/ossec/bin/agent_control -l

----------  Remove agent -----------
/var/ossec/bin/manage_agents
R
001

or 
with no confirmation
/var/ossec/bin/mamage_agents -r 001

--------  RestFull API 
# curl -u foo:bar -X POST -d 'name=NewAgent&ip=10.0.0.8' "http://localhost:55000/agents"
{"error":0,"data":"001"}
Step 2: Get the agent key.

# curl -u foo:bar -X GET "http://localhost:55000/agents/001/key"
{"error":0,"data":"MDAxIE5ld0FnZW50IDEwLjAuMC44IDM0MGQ1NjNkODQyNjcxMWIyYzUzZTE1MGIzYjEyYWVlMTU1ODgxMzVhNDE3MWQ1Y2IzZDY4M2Y0YjA0ZWVjYzM="}

Step 3: Copy the key to the agent.

# /var/ossec/bin/manage_agents -i MDAxIE5ld0FnZW50IDEwLjAuMC44IDM0MGQ1NjNkODQyNjcxMWIyYzUzZTE1MGIzYjEyYWVlMTU1ODgxMzVhNDE3MWQ1Y2IzZDY4M2Y0YjA0ZWVjYzM=

service wazuh-agent restart 

-------- Listing agents
# curl -u foo:bar "http://localhost:55000/agents?pretty"
/var/ossec/bin/agent_control -l

-------- Remove agent
# curl -u foo:bar -X DELETE "http://localhost:55000/agents/002"
/manage_agents
R

-----		grouping agents		--------------
serving agent's configs
/var/ossec/etc/shared/default/

once an agent has benn added to the manager ,assign it to a group using 
/var/ossec/bin/agent_groups -a -i 002 -g dbms  # for example

Using the API:
curl -u foo:bar -X PUT "http://localhost:55000/agents/002/group/dbms?pretty"
The group must be created before.

To check use
/var/ossec/bin/agent_groups -l -g dbms
or
curl -u foo:bar -X GET "http://localhost:55000/agents/groups/dbms?pretty"

After creating group, its agent.conf file can be edited to include the specific configuration you want assign to this group.
/var/ossec/etc/shared/dbms/agent.conf each agent which belong to this group will receive this file

Multiple groups

New in version 3.7.0.

Since Wazuh v3.7.0, agents have the ability to belong to multiple groups. The agents will receive all the configuration files from each group. Configuration received from the last assigned group has more priority than the other ones.

With the agent_groups CLI, agents can be registered to groups on the same way:

$ /var/ossec/bin/agent_groups -a -i 001 -g webserver
$ /var/ossec/bin/agent_groups -a -i 001 -g apache
Do you want to add the group 'apache' to the agent '001'? [y/N]: y

# /var/ossec/bin/agent-auth -m MANAGER_IP -G webserver,apache  

------	Listing groups and configuration	------------
/var/ossec/bin/agent_groups -l -g webserver

which groups assigned to agent
/varossec/bin/agent_groups -s -i 001

-----  Making changes ---------
/var/ossec/bin/agent_groups -r -i 001 -g apache -q
/var/ossec/bin/agent_groups -s -i 001   # list groups

--------  synchronization status of the group configuration for a single agent:
/bin/agent_groups -S -i 001
curl -u foo:bar -X GET "http://localhost:55000/agents/001/group/is_sync?pretty"

======  Agent updating  ========
agent_upgrade -l
agent_upgrade -a 002

agent_control -i 002

Using the RESTful API
curl -u foo:bar -X GET "http://localhost:55000/agents/outdated?pretty"

curl -u foo:bar -X PUT "http://localhost:55000/agents/002/upgrade?pretty"

Check the upgrade result:
curl -u foo:bar -X GET "http://localhost:55000/agents/002/upgrade_result?pretty"

curl -u foo:bar -X GET "http://localhost:55000/agents/002?pretty"

=========  Adding a custom repository  ==========

=========	LOG COLLECTION		=========
---- Log files
<localfile>
	<location>/var/log/example.log</location>
	<log_format>syslog</log_format>
</localfile>

Windows:
<localfile>
	<location>C:\mysqpp\example.log</location>
	<log_format>syslog</log_format>
</localfile>
Windows event logs
Event log:
<localfile>
	<location>Security</location>
	<log_format>eventlog</log_format>
</localfile>
Event channel:
<localfile>
	<location>Microsoft-Windows-PrintService/Operational</location>
	<log_format>eventchannel</log_format>
</localfile>

Remote syslog
<ossec_config>
	<remote>
		<connection>syslog</connection>
		<allowed-ips>192.168.2.0/24</allowed-ips>
	</remote>
<ossec_config>

==========	ANALYSIS	==============
1) Pre-decoding
Phase of analysis ,static info from well-known fields

2) Decoding
Here log message is evaluated to identify what type of log it is and known fields for that specific log type are then extrated.

prg name
dstuser
srcip

3) Rule matching
extrcted log information is compared to the ruleset to look for matches
ex:

<rule id="5715" level="3">
	<if_sid>5700</if_sid>
	<match>^Accepted|authenticated.$</match>
	<description>sshd: authentication success.</description>
	<group>authentication_success.pci_dss_10.2.5.</group>
</rule>

=======		ALERT		==========
Once a rule is matched, the manager will create an alert as below:

To store all events even if they do not match a rule, enable the <log_all> option.
Alerts will be stored at /var/ossec/logs/alerts/alerts.(json|log) and events at /var/ossec/logs/archives/archives.(json|log). Logs are rotated and an individual directory is created for each month and year.

Archived logs are not automatically deleted by default. You can choose when to manually or automatically (e.g., cron job) delete logs according to your own legal and regulatory requirements.

=======		CONFIGURATION		==========
Basic usage
Log data collection is configured in the ossec.conf file primarily in the localfile, remote and gloval sections.
Configuration of log data collecion can also be completed in the agent.conf file to centralize the distribution of these configuration settings to relevant agents.

ex:

<localfile>
	<location>/var/log/messages</location>
	<log_format>syslog</log_format>
</localfile>

---------	Monitoring logs using regular expressions for file names

posix regular expressions.

<localfile>
	<location>/var/log/*.log</location>
	<log_format>syslog</log_format>
</localfile>

---------	Monitoring date-based logs
For log files that change according to the date , you can also specify a strftime format to replace the day,month, year,etc.
For example, to monitor the log files like log-08-12-15.log, 
<localfile>
	<location>c:\log-%y-%m-%d.log</location>
	log_format>syslog</log_format>
</localfile>

-----------	Reading events from Windows Event Channel
The location is the name of the event channel.
This is the only way to monitor the Applications and Services logs. If the file name contains a%, replace it with "/":
<localfile>
	<location>Microsoft-PrintService/Operational</location>
	<log_format>eventchannel<\log_format>
</localfile>


-----------	Filtering events from Windows Event Channel with queries
<localfile>
	<location>System</location>
	<log_formaat>eventchannel</log_format>
	<query>Event/System[EventID=7040]</query>
</localfile>

---------	Using environment variables
Ex reading logs from an IIS server:
<localfile>
	<location>%Windir%\System32\LogFiles\W3SVC3\ex%y$m$d.log</location>
	log_format>iis</log_format>
</localfile>

--------	Using multiple outputs
Log data is sent to the agent socket by default, but it is also possible to specify other sockets as output.ossec-logcollector uses UNIX type sockets to communicate allowing TCP or UDP protocols. To add a new output socket we need to specify it using the tag <socket> as shown in the following example configuration:

<socket>
	<name>custom_socket</name>
	<location>/var/run/custom.sock</location>
	<mode>tcp</mode>
	<prefix>custom_syslog: </prefix>
</socket>

<socket>
	<name>test_socket</name>
	<location>/var/run/test.sock</location>
</socket>

Once the socket is defined, it’s possible to add the destination socket for each localfile:

<localfile>
    <log_format>syslog</log_format>
    <location>/var/log/messages</location>
    <target>agent,test_socket</target>
</localfile>

<localfile>
    <log_format>syslog</log_format>
    <location>/var/log/messages</location>
    <target>custom_socket,test_socket</target>
</localfile>


============  FIM	========
10 optins are configuranle:
Frequency: def 12 haurs
Real-time monitoring:  support Windows or Linux. Only for dirs not for individual files.
Whodata:  in addition provides information about who triggered the event.

An alert is generated any time that modifications ae detected in the monitored files and/or registry keys.
False positives can be addressed using the ignore configuration option or by creating rules that list files to be excluded from FIM alerts.

------------	Configuration		----------
Syscheck is configured in the ossec.conf file.
frequency
directories
ignore
alert_new_files

The check_all option checks file size, permissions, owner, last modification date, inode and all the hash sums (MD5, SHA1 and SHA256).

<The directories pushed from cetralized configuration are overwritten in the ossec.conf file if the directory path is the same.

<syscheck>
	<directories check_all="yes">/etc./usr/bin./usr/sbin</directories>
	<directories check_all="yes">/root/users.txt./bsd,/root/db.html</directories>
</syscheck>

---------	Configuring scheduled  scans
<syscheck>
	<frequency>36000</frequency>
	<directories>/etc,/usr/bin,/usr/sbin</directories>
	<directories>/bin,/sbin</directories>
</syscheck>


---------	Configuring realtime monitoring
Works with directories only rather then with individual files.Real-time change detection is paused during periodic syscheck scans and ractivates as soon as these scans are complete

<syscheck>
	<ditectories check_all="yes" realtim=="yes">c:/tmp</directories>

---------	Configuring who-data monitoring
whodata option
This option replaces the realtime option , which means that whodata implies real-time monitoring but adding the who-data information. This functionality uses Linux Audit subsystem and the Microsoft Windows SACL,so additional configurations might be necessary. Check the Auditing who-data entry to get further information

<syscheck>
	<directories check_all="yes" whodata="yes">/etc</directories>
</syscheck>



----------	Configure to report changes
Using the report_changes option , we can see what specifically changed in text files. Be carefull about which folders you set up to report_changes to , because in order to do this, Wazuh copies every single file you want to monitor to a private location.

---------	Configure to ignore files 
<syscheck>
	<ignore>/etc/random-seed</ignore>
	<ignore>/root/dir</ignore>
	<ignore type="sregex">.log$|.tmp</ignore>
</syscheck>

--------	Configure maximum recursioon level allowed
recursion_level option.
<syscheck>
	<directories check_all="yes">/etc,/usr/bin,/usr/sbin</directories>
	<directories check_all="yes">/root/users.txt,/bsd,/root/db.html</directories>
	<directories check_all="yes" recursion_level="3">folder_test</directories>


We will receive alerts for all files up to folder_test/l1/l2/l3 but we won't receive alerts from any directory deeper then l3

if recursion_level is not specified, it will be set to the default value defined by syscheck.default_max_depth in the internal options configuration file.

----------	Ignoring files via reles
<rule id="100345" level="0">
	<if_group>syscheck</if_group>
	<match>/var/www/htdocs</match>
	<description>Ignore changes too /var/www/htdocs</description>
</rule>

------	Changing severity
With a custom rule, the level of a syscheck alert can be altered when changes to a specific file or file pattern are detected.
<rule id="100345" level="12">
	<if_group>syscheck</if_group>
	<match>/var/www/htdocs</match>
	<description>Changes to /var/www/htdocs - Critical file!</description>
</rule>

-------  FIM ignoring files , to avoid false positives.
<ignore> 	option

Report changes in the content of a text file
It is possible whrn monitoring directories . Using the 
<report_changes> option gives the exact content that has been changed in text files within the directory being monitored. syscheck copy every single file you want to monitor with <report_changes>

-------		force an immediate syscheck scan
/var/ossec/bin/agent_control -r -a
/var/ossec/bin/agent_control -r -u <agent_id>

By default, syscheck scans when Wazuh starts, however, this behavior can be changed with the scan_on_start option

-------
alert_new_files option

==========	Auditing who-data	==============
This information contains the user who made the changes on the monitored files and also the program name or process used to carry them out.

----------		Linux systems
uses the Linux Audit subsystem to get the information about who made the changes in a monitored directory. These changes produce audit events that are processed by syscheck and reported to the manager.

apt install auditd
ossec.conf
<syscheck>
	<directories check_all="yes" whodata="yes">/etc</directories>
</syscheck>

service wazuh restart

check if the Audit rule for monitoring the selected folder is applied.
auditctl -l | grep wazuh_fim
-w /etc -p wa -k wazuh_fim  	#checks if the rule was added

when the agent is stopped , we can use the same command to check that the added rule was successfully removed.

=========	Anomaly and malware detection		===========
rootcheck
uses syscheck to detect anomalies.
Checks:
- Check running processes
- Check hidden ports
Rootcheck checks every port in the system using bind(). If it can not bind to a port and that port is not in the netstat output, malware may be present.
- Check unusual files and permissions
	scans entire FS looking for unusual files and permissions.owned by root with write permissions, or suid bit on.
- Check hidden files using system calls
comparing the differences between te stat size and the file size when using the fopen + read calls. The number of nodes in each directory is also compared with the output of opendir + readdir. If any results do not match, malware may be present.

- Scan the /dev directory
should only contain device-specific files. Any other should be inspected because malware uses thes partition to hide files.

- Scan network interfaces
if promiscuous mode enabled.

- Rootkit checks.
own database of rootkit signaturees: rootkit_files.txt,rootkit_trojans.txt and win_malware_rcl.txt.Unfortunately,these signatures are out of date.

-------------		Configuration
ossec.conf
<rootcheck>
	<rootkit_files>/var/ossec/etc/shared/rootkit_files.txt</rootkit_files>
	<rootkit_trojans>/var/ossec/etc/shared/rootkit_trojans.txt</rootkit_trojans>
</rootcheck>

Ignoring false positives
<rule id+"100100" level="0">
	<if_group>rootcheck</if_group>
	<match>/dev/.blkid.tab</match>
	<description>Ignore false positive for /dev/.blkid.tab</description>
</rule>


------------		By default rootcheck runs every 2 hours.
-------rootcheck inspects all running processes looking for discrepanies with different system calls.

=============		Monitoring security policies
Policy monitoring is the process of verifying that all systems conform to a set of predefined rules regarding configuration settings and approved application usage.

Wazuh uses three components to perform this task: Rootcheck , OpenSCAP and CIS-CAT.

1 Rootcheck
conf files - compliant with your sec policies, standards or hardening guides.
Agents perform periodic scans to detect applications that are known to be vulnerable, unpatched, misconfigured.

The rootcheck engine  can perform the following checks:
- check if a process is running
- check if a file is present
- check if the content of a file contains a pattern , or if a Windows registry key contains a string or is simply present.

following policies have been developed:
system_audit_rcl.txt - Web vulnerabilities and exploits
system_audit_ssh.txt	SSH Hardening
cis_debian_linux_rcl.txt	Based on CIS Benchmark for Debian Linux v1.0

Alerts related to policy monitoring:
512: win audit
514: win app
516: unix app

The policy and compliance monitoring databases are normally maintained on the manager , which distributes them to all the agents.

ex:
$sshd_file=/etc/ssh/sshd_config;

[SSH Configuration - 1:Root can log in] [any] [1]
f:$sshd_file -> !r:^# && r:PermitRootLogin\.+yes;
f:$sshd_file -> r:^#\s*PermitRootLogin;

-------		Basic usage
go to Rootcheck section
<rootcheck>
	<system_audit>./db/system_audit_rcl.txt</system_audit>
	<system_audit>./db/cis_debian_linux_rcl.txt</system_audit>
	<system_audit>./db/cis_rhel_linux_rcl.txt</system_audit>
</rootcheck>

-------		Configure periodic scans
<rootcheck>
	<frequency>36000</frequency>
	<system_audit>/var/ossec/etc/share/system_audit_rcl.txt</system_audit>
	<system_audit>/var/ossec/etc/shared/cis_debian_linux_rcl.txt</system_audit>
	<system_audit>/var/ossec/etc/shared/cis_rhel_linux_rcl.txt</system_audit>
	<system_audit>/var/ossec/etc/shared/cis_rhel5_linux_rcl.txt</system_audit>
</rootcheck>


-------		Root access to SSH
create your custom audit file (audit_test.txt):
# PermitRootLogin not allowed
# PermitRootLogin indicates if the root user can log in by ssh.
$sshd_file=/etc/ssh/sshd_config;

[SSH Configuration - 1: Root can log in] [any] [1]
f:$sshd_file -> !r:^# && r:PermitRootLogin\.+yes;
f:$sshd_file -> r:^#\s*PermitRootLogin;

ossec.conf
<rootcheck>
	<system_audit>/var/ossec/etc/shared/audit_test.txt</system_audit>
</rootcheck>

=================		OpenSCAP		===================
is an integration of OpenSCAP with Wazuh HIDS that provides the ability to perform configuration and vulnerability scans of an agent. It is primarily used for:
- Verifying security compliance: OpenSCAP policies define the requirements that all systems in an organization must meet in order to be in line with applicable security policies and/or security benchmarks.
- Performing vulnerability assessments: identifies and classifies vulnerabilities in a system
- Performing specialized assessments: OpenSCAP can perform specific custom system checks 

Security Content Automation Protocol (SCAP)
- specification for expressing and manipulating security data in standardized ways. Uses seceral specifications in order to automate continuous monitoring, vulnerability management , and reporting the results of security compliance scans.

Componnents of the security compliance evaluation process:
- SCAP scanner: This is an application that reads a SCAP policy and checks whether or not the system is compliant with it. There are many tools to scan your systems against SCAP policies. This wodle is an integration with the NIST-certified scanner called OpenSCAP.
- Security policies (SCAP content): This determine how a system must be set up and what to check for. These policies contain machine-readable descriptions of the rules which your system will be required to follow.
- Profiles: Each security policy can contain multiple profiles, which provide sets of rules and values in line with a specific security baseline. You can think of a profile as a particular subset of rules within the policy; the profile determines which rules defined in the policy will be actually used and what values will be used during the evaluation.
- Evaluation (scan): This is the process performed by the OpenSCAP scanner on an agent according ro a speccific security policy and profile . It usually takes only a few minutes, depending on the number of rules selected in the profile.

-----------		Requirements
rpm-based:
yum install openscap-scanner
debian:
apt-get install libopenscap8 xsltproc

default policies
CentOS
RedHat
Debian
Ubuntu (xenial;trusty;precise)
Fedora (24)

Manager and it will generate an alert if the status of the result is fail. It is possible to tuning the rules to send the pass result too.

-----------		Configuration
-----------		Basic usage
<wodle name="open-acap">
	<disabled>no</disabled>
	<timeout>1800</timeout>
	<interval>1d</interval>
	<scan-on-start>yes</scan-on-start>
	<content type="xccdf" path="ssg-centos-7-ds.xml">
		<profile>xccdf_org.ssgproject.content_profile_pci-dss</profile>
		<profile>xccdf_org.ssgproject.content_profile_common</profile>
	</content>
</wodle>

Evaluate PCI-DSS compliance on RHEL7
Payment Card Industry Data Security Standard (PCI-DSS) compliance on Red Hat Enterprise Linux 7 agents.
---------	Configuring agent ossec.conf:
<client>
	<server>
		<address>10.0.1.4</address>
		<port>1514</port>
		<protocol>tcp</protocol>
	</server>
	<config-profile>redhat7</config-profile>
</client>

--------	Configure manager
We want to execute the PCI-DSS profile of the SSGRH7 policy only on Red Hat 7 servers.
Manager /var/ossec/etc/shared/default/agent.conf  ( assuming that the agent is on the default group):
<agent_config profile="redhat7">
	<wodle name="open-scap">
		<content type="xccdf"" path="ssg-rhel7-ds.xml">
			<profile>xccdf_org.ssgproject.content_profile_pci-dss</profile>
		</content>
	</wodle>
</agent_config>


----------		Restart manager and agents
service wazuh-manager restart
/var/ossec/bin/agent_control -R -a

-u <id> - specific agent.

---------	See alerts
/var/ossec/logs/alerts/alerts.log

----------	Dashboards
Finally, you can explore all results using the OpenSCAP dashboards for Kibana.

----------	Auditing Security Vulnerabilities of Red Hat Products
RH Security Response Team probbifes OVAL definitions for all vulnerabilities (identified by CVE name) that affect RHEL 4-7. This enables users to perform a vulnerability scan and diagnose whether a system is vulnerable or not.

---------	Step 1. Configure agents.
ossec.conf:
<client>
	<server-ip>10.0.1.4</server-ip>
	<conffig-profile>redhat7</config-profile>
</client>

Step 2: Configure manager
shared/agent.conf:
<agent_config profile="redhat7">
	<wodle name="open-scap">
		<content type="xccdf" path="com.redhat.rhsa-RHEL7.ds.xml"/>
	</wodle>
</agent_config>

-------		Step 3: Restart manager and agents
service wazuh-manager restart
/var/ossec/bin/agent_control -R -a  (-u <id>)

-------		Step 4: See alerts
/var/ossec/logs/alerts/alerts.log

-- Kibana
See dashboard

------	Overwriting the timeout
<wodle name="open-scap">
	<timeout>1800</timeout>
	<content type="xccdf" path="ssg-centos7-ds.xml">
		<timeout>120</timeout>
	</content>
	<content type="xccdf" path="ssg-centos-6-ds.xml"/>
</wodle>

-------		Using profiles

<wodle name="open-scap">
	<content type="xccdf" path="ssg-centos-7-ds.xml">
		<profile>xccdf_org.ssgproject.content_profile_standard</profile>
		<profile>xccdf_org.ssgproject.content_profile_pci-dss</profile>
	</content>
	<content type="xccdf" path="ssg-centos-6-ds.xml/>
</wodle>


-----		Using CPE dictionary
<wodle name="open-scap">
	<content type="xccdf" path=policy="ssg-centos-7-ds.xml">
		<cpe>file.xml</cpe>
	</content>
	<content type="xccdf" path="ssg-centos-6-ds.xml" />
</wodle>

-----		Using IDs
You can select a specific ID of the datastream fiile:

<wodle name="open-scap">
	<content typ="xccdf" path="ssg-centos-7-ds.xml">
		<datastream-id>id</datastream-id>
	</content>
	<content typ="xccdf" path="ssg-centos-6-ds.xml" />
</wodle>

------
by default, policies are evaluated when the wodle starts.

-----
Each agent must have its policies in /var/ossec/wodles/oscap/content


=============	CIS-CAT integration
-----	Center for internet security - is an entity dedicated to safeguard private and public organizations against cyber threats.
This entity provides CIS benchmarks gurdelines, which are a recognized global standard and best practices for securing IT systems and data against cyberattacks.

In addition , CIS-CAT Pro is a "cross-platform Java app" tool developed for scanning target systems and generating a report compring the system settings to the CIS benchmarks. There are more than 80 CIS benchmarks that cover nearly all ASs , providing different profiles depending on the specific need.

This integration requires CIS-CAT Pro , which is proprietary software You can learn more about this tool and how to download it at the official cis WEBSITE.

-------		How it works.
The CIS-CAT Wazuh module integrates CIS benchmark assessments into Wazuh agents and reports the results of each scan in the form of an alert.

written in Java, so it requires a Java Runtime Environment in order to execute it. Currently, the JRE versions supported in CIS-CAT are JRE 6,7,8. Follow these steps to install the OpenJDK platform:
apt update && apt install openjdk-8-jre

-------		CIS-CAT must be reside on the local agent that runs the scans.JRE can be located on a removable disk or network drive for the purpose of sharing between multiple agents.

unix:
chmod +x CIS-CAT.sh

Once you have the requirements for running CIS evaluations, you can configure the wodle to check for specific benchmarks at a your chosen interval. The scan results from these checks are sent to the manager and can be included in the visualizations.

-------		Use case: Running a CIS evaluation
ossec.conf 
<wodle name="cis-cat">
 <disabled>no</disabled>
  <timeout>1800</timeout>
  <interval>1d</interval>
  <scan-on-start>yes</scan-on-start>

  <java_path>/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/bin</java_path>
  <ciscat_path>wodles/ciscat</ciscat_path>

  <content type="xccdf" path="benchmarks/CIS_Ubuntu_Linux_16.04_LTS_Benchmark_v1.0.0-xccdf.xml">
    <profile>xccdf_org.cisecurity.benchmarks_profile_Level_2_-_Server</profile>
  </content>

</wodle>

============		Monitoring system calls
------ Linux Audit system provides a way to track security-relevant information on your machine.Based on preconfigured rules, Audit proves detailed real-time logging about the events that are happening on your system. This information is crucial for mission-critical environments to determine the violator of the security policy and the actions they performed.

------		How it works
Audit uses a set of rules to define what is to be captured in the log files. There are three types of Audit rules that can be specified:
- Control rules allow the Audit system's  behavior and some of its configuration to be modified
- File system rules, also known as file watches, allow the auditing of access to a particular file or a directory.
- System call rules allow logging of system calls that specified programs makes.

Audit rules can be specified interactively with the auditctl command-line utility, but to make changes persistent, edit /etc/audit/audit.rules
------		Control rules
auditctl -b Set the maximum amount of existing Audit buffers in the kernel.
auditctl -e Enable/disable the Audit system or lock its configuration.
auditctl -s Report the status of the Audit system.
auditctl -l List all currently loaded Audit reles.
auditctl -D Delete all currently loaded Audit rules.

-----		File System Rules
To define a file system rule, use the following systax:
-w <path> -p <permissions> -k <key_name>
-w <path> Specify what file or dir to audit with <path>
-p <perm> are the perm that are to auditing, including the following:
	r - read access to a file or dir
	w - write access to afile or a dir
	x - execute access --||---
	a - change in the file's or dir's attr
-k <key_name> is an optional string to identify which rule/set of rules generates a particular log line.
This argument is required by Wazuh in order to analyze the logs more accurately.

ex:
defining a rule that logs all write access to , and every attr change of , the /etc/passwd file, exec:
auditctl -w etc/passwd -p wa -k passwd_changes

---------		System Call Rules
-a action, filter -S system_call -F field=value -k key_name
where:
Tells the kernel's rule matching engine to append a rule at the end of the rule list.
We must specify which rule list to append it to and what action to take when it triggers.
-a <action>,<filter>
	<action>	always 		- read access to a file or a dir.
			never		- write access to a file or a dir.
	The <filter> value specifies which kernel rule-matching filter is  applied to the enevt
			task 		- Only audit events fork or clone syscalls.
					- This is rarely used in practice.
			exit		- All syscall and file system audit requests are evaluated.
			user		- This is used to remove some events that originate in user space.
			exclude		- This is used to exclude certain events from being logged.
					- msgtype is used to tell the kernell which message to filter out.
					- For more granular control over which events to audit:
					  use the user and exit filters instead.
-S <system_call>		This specifies which system_call to audit . Multiple system calls can be specified in a single rule.
				A list of all system calls can be found with the connand :
				ausyscall --dump

-F <field=value>	Use field=value to specify additional criteria to narrow down which events to audit, based on:
			architecture, group ID, process ID, etc...,
			Multiple -F options can be used in a single rule.

-k <key_name> 		<key_name> is an optional string to identify which rule/set of rules generates a particular log line.
			This argument is required by Wazuh in order to analyze the logs more accurately.

Ex:
For example, to define a rule that creates a log entry every time a file is deleted or renamed by a system user whose ID is 500 or larger, use the following. Note thatt the -F auid!=4294967295 option is used to exclude users whose login UID is not set.

auditctl -a always,exit -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete

It is also possible to define a file system rule using the system call rule systax.
analg to the 	-w /etc/shadow -p wa 

auditctl -a always,exit -F path=/etc/shadow -F perm=wa

-----------		Confifuration
-----		Basic

Manager 
We will use a CDB list to determine the types of audit rule that has fire. This list will have the follwing syntax:
	key_name:value
	key_name is the string you used in the argument -k
	Value is one of the following values:
		write;read; execute;attribute;command
By default, OSSEC includes a CDB list with the following keys:

# cat /var/ossec/etc/lists/audit-keys

audit-wazuh-w:write
audit-wazuh-r:read
audit-wazuh-a:attribute
audit-wazuh-x:execute
audit-wazuh-c:command
You can add your own key with its value to the list like this:

# echo "my_key_write_type:write" >> /var/ossec/etc/lists/audit-keys
Each time you modify a CDB list, you must compile it:

# /var/ossec/bin/ossec-makelists

-----		Agent
Installing Audit
apt install auditd

ossec.conf
<localfile>
	<log_format>audit</log_format>
	<location>/var/log/audit/audit.log</location>
</localfile>

service wazuh-agent restart

--------
Now everything is ready to process audit events. You only need to create the proper audit rules (via auditctl or /etc/audit/audit.rules). In the next section we will describe some good use cases.

Monitoring accesses to a directory

In this example, we are going to monitor every kind of access under the /home directory:

auditctl -w /home -p w -k audit-wazuh-w
auditctl -w /home -p a -k audit-wazuh-a
auditctl -w /home -p r -k audit-wazuh-r
auditctl -w /home -p x -k audit-wazuh-x
Now we start getting alerts on account of the new audit rules:

--------	Monitoring user actions
# auditctl -a exit,always -F euid=0 -F arch=b64 -S execve -k audit-wazuh-c
# auditctl -a exit,always -F euid=0 -F arch=b32 -S execve -k audit-wazuh-c

-------- Privilege escalation

By default, Wazuh is able to detect privilege escalation by analyzing the corresponding log in /var/log/auth.log. The below example shows the homer user executing a root action:


In order to keep the track of the user after sudo, it is necessary to configure PAM.

Warning

Be very careful with PAM configuration, as a bad configuration could make your system inaccessible.

Add the following line to every PAM service that needs it:

session required        pam_loginuid.so

A common configuration should include: login, common-session, cron and sshd:

# grep -R "pam_loginuid.so" /etc/pam.d/

/etc/pam.d/login:session    required     pam_loginuid.so
/etc/pam.d/common-session:session required        pam_loginuid.so
/etc/pam.d/cron:session    required     pam_loginuid.so
/etc/pam.d/sshd:session    required     pam_loginuid.so

After configuring PAM, if we execute the previous command with the user homer we will see that the field auid is 1004, the id of the user homer.

# homer@springfield:/# sudo ls /var/ossec/etc

=============			Command monitoring

There are times when you may want to monitor things that are not in the logs. To address this, Wazuh incorporates the ability to monitor the output of specific commands and treat the output as though it were log file content.

Configure Wazuh agents to accept remote commands from the manager

Agents have the ability to run commands pushed from the manager (via the files in the shared directory). Before this feature can be used, however, the agents must be explicitly configured to accept remote commands. This can be done by setting the logcollector.remote_commands in the local_internal_options.conf file on each agent as shown below:

# Logcollector - Whether or not to accept remote commands from the manager
logcollector.remote_commands=1

Configure a command to monitor

The commands to run and monitor can be configured in the local the ossec.conf file of individual agents, however, the ideal location for this configuration is in the appropriate configuration section of the agent.conf file on the manager.

Example:

<localfile>
     <log_format>full_command</log_format>
     <command>.....</command>
     <frequency>120</frequency>
</localfile>

Process the output

After configuring the system to monitor the command’s output as if it were log data, custom rules can be created, like for Log analysis for instance, in order to process the output and trigger an alert when alert criteria are met.

============		Configuration 
------------		Basic
Command monitoring is configured in the localfile section of ossec.conf. It can be also be centrally configured in agent.conf.

Monitor running Windows processes

Let’s say you want to monitor running processes and alert if an important process is not running.

Example with notepad.exe as the important process to monitor:

1. Configure the agent in the agent’s local_internal_options.conf file to accept remote commands from the manager.

# Logcollector - Whether or not to accept remote commands from the manager
logcollector.remote_commands=1
2. Define the command in the manager’s agent.conf file to list running processes.

<localfile>
     <log_format>full_command</log_format>
     <command>tasklist</command>
     <frequency>120</frequency>
 </localfile>
The <frequency> tag defines how often the command will be run in seconds.

3. Define the rules.

<rule id="100010" level="6">
  <if_sid>530</if_sid>
  <match>^ossec: output: 'tasklist'</match>
  <description>Important process not running.</description>
  <group>process_monitor,</group>
</rule>
<rule id="100011" level="0">
  <if_sid>100010</if_sid>
  <match>notepad.exe</match>
  <description>Processes running as expected</description>
  <group>process_monitor,</group>
</rule>

The first rule (100010) will generate an alert (“Important process not running”), unless it is overridden by its child rule (100011) that matches notepad.exe in the command output. You may add as many child rules as needed to enumerate all of the important processes you want to monitor. You can also adapt this example to monitor Linux processes by changing the <command> from tasklist to a Linux command that lists processes, like ps -auxw.

Disk space utilization

The df command can be configured in the manager’s agent.conf file or in the agent’s ossec.conf file:

<localfile>
    <log_format>command</log_format>
    <command>df -P</command>
</localfile>
Wazuh already has a rule to monitor this:

<rule id="531" level="7" ignore="7200">
  <if_sid>530</if_sid>
  <match>ossec: output: 'df -P': /dev/</match>
  <regex>100%</regex>
  <description>Partition usage reached 100% (disk space monitor).</description>
  <group>low_diskspace,pci_dss_10.6.1,</group>
</rule>

Check if the output changed

In this case, the Linux “netstat” command is used along with the check_diff option to monitor for changes in listening tcp sockets.

This can be configured in either the agent.conf file or the ossec.conf file:

<localfile>
  <log_format>full_command</log_format>
  <command>netstat -tan |grep LISTEN|grep -v 127.0.0.1</command>
</localfile>
Wazuh already has a rule to monitor this:

<rule id="533" level="7">
  <if_sid>530</if_sid>
  <match>ossec: output: 'netstat -tan</match>
  <check_diff />
  <description>Listened ports status (netstat) changed (new port opened or closed).</description>
  <group>pci_dss_10.2.7,pci_dss_10.6.1,</group>
</rule>

If the output changes, the system will generate an alert indicating a network listener has disappeared or a new one has appeared. This may indicate something is broken or a network backdoor has been installed.

Load average

Wazuh can be configured to monitor the Linux uptime command and alert when it is higher than a given threshold, like 2 in this example.

This can be configured in agent.conf or ossec.conf:

<localfile>
    <log_format>command</log_format>
    <command>uptime</command>
</localfile>
And the custom rule to alert when “uptime” is higher than 2:

<rule id="100101" level="7" ignore="7200">
  <if_sid>530</if_sid>
  <match>ossec: output: 'uptime': </match>
  <regex>load averages: 2.</regex>
  <description>Load average reached 2..</description>
</rule>
Detect USB Storage

Wazuh can be configured to alert when a USB storage device is connected. This example is for a Windows agent.

Configure your agent to monitor the USBSTOR registry entry by adding the following to the manager’s agent.conf

<agent_config os="Windows">
  <localfile>
      <log_format>full_command</log_format>
      <command>reg QUERY HKLM\SYSTEM\CurrentControlSet\Enum\USBSTOR</command>
  </localfile>
</agent_config>
Next create a custom rule:

<rule id="140125" level="7">
    <if_sid>530</if_sid>
    <match>ossec: output: 'reg QUERY</match>
    <check_diff />
    <description>New USB device connected</description>
</rule>

============		Active response
 Active responses are either stateful or stateless responses. Stateful responses are configured to undo the action after a specified period of time while stateless responses are configured as one-time actions.

Where are active response actions executed?

Each active response specifies where its associated command will be executed: on the agent that triggered the alert, on the manager, on another specified agent or on all agents, which also includes the manager(s).

Active response configuration

Active responses are configured in the manager by modifying the ossec.conf file as follows:

Create a command

In order to configure an active response, a command must be defined that will initiate a certain script in response to a trigger.

Custom scripts that have the ability to receive parameters from the command line may also be used for an active response.

Example:

<command>
  <name>host-deny</name>
  <executable>host-deny.sh</executable>
  <expect>srcip</expect>
  <timeout_allowed>yes</timeout_allowed>
</command>
In this example, the command is called host-deny and initiates the host-deny.sh script. The data element is defined as srcip. This command is configured to allow a timeout after a specified period of time, making it a stateful response.

----------	Define the active response

The active response configuration defines when and where a command is going to be executed. A command will be triggered when a specific rule with a specific id, severity level or source matches the active response criteria. This configuration will further define where the action of the command will be initiated, meaning in which environment (agent, manager, local, or everywhere).

Example:

<active-response>
  <command>host-deny</command>
  <location>local</location>
  <level>7</level>
  <timeout>600</timeout>
</active-response>

<active-response>
  <command>host-deny</command>
  <location>local</location>
  <level>7</level>
  <timeout>600</timeout>
</active-response>
In this example, the active response is configured to execute the command that was defined in the previous step. The where of the action is defined as the local host and the when is defined as any time the rule has a level higher than 6. The timeout that was allowed in the command configuration is also defined in the above example.

---------	The active response log can be viewed at /var/ossec/logs/active-response.log.
---------	Default Active response scripts

Wazuh is pre-configured with the following scripts for Linux:

Script name	Description
disable-account.sh	Disables an account by setting passwd-l
firewall-drop.sh	Adds an IP to the iptables deny list
firewalld-drop.sh	Adds an IP to the firewalld drop list
host-deny.sh	Adds an IP to the /etc/hosts.deny file
ip-customblock.sh	Custom OSSEC block, easily modifiable for custom response
ipfw_mac.sh	Firewall-drop response script created for the Mac OS
ipfw.sh	Firewall-drop response script created for ipfw
npf.sh	Firewall-drop response script created for npf
ossec-slack.sh	Posts modifications on Slack
ossec-tweeter.sh	Posts modifications on Twitter
pf.sh	Firewall-drop response script created for pf
restart-ossec.sh	Automatically restarts Wazuh when ossec.conf has been changed
route-null.sh	Adds an IP to null route


----------	Configuration
Basic usage

An active response is configured in the ossec.conf file in the Active Response and Command sections.
This is a Stateless response as no timeout parameter is defined.

Command:

<command>
  <name>restart-ossec</name>
  <executable>restart-ossec.sh</executable>
  <expect></expect>
</command>
Active response:

<active-response>
  <command>restart-ossec</command>
  <location>local</location>
  <rules_id>10005</rules_id>
</active-response>

---------	Windows automatic remediation
In this example, the win_rout-null command is configured to use the route-null.cmd script using the data element srcip. The active response is configured to initiate the win_rout-null command on the local host when the rule has a higher alert level than 7. This is a Stateful response with a timeout set at 900 seconds.

Command:

<command>
  <name>win_route-null</name>
  <executable>route-null.cmd</executable>
  <expect>srcip</expect>
  <timeout_allowed>yes</timeout_allowed>
</command>
Active response:

<active-response>
  <command>win_route-null</command>
  <location>local</location>
  <level>8</level>
  <timeout>900</timeout>
</active-response>

--------	Block an IP with PF
Command:

<command>
  <name>pf-block</name>
  <executable>pf.sh</executable>
  <expect>srcip</expect>
</command>
Active response:

<active-response>
  <command>pf-block</command>
  <location>defined-agent</location>
  <agent_id>001</agent_id>
  <rules_group>authentication_failed,authentication_failures</rules_group>
</active-response>


Add an IP to the iptables deny list
----------   Windows automatic remediation
Command:

<command>
  <name>win_route-null</name>
  <executable>route-null.cmd</executable>
  <expect>srcip</expect>
  <timeout_allowed>yes</timeout_allowed>
</command>
Active response:

<active-response>
  <command>win_route-null</command>
  <location>local</location>
  <level>8</level>
  <timeout>900</timeout>
</active-response>

----------   PF
Active response:

<active-response>
  <command>pf-block</command>
  <location>defined-agent</location>
  <agent_id>001</agent_id>
  <rules_group>authentication_failed,authentication_failures</rules_group>
</active-response>

------------	Add an IP to the iptables deny list
Command:

<command>
  <name>firewall-drop</command>
  <executable>firewall-drop.sh</executable>
  <expect>srcip</expect>
</command>
Active response:

<active-response>
  <command>firewall-drop</command>
  <location>all</location>
  <rules_group>authentication_failed,authentication_failures</rules_group>
  <timeout>700</timeout>
  <repeated_offenders>30,60,120</repeated_offenders>
</active-response>

----------		Active response for a specified period of time
Command:

<command>
  <name>host-deny</name>
  <executable>host-deny.sh</executable>
  <expect>srcip</expect>
  <timeout_allowed>yes</timeout_allowed>
</command>
Active response:

<active-response>
  <command>host-deny</command>
  <location>local</location>
  <level>7</level>
  <timeout>600</timeout>
</active-response>

--------		Active response that will not be undone

In this example, the mail-test command is configured to use the mail-test.sh script with no data element. The active response is configured to initiate the mail-test command on the server when the rule with ID 1002 fires.

Command:

<command>
  <name>mail-test</name>
  <executable>mail-test.sh</executable>
  <timeout_allowed>no</timeout_allowed>
  <expect></expect>
</command>
Active response:

<active-response>
    <command>mail-test</command>
    <location>server</location>
    <rules_id>1002</rules_id>
 </active-response>

===============		Agentless monitoring

------The first step to using agentless monitoring is to enable it using the following command:

# /var/ossec/bin/ossec-control enable agentless

------	In order to connect the manager to the device using SSH authentication, the following register_host.sh script should be used. This script is located in the /var/ossec/agentless/ directory and has two options: list and add.

Using the list option will list all hosts already included.

# /var/ossec/agentless/register_host.sh list
Using the add option will specify a new device to be added to the manager. NOPASS may be entered as the password to use public key authentication rather than using a password. For Cisco devices, such as routers or firewalls, enablepass should be used to specify the enable password.

# /var/ossec/agentless/register_host.sh add root@example_address.com example_password [enablepass]
Public key authentication can be used with the following command:

# sudo -u ossec ssh-keygen
Once created, the public key must be copied into the remote device.

--------	Monitoring
ossec.conf
---	BSD integrity check
<agentless>
  <type>ssh_integrity_check_bsd</type>
  <frequency>20000</frequency>
  <host>root@test.com</host>
  <state>periodic</state>
  <arguments>/bin /var/</arguments>
</agentless>

---	Linux integrity check
<agentless>
  <type>ssh_integrity_check_linux</type>
  <frequency>36000</frequency>
  <host>root@test.com</host>
  <state>periodic</state>
  <arguments>/bin /etc/ /sbin</arguments>
</agentless>
---	Generic Diff
A set of commands can also be configured to run on a remote device. Wazuh will alert you if the output of those commands changes. In order to use this option, set the type as ssh_generic_diff, as shown below.

<agentless>
  <type>ssh_generic_diff</type>
  <frequency>20000</frequency>
  <host>root@test.com</host>
  <state>periodic_diff</state>
  <arguments>ls -la /etc; cat /etc/passwd</arguments>
</agentless>

---	Pix config
This option will alert if a Cisco PIX/router configuration changes. Set the type to ssh_pixconfig_diff, as shown below.

<agentless>
  <type>ssh_pixconfig_diff</type>
  <frequency>36000</frequency>
  <host>pix@pix.fw.local</host>
  <state>periodic_diff</state>
</agentless>

---	Checking the setup
Finally, the expect package must be present on the manager for this feature to work.

When the expect package is present and Wazuh is restarted, the following is shown in the /var/ossec/logs/ossec.log file:

ossec-agentlessd: INFO: Test passed for 'ssh_integrity_check_linux'.
When Wazuh has connected to the remote device, the following will be shown in the same log file:

ossec-agentlessd: INFO: ssh_integrity_check_linux: root@example_adress.com: Starting.
ossec-agentlessd: INFO: ssh_integrity_check_linux: root@example_adress.com: Finished.

---	Alert
Once configured as above, Wazuh alerts will be triggered when changes occur within the directories:

Sample alerts are as follows:

Integrity check BSD/Linux sample alert:

---------		Configuration

===============		Anti-flooding mechanism
Here are some misconfiguration scenarios that could lead to this problem:

Realtime FIM (Syscheck) of a directory with files that keep changing:
Events are generated every time a file under a Syscheck-monitored directory changes. If Syscheck monitors a directory which changes constantly, it will generate a large volume of events. In addition, if the monitored directory contains any file to which Wazuh writes when it generates an event, like /var/ossec/queue/, it will cause an infinite loop.

Windows Filtering Platform:
A Windows firewall event (ID 5156) is generated each time an outbound network connection is allowed. When this event is enabled in Windows, and Wazuh is configured to monitor all Windows Security Log events the result is an infinite loop. When the agent connects its manager, it generates a Windows firewall event that in turn causes the agent to connect again to its manager.

Applications that retry on errors with no rate limiting:
When certain applications encounter an error, like disk full for instance, they may generate an error log entry and retry given the task over and over again hundreds of times per second, generating a massive volume of events.

Each of these scenarios may well create such a high rate of events that the functioning of the agent, network, and/or manager may be significantly hampered.

In order to better handle these kinds of situations, the following controls have been deployed:

Agent-to-manager anti-flooding mechanism:
This provides event congestion control with an agent-side leaky bucket queue to guard against saturation of the network or of the manager by an agent.

Internal agent anti-flooding control:
This mechanism uses internal limits in different components of the agent, controlling the rate at which they generate events.

-------		How it works: Leaky bucket
Leaky bucket collects events in a buffer of a specified size (default 5000 events), and sends them to the manager at a rate no higher than a specified number, and network environment.(default 500 EPS).

-----			Buffer architecture
0-70% - normal working
70-90% - warning. Operation: Working properly.
Aler: Warning alert when reach 90%
100% - Operation: loss when is full
Alert: Full alert when buffer is filled.
Alert: Flood alert when is flooded.

-----	There are several levels of control:
Warning alert: The first control will trigger an alert on the manager when the occupied capacity of the buffer has reached a certain threshold. By default it is set at 90 percent.
Full alert: After the first control, if the buffer gets filled, another alert will be triggered on the manager. This new alert is more serious than a warning alert because a full bucket will drop incoming events.
Flood alert: This alert is generated if more than a configurable amount of time passes between a full alert event and the buffer level dropping below the warning level.
Normal alert: This alert is generated to announce that the buffer level has returned to normal (by default <= 70%) after having previously triggered a warning alert or higher.

-----	Measured configuration
In the <client_buffer> section of Local configuration it is possible to disable the buffer, configure the size of the buffer (in number of events), and configure its throughput limit measured in EPS, or event-per-second.

Disable buffer: This parameter disables the use of the leaky bucket, resulting in no restriction on the rate of events transmitted by the agent to the manger. This is how previous versions of the agent were set up.
Queue size: The queue size is the maximum number of events that can be held in the leaky bucket at one time. It should be configured according to the expected rate at which an agent may generate events. This value is set to 5000 events by default, which is a generous buffer size for most environments.
Events per second: This is the maximum rate at which events will be pulled from the agent’s buffer and transmitted to its manager. The default is a generous 500 EPS, but this should be set with consideration of the capacity of the network and the number of agents a manager is serving.

==========	Agent Labels
-------	Addition configuration information is available in the Internal configuration section. This includes information on analysisd.label_cache_maxage and analysisd.show_hidden_labels.

------		Use case.
AWS - large environment.
AWS instance-id
AWS Security group
Network IP address
Network MAC
Date of installation

To include these labels in alerts from a specific agent, the following configuration must be inserted into the ossec.conf file:

<labels>
  <label key="aws.instance-id">i-052a1838c</label>
  <label key="aws.sec-group">sg-1103</label>
  <label key="network.ip">172.17.0.0</label>
  <label key="network.mac">02:42:ac:11:00:02</label>
  <label key="installation" hidden="yes">January 1st, 2017</label>
</labels>
To set the labels at the manager level, the following configuration would be added to the agent.conf file:

<agent_config name="92603de31548">
  <labels>
    <label key="aws.instance-id">i-052a1838c</label>
    <label key="aws.sec-group">sg-1103</label>
    <label key="network.ip">172.17.0.0</label>
    <label key="network.mac">02:42:ac:11:00:02</label>
    <label key="installation" hidden="yes">January 1st, 2017</label>
  </labels>
</agent_config>
When an alert is fired for an agent with the above configuration applied from the manager, the defined labels will add information to alerts as shown below:

 ** Alert 1488922301.778562: mail  - ossec,syscheck,pci_dss_11.5,
 2017 Jun 07 13:31:43 (92603de31548) 192.168.66.1->syscheck
 aws.instance-id: i-052a1838c
 aws.sec-group: sg-1103
 network.ip: 172.17.0.0
 network.mac: 02:42:ac:11:00:02
 Rule: 550 (level 7) -> 'Integrity checksum changed.'
 Integrity checksum changed for: '/var/ossec/etc/ossec.conf'
 Size changed from '3663' to '3664'
 Old md5sum was: '98b351df146410f174a967d726f9965e'
 New md5sum is : '7f4f5846dcaa0013a91bd6d3ac4a1915'
 Old sha1sum was: 'c6368b866a835b15baf20976ae5ea7ea2788a30e'
 New sha1sum is : 'c959321244bdcec824ff0a32cad6d4f1246f53e9'

============		System inventory
The Wazuh agents are able to collect interesting system information and store it into an SQLite database for each agent on the manager side. The Syscollector module is in charge of this task.

Once the agent starts, Syscollector runs periodically scans of defined targets (hardware, OS, packages, etc.), forwarding the new collected data to the manager, which updates the appropriate tables of the database.

----	Available scans

The collected information from Wazuh agents is stored in different SQLite tables. Here the content of each available table is described .

At present, this module is available for Linux, Windows, MacOS, OpenBS and FreeBSD. See the compatibility matrix for more information.

- Hardware
- OS
	hostname
	architecture 
	os_name
	Os_version
	os_codename
	os_major
	os_minor
	os_build
	os_platform
	sysname
	release
	version

- Packages
	name
	priority
	section
	size
	vendor
	install_time
	version
	architecture
	multiarch
	source
	description
	location

- Network interfaces
sys_netiface table
	name
	adapter
	type 
	state
	mtu
	mac
	tx_packets
	rx_packets
	tx_bytes
	rx_bytes
	tx_errors
	rx_errors
	tx_dropped
	rx_dropped

sys_netaddr table
	proto
	address
	netmask
	broadcast

sys_netproto table
routing configuration for each interface
	iface
	type
	gateway
	dhcp

- Ports
	protocol
	local_ip
	local_port
	remote_ip
	remote_port
	tx_queue
	rx_queue
	inode
	state
	PID
	process

- Processes
List the current processes running in a system host.

	pid 
	name
	state
	ppid
	utime
	stime
	cmd
	argvs
	euser
	ruser
	suser
	egroup
	rgroup
	...

-Compatibility matrix

The following table shows the operating systems that this module currently supports.

Operating System	Syscollector scan
Hardware	OS	Packages	Network	Ports	Processes
Windows	✓	✓	✓	✓	✓	✓
Linux	✓	✓	✓	✓	✓	✓
macOS	✓	✓	✓	✓	✗	✗
FreeBSD	✓	✓	✓	✓	✗	✗
OpenBSD	✓	✓	✗	✓	✗	✗

--------Use case: Visualize system inventory in the Wazuh app

The Syscollector module is enabled by default in all compatible systems including all the available scans. Here we can see the default configuration block:

<!-- System inventory -->
<wodle name="syscollector">
  <disabled>no</disabled>
  <interval>1h</interval>
  <scan_on_start>yes</scan_on_start>
  <hardware>yes</hardware>
  <os>yes</os>
  <network>yes</network>
  <packages>yes</packages>
  <ports all="no">yes</ports>
  <processes>yes</processes>
</wodle>

Once the module starts, it will run periodically scans and send the new data in JSON events format to the manager, where it will be decoded and stored into a particular database for each agent.

The current inventory can be consulted in different ways. Let’s see an example querying for a particular package in a Debian agent:

Querying the Database directly on the manager side, located at $install_directory/queue/db/:agent_id.db.

=========		Vulnerability detection
=========		CVE - Common vulnarabilities and exposes.

This capability can be used to detect applications that are known to be vulnerable (affected by a CVE).

----	How it works
To be able to detect, now agents are able to natively collect a list of installed applications,
sending it periodically to the manager ( where it is stored in local sqlite databases, one per agent). 
In addition , the manager builds a global vulnerabilities database, using public OVAL CVE
repositories, using it later to cross correlate this information with agent's applications inventory data.

The global vulnerabilities database is created automatically, currently pulling data from the following repositories:
https://people.canonical.com # pull CVEs for Ubuntu Linux distriburions
https://www.refat.com	# pull CVEs for Red Hat and CentOS Linux distriburions
https://www.debian.com	#	pull CVEs for Debian Linux distributiona.

This database can be configured to be updated periodically, ensuring that the solution will check for the very latest CVEs.

Once the global vulnerability databse (with the CVEs( is created, the detection process will look for vvulnerable packages in the inventory databases (unique per agent). Alerts are generated when a CVE (Common Vulnerabilities and Exposures) affects a paxkage that is known to be installed in one of the monitored servers.

----		Compatibility matrix 
and the OVAL configuration needed for each distribution:

Distribution	Versions	Configuration OVALs
Red Hat & CentOS	5	Red Hat 5 OVAL
6	Red Hat 6 OVAL
7	Red Hat 7 OVAL
Ubuntu	12	Ubuntu 12 OVAL
14	Ubuntu 14 OVAL
16	Ubuntu 16 OVAL
18	Ubuntu 18 OVAL
Debian	7	Debian 7 OVAL
8	Debian 8 OVAL
9	Debian 9 OVAL
Amazon Linux	1	Red Hat 7 OVAL

--- Use case: Running a vulnerability scan
Config
1. Enable the agent module used to collect installed packages on the monitored system.
add to shared agent configuration file:
<wodle name="syscollector">
	<disabled>no</disabled>
	<interval>1h</interval>
	<packages>yes</packages>
</wodle>

 Enable the manager module used to detect vulnerabilities.
You can do this adding the following block of settings to your manager configuration file:

<wodle name="vulnerability-detector">
  <disabled>no</disabled>
  <interval>5m</interval>
  <run_on_start>yes</run_on_start>
  <feed name="ubuntu-18">
    <disabled>no</disabled>
    <update_interval>1h</update_interval>
  </feed>
</wodle>

service wazuh-manager restart

The following fields are captured in evry alert:
- CVE: The CVE identifier for the corresponding culnerability.
- Title: Short description of the impact of vulnerability.
- Severity: It specifies the impact of the vulnerability in terms of security.
- Published: Date when the vulnerability was included in the offical database.
- Reference: URL of the official database website with extra information of the vulnerability.
- Rationale: Broad description of the vulnerability.
- State: This field informs if it exists a patch for the vulnerability (fixed) or instead, its state.


=============		Virus Total Integration
scans monitored filed for malicious content.

Virus Total - powerful platform that aggregates multiple antivirus products along with an online scanningh engine.
Combining this tool with out FIM ingine provides a simple means of scanning the files that are monitored by syscheck to inspect them for malicious content.

----	Virus Total - is an online service that analyzes files and URLs for the detection of viruses, worms, trojans and other kinds of malicious content using antivirus engines and website scanners. It also has the ability to detect false positives.

VT - free sevice with numerous useful features.
- VT stores all of the analyses it performs which allows for the hash of a specific file to be searched. By sending the hash to the VirusTotal engine, it can be known if that specific file has already been scanned by VT and analyze its report.
- VT also provides an API that allows access to the inforrnation generated by VT without needing to utilize the HTML websit interface. This API is subject to its Terms of Service which are briefly discussed in the following section.

-----	ToS: Public API vs Private API
- Public API	-  has important limitations, 
	the request ratio limitation to no more than four requests of per minute, and
	low priority access of requests done by this API for the VT enfine.

	Users who run a honeyclient, honeypot or any other automation that provides resources to VT are rewarded with a higher request rate quota and special privileges when performing the calls to the API

- PRIVATE API
	premium . it provides high priority access for requests, along with additional advantages.

-------			HOW IT WORKS

syscheck monitored files , and they are checked by VT.
1. FIM fix change or deletion of files in the folders monitored by the syscheck module.
2. When the VT integration is enabled , it is triggered when a FIM alert occurs. From this alert, the module extracts the hash field of the file.
3. The module then makes an HTTP POST request to the VT database using the VT API for comparison between the extracted hash and the information contained in the database.
4. A JSON response is then received that is the result of this search which will trigger one of the following alerts:
	Pub API request rate limit reached
	check credentials
	no records in VT database
	no positives found
	x engines detected this file



----			Use case: scanning a gile with the VT integration
1. pip install requests
2. add to ossec.conf:
<integration>
	<name>virustotal</name>
	<api_key>API_KEY</api_key>
	<group>syscheck</group>
	<alert_format>json</alert_format>
</integration>
3. bin/ossec-control enable integrator
4. service wazuh-manager restart
After this is complete, and FIM alert automatically triggers the VT integration.

----		Using FIM to monitor a directory
1. The following must be added to the <syscheck> section of the configuration file:
<syscheck>
  <directories check_all="yes" realtime="yes">/media</directories>
</syscheck>

2. syscheck module must then be restarted.

----	VT integration alerts.
When a request to VT is sent bt the integrator module , as noted above, different alerts will be triggered depending on the situation. Below are examples and explanations of these alerts:

==========		Osquery
---	Wazuh module that allows to manage the Osquery tool from Wazuh agents, being able to set the Osquery configuration and collect the information generated by Osquery to send it to the manager, generating the corresponding alerts if necessary.

----	How it works 
Osquery can be used to expose an operating system as a high-performance relational database.
This allows you to write SQL-based queries to explore operating system data.

Below you can see some examples of the queries you can make:

List all the local users of the machine.

SELECT * FROM users;

Get the process name, port , and PID, for processes listening on all interfaces.
SELECT DISTINCT processes,name, listening_ports.port, processes.pid FROM listening_ports JOIN processes USING (pid) WHERE listening_ports.address = '0.0.0.0';

Check the processes that have a deleted executable.

SELECT * FROM processes WHERE on_disk = 0;

-------		Configuration
1. You need a working Osquery installation in your system. 
# export OSQUERY_KEY=1484120AC4E9F8A1A577AEEE97A80C63C9D8B80B
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys $OSQUERY_KEY
# add-apt-repository 'deb [arch=amd64] https://pkg.osquery.io/deb deb main'
# apt-get update
# apt-get install osquery
2. cp /usr/share/osquery/osquery.example.conf /etc/osquery/osquery.conf
or 
copy custom configuration in /etc/osquery/osquery.conf:
{
    "options": {
        "config_plugin": "filesystem",
        "logger_plugin": "filesystem",
        "utc": "true"
    },

    "schedule": {
        "system_info": {
        "query": "SELECT hostname, cpu_brand, physical_memory FROM system_info;",
        "interval": 3600
        },
        "high_load_average": {
        "query": "SELECT period, average, '70%' AS 'threshold' FROM load_average WHERE period = '15m' AND average > '0.7';",
        "interval": 900,
        "description": "Report if load charge is over 70 percent."
        },
        "low_free_memory": {
        "query": "SELECT memory_total, memory_free, CAST(memory_free AS real) / memory_total AS memory_free_perc, '10%' AS threshold FROM memory_info WHERE memory_free_perc < 0.1;",
        "interval": 1800,
        "description": "Free RAM is under 10%."
        }
    },

    "packs": {
        "osquery-monitoring": "/usr/share/osquery/packs/osquery-monitoring.conf",
        "incident-response": "/usr/share/osquery/packs/incident-response.conf",
        "it-compliance": "/usr/share/osquery/packs/it-compliance.conf",
        "vuln-management": "/usr/share/osquery/packs/vuln-management.conf",
        "hardware-monitoring": "/usr/share/osquery/packs/hardware-monitoring.conf",
        "ossec-rootkit": "/usr/share/osquery/packs/ossec-rootkit.conf"
    }
}

as you can see in this sample configuration, system_info , high_load_average and low_free_memory queries will be executed every hour.

Furthermore, this configuration uses some default packs such as osquery-monitoring, hardware-monitoring or ossec-rootkit among others. You can define you own packs and use it with this wodle.

-----		Alert examples


==============		Ruleset
This documentation explains how to install, update, and contribute to Wazuh Ruleset. These rules are used by the system to detect 
attacks, 
intrusions, 
software misuse, 
configuration problems, 
application errors, 
malware, 
rootkits, 
system anomalies or 
security policy violations. 
OSSEC provides an out-of-the-box set of rules that we update and augment, in order to increase Wazuh detection capabilities.

----		Begin
The default number of rules and decoders is limited. For this reason, we centralize, test and maintain decoders and rules submitted by opensource contributors.
We also create new rules and rootchecks perodically and add them to this repository so they can be used by the user community.
Some examples are the new rules for Netscaler and Puppt.

----		GitHub repository
in the ruleset repository you will find:
- New rules, decoders and rootcheccks
	eliminate false positives and to increase accuracy. We map the rules to pci-dss compliance controls, making it easy to identify when an alert is related to a specific compliance requirement.
- Tools - we provide some useful tools for testing.

----		Resources
- Visit out repository to view the rules in detail at https://github.com/wazuh/wazuh-ruleset
- Find a complete description of the available rules at Wazuh Ruleset Summary https://www.wazuh.com/resources/OSSEC_Ruleset.pdf

--- 	Rule and Rootcheck example
<rule id="80102" level="10" frequency="6">
	<if_matched_sid>80101</if_matched_sid>
	<same_source_ip />
	<description> Netscaler: Multiple AAA failed to login the user </description>
	<group>authentication_failure, netscaler-aaa,pce_dss_10.2.4,pci_dss_10.2.5,pci_dss_11.4,</group>
</rule>


----		Directory layout
The ruleset folder structure is shown below:
/var/ossec/
        ├─ etc/
        │   ├─ decoders/
        |   |        └─ local_decoder.xml
        │   └─ rules/
        |         └─ local_rules.xml
        └─ ruleset/
                ├─ decoders/
                └─ rules/

Insede the ruleset/ folder you will find all the common rules and decoders. All files insede this ffolder will be overwritten or modified in the Wazuh update process, so please do not edit files or add custom files in this folder.

If we need to perform some custom changes, we will use the etc/ folder. You can add here your own decoders/rules files or use the default local_decoder.xml and local_rules.xml files.


-------		Update ruleset 
bin/update_ruleset
-----		Configure weekly updates
sudo crontab -e 
@weekly root cd /var/ossec/bin && ./update_ruleset -r

=======		JSON decoder
Wazuh now incorporates an integrated decoder for JSON logs enabling the extraction of data from any source in this format.

This decoder has the ability to extract the following data types:
Numbers
Strings 
Booleans
Null values
Arrays
Objects

Extracted fields are stored as Dynamic Fields and can be referred to by the rules.

The following example shows how Wazuh decodes a JSON log and generates an alert for Suricata.

Suricata event log:

{
   "timestamp": "2016-05-02T17:46:48.515262+0000",
   "flow_id": 1234,
   "in_iface": "eth0",
   "event_type": "alert",
   "src_ip": "16.10.10.10",
   "src_port": 5555,
   "dest_ip": "16.10.10.11",
   "dest_port": 80,
   "proto": "TCP",
   "alert": {
      "action": "allowed",
      "gid": 1,
      "signature_id": 2019236,
      "rev": 3,
      "signature": "ET WEB_SERVER Possible CVE-2014-6271 Attempt in HTTP Version Number",
      "category": "Attempted Administrator Privilege Gain",
      "severity": 1
   },
   "payload": "21YW5kXBtgdW5zIGRlcHJY2F0QgYWI",
   "payload_printable": "this_is_an_example",
   "stream": 0,
   "host": "suricata.com"
}

---	The JSON decodder extracts each the fields from the log data for comparison against the rules such that a apecific Suricata decoder is not needed. 
The rules will be used to identify the surce of the JSON event based on the existence of certain fields that are specific to the soutce that the JSON event was generated from.

The following example shows how the rules contained in the file 0470-suricata_rules.xml work.

Initially, there is a parent rule to check for the existence of the 'timestamp' and 'event_type' fields
to determine the type of log (Suricata), then the child rule displays the alert using the value of the extracted fields.

<rule id="86600" lebel="0">
	<decoded_as>json</decoded_as>
	<field name="timestamp">\.+</field>
	<field name="event_type">\.+</field>
	<description>Suricata messages.</description>
</rule>

<rule id="86601" level="3">
	<if_sid>86600</if_sid>
	<field name="event_type">^alert$</field>
	<description>Suricata: Alert - $(alert.signature)</description>
</rule>
...


-------
New in version 3.3.0.

Lets see another example where we use the JSON decoder to extract a JSON included as a part of an incoming log. This is possible thanks to the new attribute offset introduced to the decoder options, that allows to discard some parts of the input string.

If we use this input log:

2018 Apr 04 13:11:52 nba_program: this_is_an_example: " player_information: "{ "name": "Stephen", "surname": "Curry", "team": "Golden State Warriors", "number": 30, "position": "point guard"}
The decoder declaration using that new feature would be the following:

<decoder name="raw_json">
    <program_name>nba_program</program_name>
    <prematch>player_information: "</prematch>
    <plugin_decoder offset="after_prematch">JSON_Decoder</plugin_decoder>
</decoder>
The JSON decoder will extract the fields contained in the JSON event as dynamic fields, taking into account from the end of the prematch text. The output of the ossec-logtest is the following:

In addition, we could define a rule for these raw events decoded:

<rule id="100001" level="5">
    <decoded_as>raw_json</decoded_as>
    <description>Raw JSON event</description>
</rule>


--- Another new feature is the ability of mixing plugin decoders with regex expressions, take a look in the following incoming log:

2018 Jun 08 13:11:52 nba_email_db: json_data: { "name": "Stephen", "surname": "Curry", "email": "curry@gmail.com"}
We can set several children decoders from a parent specifying a plugin decoder as before, and also another one including a regex expression. For example, the following ones:

<decoder name="json_parent">
    <program_name>nba_email_db</program_name>
</decoder>

<decoder name="json_child">
    <parent>json_parent</parent>
    <prematch>json_data: </prematch>
    <plugin_decoder offset="after_prematch">JSON_Decoder</plugin_decoder>
</decoder>

<decoder name="json_child">
    <parent>json_parent</parent>
    <regex>@(\S+)"</regex>
    <order>email.domain</order>
</decoder>



-------		Custom rules and decoders
It is posseble to modify the default rules and decoders from the Wazuh Ruleset and also to add new ones in order to increase Wazuh's detection capabilities.

---		Adding new decoders and rules
- local_decoder.xml and local_rules.xml to implement small changes.

We are going to describe these procedures using an easy example. Here is a log from a program called example:
Dec 25 20:45:02 MyHost example[12345]: User 'admin' logged from '192.168.1.100'

1. Decode
add new decoder to 
/var/ossec/etc/decoders/local_decoder.xml

<decoder name="example">
  <program_name>^example</program_name>
</decoder>

<decoder name="example">
  <parent>example</parent>
  <regex>User '(\w+)' logged from '(\d+.\d+.\d+.\d+)'</regex>
  <order>user, srcip</order>
</decoder>

2. Rule:
/var/ossec/etc/rules/local_rules.xml

<rule id="100010" level="0">
  <program_name>example</program_name>
  <description>User logged</description>
</rule>

3. Check if it works.
/var/ossec/vin/ossec-logtest

--------	Changing an existing rule

You can modify the standard rules.

!Updating wazuh will rewrite all in /var/ossec/ruleset/rules folder

--- 	To change existing rule 
1. Open the rule file /var/ossec/ruleset/rules/0095-sshd_rules.xml
2. Find and copy the following code from the rule file:
<rule id="5710" level="5">
  <if_sid>5700</if_sid>
  <match>illegal user| invalid user</match>
  <description>sshd: Attempt to login using a non-existent user</description>
  <group>invalid_login,authentication_failed,pci_dss_10.2.4,pci_dss_10.2.5,pci_dss_10.6.1,</group>
</rule>
3. Paste the code into /var/ossec/etc/rules/local_rules.xml, modify the level value , and add 
overwrite="yes" to indicate that this rule is overwriting an already defined rule:

<rule id="5710" level="10" overwrite="yes">
  <if_sid>5700</if_sid>
  <match>illegal user|ivalid user </match>
  <description>sshd: Attempt to login using a non-existent user</description>
  <group>invalid_login,authentication_failed,pci_dss_10.2.4,pci_dss_10.2.5,pci_dss_10.6.1,</group>
</rule>

-------		Changing an existing decoder
You can also modify the standard decoders.

! Don't change in /var/ossec/ruleset/decoders

Different from the approach which we apply to rules

If we want to change something in the decoder file ..., we will do the following:
1. Copy the decoder file /var/ossec/ruleset/decoders/ssh_decod.xml from the default folder to the user folder /var/ossec/etc/decoders in order to keep the changes.
2. Exclude the original decoder file ruleset/decoders/0310-ssh_decoders.xml from the OSSEC loading list. To do this , use the tag 
<decoder_exclude> in the ossec.conf file. 
Thus , the specified decoder will not be loaded from the default decoder folder, and the decoder file saved in the user folder will be loaded instead.

<ruleset>
  <!-- Default ruleset -->
  <decoder_dir>ruleset/decoders</decoder_dir>
  <rule_dir>ruleset/rules</rule_dir>
  <rule_exclude>0215-policy_rules.xml</rule_exclude>
  <list>etc/lists/audit-keys</list>

  <!-- User-defined ruleset -->
  <decoder_dir>etc/decoders</decoder_dir>
  <rule_dir>etc/rules</rule_dir>
  <decoder_exclude>ruleset/decoders/0310-ssh_decoders.xml</decoder_exclude>
</ruleset>

3. Perform the changs in the file /var/ossec/etc/decoders/01310-ssh_decoders.xml.
!!!
Note that at this point, if updates o the public Wazuh Ruleset include changes to 0310-ssh..., 
they will not apply to you since you are no longer loading that decoder file from the standard
location that gets updates. At some point you may have to manually migrate your customized mterial from 0310-ssh_decoders.xml to a newer copy of that file.  Consider internally documenting your changes in 0310-ssh_decoders.xml so that they are easy to find if they have to be migrated later.

=========		Dynamic fields
---		Traditional decoders
An important step for the detection and processing of treats is the extraction of information from each event received. Wazuh uses decoders to identify event types and then extract the most relevant
fields, thus enriching events andd allowing them to be more deeply analyzed and indexed.

Traditionally, OSSEC has provided thirteen prdefined fields for storing extrcted information (user , srcip,dstip,srcport,dstport,protocol,action,id,url,data,extra_data,status,system,system_name),of which only eight can be extracted simultaneously.

Static fields:
<decoder name="web-accesslog">
  <type>web-log</type>
  <prematch>^\d+.\d+.\d+.\d+ - </prematch>
  <regex>^(\d+.\d+.\d+.\d+) - \S+ [\S+ -\d+] </regex>
  <regex>"\w+ (\S+) HTTP\S+ (\d+) </regex>
  <order>srcip,url,id</order>
</decoder>


-----			Dynamic decoders
It is often necessary to extract more than eight relevant fields from an evet, and often the actual
data items extracted have no relationship to the limited list of predefined field names. Knowing that we cannot afford to operate within these constraints, Wazuh has extende OSSEC to allow the decoding of an unlimited number of fields with field names that clearly relate to what is being extractes. Even nested field names are supported.

Dynamic Fields:
<decoder name="auditd-config_chane">
  <parent>auditd</parent>
  <regex offset="after_regex">^auid=(\S+) ses=(\S+) op="(\.+)"</regex>
  <order>audit.auid,audit.session,audit.op</order>
</decoder>

Wazuh transforms any field name included in the <order> tag into a JSON field.

The next example shows how the auditd decoder extracts the information from an alert:

** Alert 1486483073.60589: - audit,audit_configuration,
2017 Feb 07 15:57:53 wazuh-example->/var/log/audit/audit.log
Rule: 80705 (level 3) -> 'Auditd: Configuration changed'
type=CONFIG_CHANGE msg=audit(1486483072.194:20): auid=0 ses=6 op="add rule" key="audit-wazuh-a" list=4 res=1
audit.type: CONFIG_CHANGE
audit.id: 20
audit.auid: 0
audit.session: 6
audit.op: add rule
audit.key: audit
audit.list: 4
audit.res: 1

JSON Output:

{
  "rule": {
    "level": 3,
    "description": "Auditd: Configuration changed",
    "id": 80705,
    "firedtimes": 2,
    "groups": [
      "audit",
      "audit_configuration"
    ]
  },
  "agent": {
    "id": "000",
    "name": "wazuh-example"
  },
  "manager": {
    "name": "wazuh-example"
  },
  "full_log": "type=CONFIG_CHANGE msg=audit(1486483072.194:20): auid=0 ses=6 op=\"add rule\" key=\"audit-wazuh-a\" list=4 res=1",
  "audit": {
    "type": "CONFIG_CHANGE",
    "id": "20",
    "auid": "0",
    "session": "6",
    "op": "add rule",
    "key": "audit",
    "list": "4",
    "res": "1"
  },
  "decoder": {
    "parent": "auditd",
    "name": "auditd"
  },
  "timestamp": "2017 Feb 07 15:57:53",
  "location": "/var/log/audit/audit.log"
}


========		Decoders Syntax
- Decoder
The attributes list below defines a decoder.
id
name 
type 
status


- parent
It is used to link a subordinate codeblock to his parent.

- accumulate
allow wazuh to track events over multiple log messages based on a decoded id.

- program_name
It defines the name of the program with which the decoder is associated.

- prematch
It attempts to find a match within the log for the string defined.

- regex
The attribute below is optional, it allows to discard some of the content of the entry.

- The attribute below is optional , it allows to  dome of the content of the entry.

- order
It defines what the parenthesis groups contain and the order in which they were received.

	static fields
		srcuser, dstuser,user,srcip,dstip,srcport,dstport,protocol,id , url,action,status,
		extra_data
	Dynamic fields:
		Any string not included in the previous list.

- fts
	It is used to designate a decoder as one in which the first time it matches the administrator would like to be alerted.

	Allowed values
		location,srcuser,dstuser,user,srcip,dstip,srcport,dstport,protocol,id , url,action,
		status, extra_data

- ftscomment
	It adds a comment to a decoder when <fts> tag is used.

- plugin_decoder
Use a specific plugin decoder to decode the incoming fields. It is useful for particular cases where it would be tricky to extract the fields by using regexes.

Allowed values
	PF_Decoder,SymantecWS_Decoder,SonicWall_Decoder,SonicWall_Decoder,OSSECAlert_Decoder,JSON_Decoder

The attribute below is optional, it allows to start the decode process after a particular point of the log.

	offset = after_parent|after_prematch

An ex of its use is described at the JSON decoder section.

- use_own_name
Allows to set the name of the child decoder from tje name attribute instead of using the name of the parent decoder.
	Allowed values = true

- json_null_field
	Specify how to treat the NULL fields coing from the JSON events. Only for the JSON decoder.
	Allowed values
		string (it shows the NULL value as string)
		discard(It discard NULL fields and doesn't store them into the alert)
		empty(it shows the NULL field as an empty field)

27.11.2018
=======		Rules syntax
---		Rule 
	level 0 to 16
	id 	rule id		1 to 999999
	maxsize 	max event size		1 to 9999
	frequency 	Number of times the rule must have matched before firing	2 to 9999
	timeframe 	intended to be used with the frequency option.
			1 to 99999
	ignore 		ignore this rule after firing it (to avoid flood)
	overwrite	Used to supersede an OSSEC rule with local changes.
			yes,no
	noalert		Not trigger any alert if the rule matches.
			no value
---	match	any sregex expression
---	regex	--||--
---	decoded_as
---	category	decoded category to match: ids,syslog,firewall, web-log,squid or windows.
---	field		any regex to be compared to a field extracted by the decoder.
---	srcip		any ip address or CIDR block to be compared to an IP decoded as srcip. ! - negate it
---	dstip		--||--
---	extra_data	any string that is decoded into the extra_data field
---	user		any sregex expression
---	program_name	any sregex expression
---	hostname	any hostname (decoded as the syslog hostname) or log file.
---	time		any time range (hh:mm-hh:mm)
---	weekday		monday-sunday,weekdays,weekends
---	id 		any ID (decoded as the ID).
---	url		any URL (decoded as the URL).
---	if_sid		Matches if the ID has matched.
---	if_group	Matches if the group has matched before.
---	if_level	Matches if the level has matched before.
---	if_matched_sid	Matches if an alert of the defined ID has been triggered in a set nember of seconds.
			This option in conjunction with frequency and timeframe.
			Note
			Rules at level 0 are discarded immediately and will not be used with the if_matched_rules.The level must be at least 1, but the <no_log> option can be added to the rule to make sure it does not get logged.
---	if_matched_group	Matches if an alert of the defined group has been triggered in a set 
				number of seconds.
				in conjunction with frequency and timeframe.
---	same_id			Specifies that the decoded id must be the same. This option is used 
				with freq and timeframe.
---	same_source_ip		decoded source ip must be the same.used with freq and timeframe.
---	same_src_port		srcport must be the same.
---	same_dst_port		dstport must be the same. frq and timeframe needed.
---	same_location		location must be the same.freq and timeframe needed.
---	same_user		decoded user must be the same.--||--
---	different_url		url must be different.--||--
---	different_srcgeoip	src geoip location must be different.--||--
---	description		rule description.
---	list			perform a CDB lookup using an ossec list. This is a fast on disk database which will always find keys within two seeks of the file.
		Attribute:
			field 	key in the CDB:srcip,srcport,dstip,dstport,extra_data,user,url,id , hostname,program_name,status,action,dynamic field.
			lookup	match_key	- key to serch
				not_match_key key to search and will match if it is not present in the database.
				match_key_value - searched for in the cdb. it will be compared with regex from attribute check_value.
				address_match_key - IP and the key to search within the cdb and will match if they key is present.
				not_address_match_key - IP the key to search and will match if it IS NOT present in the database
				address_match_key_value - IP to search in the cdb. it will be compared with regex from attribute check_value.
			check_value	regex for matching on the value pulled out of the cdb when using types:address_matcch_key_value,match_key_value


--- info	Extra information may ne added through the following attributes:
		type:
			text	def when no type is selected . Additional, information about
			link	Link to more information about the alert/event.
			cve	The CVE Number related to this a/e
			ovsdb	The osvdb id related to this a/e.
--- options	Used one <options> tag for each option you want to add.
		alert_by_email
		no_email_alert	never allert by email.
		no_log 		do not log this alert
		no_full_log 	Do not include the full_log field in the alert.
		no_counter	Omit field rule.firedtimes in the JSON alert.
--- check_diff	Used to determine when the output of a command changes.
--- group	add additional groups to the alert.Are optional tags added to alerts.

==========		Regular Expression Syntax
There are two types of regular expressions:	regex - OS_Regex and sregex (OS_Match)
---		Regex (OS_Regex) syntax
This is a fast and simple library for regular expressions in C.
This library is designed to be simple while still supporting the most common regular expressions.
Supported expressions

Expressions	Valid characters
\w	A-Z, a-z, 0-9, ‘-‘, ‘@’, ‘_’ characters
\d	0-9 character
\s	Spaces ” “
\t	Tabs
\p	()*+,-.:;<=>?[]!”’#$%&|{}
\W	Anything not w
\D	Anything not d
\S	Anything not s
\.	Anything

Modifiers
+ To match one or more times
* To match zero or more times

- Special characters
Expressions	Actions
^	To specify the beginning of the text
$	To specify the end of the text
|	To create a logical or between multiple patterns

- Characters escaping
To utilize the following characters they must be escaped with: \
$	(	)	\	|	<
\$	\(	\)	\ \	\|	\<

-------		Sregex (OS_Match) syntax
This is faster than OS_Regex, but only supports simple string matching and the following special characters.

Special characters.
Expressions	Actions
^	To specify the beginning of the text
$	To specify the end of the text
|	To create a logic: or, between multiple patterns

===========		Testing decoders and rules
The tool ossec-logtest allow us to test how an event is decoded and if an alert is generated.
bin/ossec-logtest run and paste the following log:

	To show more info you can use -v option.
bin/ossec-logtest -v

==========		Using CDB lists
---	Wazuh is able to check if a field extrxted during the decoding phase is in a CDB list (constant database) . The main use case of this feature is to create a white/black list of users,IPs or domain names.
---	Creating a CDB list
This list file is a plain text file whereeach line has the following format:
key:value1
key2:value2

Each key must be unique and is terminated with a colon : .
For IP addresses the dot notation is used for subnet matches:
key	CIDR	Possible matches
192.168.:	192.168.0.0/16	192.168.0.0-192.168.255.255
172.16.19.:	172.16.19.0/24	172.16.19.0-172.16.19.255
10.1.1.1:	10.1.1.1/32	10.1.1.1

Ex of IP address list file:
192.168.: Matches 192.168.0.0 - 192.168.255.255
172.16.19.: Matches 172.16.19.0 - 172.16.19.255
10.1.1.1: Matches 10.1.1.1

---	Recommendation to store the lists on /var/ossec/etc/lists

---	Adding the list to ossec.conf
Each list must be defined in the ossec.conf file using the following syntax:
<ossec_config>
  <releset>
    <list>etc/lists/list-IP</list>

! Warn : The <list> setting uses a relative path to the Wazuh installation folder (/var/ossec/) so make sure to indicate the directory accordingly.

service wazuh-manager restart

---	Making the CDB list
THE LIST FILES MUST Be compiled before they can be used. The tool /var/ossec/bin/ossec-makelists
will process and compile all the lists if needed.

Remember to compile the lists every time that you update them . It is necessary to restart Wazuh to apply the changes.


---	Using the CDB list in the rules.
A rule would use the following syntax to look up a key within a CDB list.
---	Positive key match
This example is a search for the key stored in the field attribute and will match if it IS present in the database:
<list field="user" lookup="match_key">etc/lists/list-usr</list>

The lookup="match_key" is the default and can be left out as in this example:
<list field="user">etc/lists/list-user</list>

In case the field is an IP adress, you must to use address_match_key:
<list field="srcip" lookup="address_match_key">etc/lists/list-IP</list>

---	Negative key match
This example is a search for the key stored in the field attribute and will match if it IS NOT present in the database:
<list field="user" lookup="not_match_key">etc/lists/list-user</list>
In case the field is an IP address, you must use not_address_match_key:
<list field="srcip" lookup="not_address_match_key">etc/lists/list-IP</list>

---	Key and value match
This example is asearch for the key stored in the field attribute, and on  a positive match the returned value of the key will be processed using the regex in the check_value attribute:
<list field="user" lookup="match_key_value" vheck_value="^block">etc/lists/list-user</list>
In case the field i an IP address,you must use not_address_match_key:
<list field="srcip" lookup="address_match_key_value" check_value="^reject">etc/lists/list-IP</list>


=======		Contribute to the ruleset
In our repository you will find that most of the rules contain one or more groups called pci_dss_X
This is the PCI DSS control related to the rule. We have produced a document that can help you tag each rule with its corresponding PCI requirement: PCI tagging.

========		RESTful API
RA is an open source RESTful API that allows for interaction with the Wazuh manager from a web browser, command line tool like cURL or any script or program that can make web requests. The Wazuh Kibana app relies on this heavily and Wazuh's goal is to accommodate complete remote management of the Wazuh infrrastructure via the Wazuh Kibana app. Use the API to easily perform everyday actions like adding an agent, restarting the manager(s) or agent(s) or looking up syscheck details.


Wazuh API capabilities:
- Agent management
- Manager control & overiew
- Rootcheck control & search
- Syscheck control & serch
- Ruleset information
- Statistical information
- HTTPS and user authentication
- Error handling
- Query remote configuration


-------		Start
1. start/stop/restart
service wazuh-api start/status/stop/restart

2. Basic
The base URL for each request is https://IP:55000/ or http://IP:55000/, depending on whether or not SSL is enabled and set up in the API.
All responses are in JSON format with the following structure:

Field	Description
error	0 if everything was fine and an error code otherwise.
data	The data requested. Only if error is equal to 0.
message	The error description. Only if error is other than 0.

Responses containing collections of data will return a maximum of 500 elements. The offset and limit parameters may be used to iterate through large collections.
All responses have an HTTP status code: 2xx (success), 4xx (client error), 5xx (server error), etc.
All requests accept the parameter pretty to convert the JSON response to a more human-readable format.
The API log is stored on the manager as /var/ossec/logs/api.log. The API logs are rotated daily. The rotations are stored in /var/ossec/logs/api/<year>/<month> and compressed using gzip.
All API requests will be aborted if no response is received after a certain amount of time. The parameter wait_for_complete can be used to disable this timeout. This is useful for calls that could take more time than expected, such as PUT/agents/:agent_id/upgrade.

------		Use cases
---	Exploring the ruleset 
Often when an alert fires, it is helpful to know details about the rule itself. The following request enumerates the attibutes of rule 1002:
curl -u foo:bar -k -X GET "https://localhost:55000/rules/1002?pretty"

It can also be helpful to know what rules are available that match a specific criteria. For eample, all the rules with a group of web, a PCI tag of 10.6.1, and containing the word failures can be showed using the command bellow:
curl -u foo:bar -k -X GET "https://localhost:55000/rules?group=web&pci=10.6.1&search=failures&pretty"

---		Mining the file integrity monitoring database of an agent
The API can be used to show information about all monitored files by syscheck. The following exam
ple shows all modified .py files in agent 000(the manager):

curl -u foo:bar -k -X GET "https://localhost:55000/syscheck/000?event=modified&search=.py&pretty"
not working
You can find a file using its md5/sha1 hash. In the following wxamples, the same file is retrieved using both its md5 and sha1:

curl -u foo:bar "http://localhost:55000/syscheck/000?pretty&hash=17f51705df5b61c53ef600fc1fcbe031e4d53c20"

curl -u foo:bar "http://localhost:55000/syscheck/000?pretty&hash=39b88ab3ddfaf00db53e5cf193051351"

---	Listing outstanding rootcheck issues
Rootcheck requests are very similar to the syscheck requests. In order to gt all rootcheck issues with the outstanding status, run this request:

curl -u foo:bar "http://localhost:55000/rootcheck/000?status=outstanding&offset=10&limit=1&pretty"

---	Getting information about the manager
Some information about the manager can be retrieved using the API. Configuration, status, information,logs,etc. The following example retrieves the status of each daemon Wazuh runs:
curl -u foo:bar -k -X GET "https://localhost:55000/manager/status?pretty"

You can even dump the manager's current configuration with the request bellow (response shortened for brevity):

---
curl -u foo:bar -k -X GET "https://localhost:55000/manager/configuration?pretty"

---	Playing with agents
Here are some commands for working with the agents.
This enumerates active agents:
curl -u foo:bar -k -X GET "https://localhost:55000/agents?offset=1&limit=1&status=active&pretty"

---	Adding an agent is now easier than ever. Simply send arequest with the agent name and its IP.
curl -u foo:bar -k -X POST -d '{"name":"NewHost","ip":"10.0.0.9"}' -H 'Content-Type:application/json' "https://localhost:55000/agents?pretty"

----	Conclusion
We hope those examples have helped you to appreciate the potential ofthe Wazuh API.Remember to check out the reference document to discover all the available API requests . A nice summary can also be found here: https://documentation.wazuh.com/current/user-manual/api/reference.html#request-list

==========	Filtering data using queries
Advance filtering is possible using the Wazuh API's queries. Queries are specified using the q parameter. A query has the following structure:

. Field name: Field name to filter by. If an incorrect field name is used , anerror will be raised.
. Operator: Operator to filter by:
 - =: equality.
 - != : not equality 
 - <: smaller
 - >: bigger
 - ~: like as
.Value: Value to filter by.
.Separator: Operator to join multiple "queries":
 - ,: represents an OR.
 - ;: represents an AND.
Ex
Filtering agents by OS name and OS version
 For example, to filter Ubuntu agents with a version higher than 12:

curl -u foo:bar -k -X GET "https://localhost:55000/agents?pretty&q=os.name=ubuntu;os.version>12&select=id,name,os.name,os.version,os.codename,os.major"

---	Filtering rootcheck events by date
curl -u foo:bar -X GET "https://loclhost:55000/rootcheck/001?pretty&q=oldDay<3h25m&limit=2"

---------		Configuration
The API will bind to port 55000/tcp by default and requires userbane and password authentication. The default username and password is "foo" and "bar".
---	Configuration script
Run the script /var/ossec/api/scripts/configure_api.sh to configure the basic settings.

The script supports both unattended and attended configuration. To set the parameters of the unattended configuration use the file /var/ossec/api/configuration/preloaded_vars.conf.
This file will be removed after running the script to remove any sensitive information written there.

---	Configuration file 
You can configure certain API settings in the file /var/ossec/api/configuration/config.js

// Path 
config.ossec_path = "/var/ossec";
//The host to bind the API to.
config.host = "0.0.0.0";
// TCP Port used by the api.
CONFIG.PORT = "55000";
// USE http PROTOCOL over TLS/SSL. Values: yes, no.
config.https = "yes";
//Use HTTP authentication . Values: yes, no.
config.basic_auth = "yes";
// In case the API run behind a proxy server, turn to "yes" this feature. Values: yes, no.
config.BehindProxyServer = "no";

service wazuh-api restart

--- Basic Authentication
It is generally recommended that new credentials be created to replace foo:bar. This can be done very easily with the following steps, substituting your desired username for myUserName:


cd /var/ossec/api/configuration/auth
node htpasswd -c user myUserName
service wazuh-api restart

---	Manually enablee https support

cd /var/ossec/api/configuration/ssl
openssl genrsa -des3 -out server.key 1024
openssl req -new -key server.key -out server.csr

By default , the key's password must be entered every time you run the server. If you don't want to enter the password every time, you can remove it by running these commands:

cp server.key server.key.org
openssl rsa -in server.key.org -out server.key

- Next generate uour self-signed certificate:
opnssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt

----------		Reference
This API reference is organized by resources:
- Active Response
- Agents
- Cache
- Ciscat
- Cluster
- Decoders
- Experimental
- Manager
- Rootcheck
- Rules
- Syscheck
- Syscollector

---------		Request List
- Active Response
	PUT /active-response/:agent_id (Run an AR command in the agent)

- Agents
DELETE /agents (Delete agents)
DELETE /agents/:agent_id (Delete an agent)
DELETE /agents/:agent_id/group (Remove all agent groups.)
DELETE /agents/:agent_id/group/:group_id (Remove a single group of an agent)
DELETE /agents/groups (Delete a list of groups)
DELETE /agents/groups/:group_id (Remove group)
GET /agents (Get all agents)
GET /agents/:agent_id (Get an agent)
GET /agents/:agent_id/config/:component/:configuration (Get active configuration)
GET /agents/:agent_id/group/is_sync (Get sync status of agent)
GET /agents/:agent_id/key (Get agent key)
GET /agents/:agent_id/upgrade_result (Get upgrade result from agent)
GET /agents/groups (Get groups)
GET /agents/groups/:group_id (Get agents in a group)
GET /agents/groups/:group_id/configuration (Get group configuration)
GET /agents/groups/:group_id/files (Get group files)
GET /agents/groups/:group_id/files/:filename (Get a file in group)
GET /agents/name/:agent_name (Get an agent by its name)
GET /agents/no_group (Get agents without group)
GET /agents/outdated (Get outdated agents)
GET /agents/stats/distinct (Get distinct fields in agents)
GET /agents/summary (Get agents summary)
GET /agents/summary/os (Get OS summary)
POST /agents (Add agent)
POST /agents/insert (Insert agent)
POST /agents/restart (Restart a list of agents)
PUT /agents/:agent_id/group/:group_id (Add agent group)
PUT /agents/:agent_id/restart (Restart an agent)
PUT /agents/:agent_id/upgrade (Upgrade agent using online repository)
PUT /agents/:agent_id/upgrade_custom (Upgrade agent using custom file)
PUT /agents/:agent_name (Add agent (quick method))
PUT /agents/groups/:group_id (Create a group)
PUT /agents/restart (Restart all agents)
Cache
DELETE /cache (Clear group cache)
DELETE /cache (Delete cache index)
GET /cache (Get cache index)
GET /cache/config (Return cache configuration)
Ciscat
GET /ciscat/:agent_id/results (Get CIS-CAT results from an agent)
Cluster
GET /cluster/:node_id/configuration (Get node node_id’s configuration)
GET /cluster/:node_id/info (Get node_id’s information)
GET /cluster/:node_id/logs (Get ossec.log from a specific node in cluster.)
GET /cluster/:node_id/logs/summary (Get summary of ossec.log from a specific node in cluster.)
GET /cluster/:node_id/stats (Get node node_id’s stats)
GET /cluster/:node_id/stats/hourly (Get node node_id’s stats by hour)
GET /cluster/:node_id/stats/weekly (Get node node_id’s stats by week)
GET /cluster/:node_id/status (Get node node_id’s status)
GET /cluster/config (Get the cluster configuration)
GET /cluster/healthcheck (Show cluster health)
GET /cluster/node (Get local node info)
GET /cluster/nodes (Get nodes info)
GET /cluster/nodes/:node_name (Get node info)
GET /cluster/status (Get info about cluster status)
Decoders
GET /decoders (Get all decoders)
GET /decoders/:decoder_name (Get decoders by name)
GET /decoders/files (Get all decoders files)
GET /decoders/parents (Get all parent decoders)
Experimental
DELETE /experimental/syscheck (Clear syscheck database)
GET /experimental/ciscat/results (Get CIS-CAT results)
GET /experimental/syscollector/hardware (Get hardware info of all agents)
GET /experimental/syscollector/netaddr (Get network address info of all agents)
GET /experimental/syscollector/netiface (Get network interface info of all agents)
GET /experimental/syscollector/netproto (Get network protocol info of all agents)
GET /experimental/syscollector/os (Get os info of all agents)
GET /experimental/syscollector/packages (Get packages info of all agents)
GET /experimental/syscollector/ports (Get ports info of all agents)
GET /experimental/syscollector/processes (Get processes info of all agents)
Manager
GET /manager/configuration (Get manager configuration)
GET /manager/info (Get manager information)
GET /manager/logs (Get ossec.log)
GET /manager/logs/summary (Get summary of ossec.log)
GET /manager/stats (Get manager stats)
GET /manager/stats/analysisd (Get analysisd stats)
GET /manager/stats/hourly (Get manager stats by hour)
GET /manager/stats/remoted (Get remoted stats)
GET /manager/stats/weekly (Get manager stats by week)
GET /manager/status (Get manager status)
Rootcheck
DELETE /rootcheck (Clear rootcheck database)
DELETE /rootcheck/:agent_id (Clear rootcheck database of an agent)
GET /rootcheck/:agent_id (Get rootcheck database)
GET /rootcheck/:agent_id/cis (Get rootcheck CIS requirements)
GET /rootcheck/:agent_id/last_scan (Get last rootcheck scan)
GET /rootcheck/:agent_id/pci (Get rootcheck pci requirements)
PUT /rootcheck (Run rootcheck scan in all agents)
PUT /rootcheck/:agent_id (Run rootcheck scan in an agent)
Rules
GET /rules (Get all rules)
GET /rules/:rule_id (Get rules by id)
GET /rules/files (Get files of rules)
GET /rules/gdpr (Get rule gdpr requirements)
GET /rules/groups (Get rule groups)
GET /rules/pci (Get rule pci requirements)
Syscheck
DELETE /syscheck/:agent_id (Clear syscheck database of an agent)
GET /syscheck/:agent_id (Get syscheck files)
GET /syscheck/:agent_id/last_scan (Get last syscheck scan)
PUT /syscheck (Run syscheck scan in all agents)
PUT /syscheck/:agent_id (Run syscheck scan in an agent)
Syscollector
GET /syscollector/:agent_id/hardware (Get hardware info)
GET /syscollector/:agent_id/netaddr (Get network address info of an agent)
GET /syscollector/:agent_id/netiface (Get network interface info of an agent)
GET /syscollector/:agent_id/netproto (Get network protocol info of an agent)
GET /syscollector/:agent_id/os (Get os info)
GET /syscollector/:agent_id/packages (Get packages info)
GET /syscollector/:agent_id/ports (Get ports info of an agent)
GET /syscollector/:agent_id/processes (Get processes info)


---------		Python
You can also interact with the API using Python as shown below:
Code:
#!/usr/bin/env python
import json
import requests # to install requests, use: pip install requests

#Configuration
base_url = 'https://localhost:55000'
auth = requests.auth.HTTPBasicAuth('foo','bar')
verify = False
requests.packages.urllib3.disable_warnings()

# Request
url = '{0}{1}'.format(base_url, "/agents/000")
r = requests.get(url, auth=auth, params=None, verify=verify)
print(json.dumps(r.json(), indent=4, sort_keys=True))
print("status: {0}.format(r.status_code))


==============		Kibana app
==============
==============
The Wazuh app for Kibana lets you visualize and analyze Wazuh alerts stored in Elasticsearch. You can 
obtain statistics per agent, search alerts and filter using different visualizations. It integrates
with the Wazuh API to retrieve information about manager and agents configuration, logs, ruleset, groups and much more.

To install the app, you can follow our Elastic Stack installation guides (for Debian systems:https://documentation.wazuh.com/current/installation-guide/installing-elastic-stack/elastic_server_deb.html#install-kibana-app-deb )

This manual describes the configuration process to get it started and the different app features that you can use. In addition to this, you can find a troubleshooting and reference guide for quick access
 to some key solutions and configuration options.

---	Setting up the app
register the Wazuh RESTful API with the Wazuh app in Kibana:
1. 

==========	Kibana app
----------	Configuration file
The Wazuh app includes a configuration file 
/usr/share/kibana/plugins/wazuh/config.yml

----------	Basic option
def ind to use on the app. If there's no valid index patterns on Elasticsearch, the app will automatically create one with the name indicated in this option.
- def wazuh-alerts-3.x-*

--- timeout
max time the app will wait for an API response when making requests to it. It will be ignored if the value is set under 1500 milliseconds.
-def 8000

--- ip.selector
defines if the user is allowed to change the selected index pattern directly from the top menu bar.
- def true

--- ip.ignore
Disable certain index pattern names from neing available in index pattern selector from the Wazuh app. An empty list (the def value ) won't ignore any valid index pattern.
-def []
-allowed values: Array of strings. Eg:["wazuh-archives-*"]

--- xpack.rbac.enabled
en or disable x-pack RBAC security capabilities when using the app.

--- admin
en or dis adimn requests to the Wazuh API when using the app. This makes PUT, POST and DELETE requests available on the Dev tools tab.
- def: true

--- Monitoring
- wazuh.monitoring.enabled : true
en or dis the wazuh-monitoring index creation and/or visualization:
	. if true, the app will show the agents status visualization and will insert monitoring-related data.
	. if false, the app won't show the visualization and won't insert monitoring-related data.
	. if set to worker, the app will show the visualization, but won't insert monitoring- related data.

- wazuh.monitoring.frequency: 3600 ( any from 60 sec )
in seconds the app generates a new document on the wazuh-monitoring index.

--- Checks
- checks.pattern: true
en or dis the index pattern health check when opening the app.

- checks.template: true
template health check when opening the app

- checks.api : true
pai health check when opening the app.

- checks.setup : true
setup health check when opening the app.

-----	Extensions ( applied for newly inserted APIs on the Settings tab, not for the existing ones.

- extensions.pci : true
PCI DSS tab on Overview and agents

- extensions.gdpr: true
GDPR tan on Overview and Agents.

- extensions.audit: true
Audit tab on Overview and Agents.

- extensions.oscap: true
Open SCAP tab on Overview and Agents.

- extensions.ciscat: false
CIS-CAT tab on Overview and Agents.

- extensions.aws : false
AWS tab on Overview and Agents.

- extensions.virustotal: false
VirusTotal tab on Overview and Agents.

- extensions.osquery : false
Osquery tab on Overview and Agents.

--- Advanced index options. Calid if modified before starting the Kibana service for the very first time. (shards and replicas)
- wazuh.shards:1
starting from 1

- wazuh.replicas : 1
from 0

- wazuh-version.shards: 1
munber of shards to use for the wazuh-version index.
any from 1

- wazuh-version.replicas : 1
for the wazuh-version index

- wazuh.monitoring.shards: 5
mun of shards to use for the wazuh-monitoring-3.x-* indices.

- wazuh.monitoring.replicas: 1
number of replicas to use for the wazuh-monitoring-3.x-* indices.









































