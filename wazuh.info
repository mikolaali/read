1514	Wazuh UDP
1515	Wazuh TCP
514	Wazuh UDP
55000	Wazuh API
5000	Logstash TCP input
9200	Elasticsearch HTTP
9300	Elasticsearch TCP transport
5601	Kibana

Integration 
Slack  -mini chat --good  - $
Pagerduty  -- msg routing to different sd team
VirusTotal -- check , if syscheck alerts comes


----- configuring syslog output
<server>IP</server>

/var/ossec/bin/ossec-control enable client-syslog
service wazuh-manager restart


------- Generating automatic reports
every day configure
<ossec_config>
  <reports>
      <category>syscheck</category>
      <title>Daily report: File changes</title>
      <email_to>example@test.com</email_to>
  </reports>
</ossec_config>

<ossec_config>
  <reports>
      <level>10</level>
      <title>Daily report: Alerts with level higher than 10</title>
      <email_to>example@test.com</email_to>
  </reports>
</ossec_config>

------ email notification
<ossec_config>
    <global>
        <email_notification>yes</email_notification>
        <email_to>me@test.com</email_to>
        <smtp_server>mail.test.com..</smtp_server>
        <email_from>wazuh@test.com</email_from>
    </global>
    ...
</ossec_config>

# apt-get install postfix mailutils libsasl2-2 ca-certificates libsasl2-modules
/etc/postfix/main.cf
relayhost = [smtp.gmail.com]:587
smtp_sasl_auth_enable = yes
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtp_sasl_security_options = noanonymous
smtp_tls_CAfile = /etc/ssl/certs/thawte_Primary_Root_CA.pem
smtp_use_tls = yes

# echo [smtp.gmail.com]:587 USERNAME@gmail.com:PASSWORD > /etc/postfix/sasl_passwd
# postmap /etc/postfix/sasl_passwd
# chmod 400 /etc/postfix/sasl_passwd

# chown root:root /etc/postfix/sasl_passwd /etc/postfix/sasl_passwd.db
# chmod 0600 /etc/postfix/sasl_passwd /etc/postfix/sasl_passwd.db

 systemctl reload postfix

 echo "Test mail from postfix" | mail -s "Test Postfix" -r "you@example.com" you@example.com

Configure Wazuh in the /var/ossec/etc/ossec.conf as follows:

<global>
  <email_notification>yes</email_notification>
  <smtp_server>localhost</smtp_server>
  <email_from>USERNAME@gmail.com</email_from>
  <email_to>you@example.com</email_to>
</global>


---------- agent installation and configure  - ------------
# /var/ossec/bin/agent-auth -m 192.168.1.2
vim /Library/Ossec/etc/ossec.conf
<server>10.245.0.46</server>

Otherwise, you can create a self-signed certificate:
openssl req -x509 -batch -nodes -days 365 -newkey rsa:2048 -keyout /var/ossec/etc/sslmanager.key -out /var/ossec/etc/sslmanager.cert

/var/ossec/bin/ossec-authd

agent:
/var/ossec/bin/agent-auth -m server_IP

If you want to add agents with a dynamic IP address (like using any on manage_agents) you must change etc/ossec.conf on the server-side:

(Manager)

<auth>
    <use_source_ip>no</use_source_ip>
</auth>

Launching the authd daemon with default options would allow any agent to register itself, and then connect to a manager. The following options provide some mechanisms to authorize connections:

Use a password to authorize agents  -----------
# echo "TopSecret" > /var/ossec/etc/authd.pass
  # /var/ossec/bin/ossec-authd -P

If you don’t specify a password, then authd will create a password itself and tell you what it is:

(Manager)

  # /var/ossec/bin/ossec-authd -P

(Agent)

# /var/ossec/bin/agent-auth -m 192.168.1.2 -P "abcd1234"

Use SSL to verify hosts
First we are going to create a certificate of authority (CA) that we will use to sign the certificates for the manager and agents. Hosts will receive a copy of this certificate in order to verify the remote certificate:

# openssl req -x509 -new -nodes -newkey rsa:2048 -keyout rootCA.key -out rootCA.pem -batch -subj "/C=US/ST=CA/O=Manager"

Verify manager via SSL
Issue and sign a certificate for the authd server, entering the hostname or the IP address that agents will use to connect to the server. For example, if the server’s IP is 192.168.1.2:

# openssl req -new -nodes -newkey rsa:2048 -keyout sslmanager.key -out sslmanager.csr -subj '/C=US/CN=192.168.1.2'
# openssl x509 -req -days 365 -in sslmanager.csr -CA rootCA.pem -CAkey rootCA.key -out sslmanager.cert -CAcreateserial

Copy the newly created certificate and the key to the manager’s etc folder and start ossec-authd:

(Manager)

# cp sslmanager.cert sslmanager.key /var/ossec/etc
# /var/ossec/bin/ossec-authd
Copy the CA (but not the key) to the agent’s etc folder and run agent-auth:

(Agent)

# cp rootCA.pem /var/ossec/etc
# /var/ossec/bin/agent-auth -m 192.168.1.2 -v /var/ossec/etc/rootCA.pem

Verify agents via SSL (no host validation)

In this example, we are going to create a certificate for agents without specifying their hostname, so that the same certificate can be used by many agents. This verifies that agents have a certificate signed by our CA, no matter where they are connecting from.

Issue and sign a certificate for the agent. Note that we will not enter the common name field:
# openssl req -new -nodes -newkey rsa:2048 -keyout sslagent.key -out sslagent.csr -batch
# openssl x509 -req -days 365 -in sslagent.csr -CA rootCA.pem -CAkey rootCA.key -out sslagent.cert -CAcreateserial

Copy the CA (but not the key) to the manager’s etc folder (if not already there) and start ossec-authd:
(Manager)

# cp rootCA.pem /var/ossec/etc
# /var/ossec/bin/ossec-authd -v /var/ossec/etc/rootCA.pem
Copy the newly created certificate and key to the agent’s etc folder and run agent-auth. For example, if the server’s IP is 192.168.1.2:
(Agent)

# cp sslagent.cert sslagent.key /var/ossec/etc
# /var/ossec/bin/agent-auth -m 192.168.1.2 -x /var/ossec/etc/sslagent.cert -k /var/ossec/etc/sslagent.key

Verify agents via SSL (host validation)

This is an alternative method to the last section. In this case, we will bind the agent’s certificate to the agent IP address as seen by the manager.

Issue and sign a certificate for the agent. Then enter its hostname or IP address into the common name field. For example, if the agent’s IP is 192.168.1.3:
# openssl req -new -nodes -newkey rsa:2048 -keyout sslagent.key -out sslagent.csr -subj '/C=US/CN=192.168.1.3'
# openssl x509 -req -days 365 -in sslagent.csr -CA rootCA.pem -CAkey rootCA.key -out sslagent.cert -CAcreateserial

(Manager)

# cp rootCA.pem /var/ossec/etc
# /var/ossec/bin/ossec-authd -v /var/ossec/etc/rootCA.pem -s
Copy the newly created certificate and key to the agent’s etc folder and run agent-auth. For example, if the server’s IP is 192.168.1.2:
(Agent)

# cp sslagent.cert sslagent.key /var/ossec/etc
# /var/ossec/bin/agent-auth -m 192.168.1.2 -x /var/ossec/etc/sslagent.cert -k /var/ossec/etc/sslagent.key

---------------  Register Agent useng command line ----------------
On the manager, run manage_agents:
# /var/ossec/bin/manage_agents
Now on the agent run manage_agents:
# /var/ossec/bin/manage_agents
Select I to import a key and paste in the key that you extracted on the manager:

Choose your action: I or Q: I
service wazuh-agent restart

in case of reinstalling Manager Server
/var/ossec/bin/manage_agents -n Server1 -a 10.10.10.10 -F 0

----------  Listing Agents ----------

The binary /var/ossec/bin/agent_control allows for the retrieval of a list of the available agents:

# /var/ossec/bin/agent_control -l

----------  Remove agent -----------
/var/ossec/bin/manage_agents
R
001

or 
with no confirmation
/var/ossec/bin/mamage_agents -r 001

--------  RestFull API 
# curl -u foo:bar -X POST -d 'name=NewAgent&ip=10.0.0.8' "http://localhost:55000/agents"
{"error":0,"data":"001"}
Step 2: Get the agent key.

# curl -u foo:bar -X GET "http://localhost:55000/agents/001/key"
{"error":0,"data":"MDAxIE5ld0FnZW50IDEwLjAuMC44IDM0MGQ1NjNkODQyNjcxMWIyYzUzZTE1MGIzYjEyYWVlMTU1ODgxMzVhNDE3MWQ1Y2IzZDY4M2Y0YjA0ZWVjYzM="}

Step 3: Copy the key to the agent.

# /var/ossec/bin/manage_agents -i MDAxIE5ld0FnZW50IDEwLjAuMC44IDM0MGQ1NjNkODQyNjcxMWIyYzUzZTE1MGIzYjEyYWVlMTU1ODgxMzVhNDE3MWQ1Y2IzZDY4M2Y0YjA0ZWVjYzM=

service wazuh-agent restart 

-------- Listing agents
# curl -u foo:bar "http://localhost:55000/agents?pretty"
/var/ossec/bin/agent_control -l

-------- Remove agent
# curl -u foo:bar -X DELETE "http://localhost:55000/agents/002"
/manage_agents
R

-----		grouping agents		--------------
serving agent's configs
/var/ossec/etc/shared/default/

once an agent has benn added to the manager ,assign it to a group using 
/var/ossec/bin/agent_groups -a -i 002 -g dbms  # for example

Using the API:
curl -u foo:bar -X PUT "http://localhost:55000/agents/002/group/dbms?pretty"
The group must be created before.

To check use
/var/ossec/bin/agent_groups -l -g dbms
or
curl -u foo:bar -X GET "http://localhost:55000/agents/groups/dbms?pretty"

After creating group, its agent.conf file can be edited to include the specific configuration you want assign to this group.
/var/ossec/etc/shared/dbms/agent.conf each agent which belong to this group will receive this file

Multiple groups

New in version 3.7.0.

Since Wazuh v3.7.0, agents have the ability to belong to multiple groups. The agents will receive all the configuration files from each group. Configuration received from the last assigned group has more priority than the other ones.

With the agent_groups CLI, agents can be registered to groups on the same way:

$ /var/ossec/bin/agent_groups -a -i 001 -g webserver
$ /var/ossec/bin/agent_groups -a -i 001 -g apache
Do you want to add the group 'apache' to the agent '001'? [y/N]: y

# /var/ossec/bin/agent-auth -m MANAGER_IP -G webserver,apache  

------	Listing groups and configuration	------------
/var/ossec/bin/agent_groups -l -g webserver

which groups assigned to agent
/varossec/bin/agent_groups -s -i 001

-----  Making changes ---------
/var/ossec/bin/agent_groups -r -i 001 -g apache -q
/var/ossec/bin/agent_groups -s -i 001   # list groups

--------  synchronization status of the group configuration for a single agent:
/bin/agent_groups -S -i 001
curl -u foo:bar -X GET "http://localhost:55000/agents/001/group/is_sync?pretty"

======  Agent updating  ========
agent_upgrade -l
agent_upgrade -a 002

agent_control -i 002

Using the RESTful API
curl -u foo:bar -X GET "http://localhost:55000/agents/outdated?pretty"

curl -u foo:bar -X PUT "http://localhost:55000/agents/002/upgrade?pretty"

Check the upgrade result:
curl -u foo:bar -X GET "http://localhost:55000/agents/002/upgrade_result?pretty"

curl -u foo:bar -X GET "http://localhost:55000/agents/002?pretty"

=========  Adding a custom repository  ==========

=========	LOG COLLECTION		=========
---- Log files
<localfile>
	<location>/var/log/example.log</location>
	<log_format>syslog</log_format>
</localfile>

Windows:
<localfile>
	<location>C:\mysqpp\example.log</location>
	<log_format>syslog</log_format>
</localfile>
Windows event logs
Event log:
<localfile>
	<location>Security</location>
	<log_format>eventlog</log_format>
</localfile>
Event channel:
<localfile>
	<location>Microsoft-Windows-PrintService/Operational</location>
	<log_format>eventchannel</log_format>
</localfile>

Remote syslog
<ossec_config>
	<remote>
		<connection>syslog</connection>
		<allowed-ips>192.168.2.0/24</allowed-ips>
	</remote>
<ossec_config>

==========	ANALYSIS	==============
1) Pre-decoding
Phase of analysis ,static info from well-known fields

2) Decoding
Here log message is evaluated to identify what type of log it is and known fields for that specific log type are then extrated.

prg name
dstuser
srcip

3) Rule matching
extrcted log information is compared to the ruleset to look for matches
ex:

<rule id="5715" level="3">
	<if_sid>5700</if_sid>
	<match>^Accepted|authenticated.$</match>
	<description>sshd: authentication success.</description>
	<group>authentication_success.pci_dss_10.2.5.</group>
</rule>

=======		ALERT		==========
Once a rule is matched, the manager will create an alert as below:

To store all events even if they do not match a rule, enable the <log_all> option.
Alerts will be stored at /var/ossec/logs/alerts/alerts.(json|log) and events at /var/ossec/logs/archives/archives.(json|log). Logs are rotated and an individual directory is created for each month and year.

Archived logs are not automatically deleted by default. You can choose when to manually or automatically (e.g., cron job) delete logs according to your own legal and regulatory requirements.

=======		CONFIGURATION		==========
Basic usage
Log data collection is configured in the ossec.conf file primarily in the localfile, remote and gloval sections.
Configuration of log data collecion can also be completed in the agent.conf file to centralize the distribution of these configuration settings to relevant agents.

ex:

<localfile>
	<location>/var/log/messages</location>
	<log_format>syslog</log_format>
</localfile>

---------	Monitoring logs using regular expressions for file names

posix regular expressions.

<localfile>
	<location>/var/log/*.log</location>
	<log_format>syslog</log_format>
</localfile>

---------	Monitoring date-based logs
For log files that change according to the date , you can also specify a strftime format to replace the day,month, year,etc.
For example, to monitor the log files like log-08-12-15.log, 
<localfile>
	<location>c:\log-%y-%m-%d.log</location>
	log_format>syslog</log_format>
</localfile>

-----------	Reading events from Windows Event Channel
The location is the name of the event channel.
This is the only way to monitor the Applications and Services logs. If the file name contains a%, replace it with "/":
<localfile>
	<location>Microsoft-PrintService/Operational</location>
	<log_format>eventchannel<\log_format>
</localfile>


-----------	Filtering events from Windows Event Channel with queries
<localfile>
	<location>System</location>
	<log_formaat>eventchannel</log_format>
	<query>Event/System[EventID=7040]</query>
</localfile>

---------	Using environment variables
Ex reading logs from an IIS server:
<localfile>
	<location>%Windir%\System32\LogFiles\W3SVC3\ex%y$m$d.log</location>
	log_format>iis</log_format>
</localfile>

--------	Using multiple outputs
Log data is sent to the agent socket by default, but it is also possible to specify other sockets as output.ossec-logcollector uses UNIX type sockets to communicate allowing TCP or UDP protocols. To add a new output socket we need to specify it using the tag <socket> as shown in the following example configuration:

<socket>
	<name>custom_socket</name>
	<location>/var/run/custom.sock</location>
	<mode>tcp</mode>
	<prefix>custom_syslog: </prefix>
</socket>

<socket>
	<name>test_socket</name>
	<location>/var/run/test.sock</location>
</socket>

Once the socket is defined, it’s possible to add the destination socket for each localfile:

<localfile>
    <log_format>syslog</log_format>
    <location>/var/log/messages</location>
    <target>agent,test_socket</target>
</localfile>

<localfile>
    <log_format>syslog</log_format>
    <location>/var/log/messages</location>
    <target>custom_socket,test_socket</target>
</localfile>


============  FIM	========
10 optins are configuranle:
Frequency: def 12 haurs
Real-time monitoring:  support Windows or Linux. Only for dirs not for individual files.
Whodata:  in addition provides information about who triggered the event.

An alert is generated any time that modifications ae detected in the monitored files and/or registry keys.
False positives can be addressed using the ignore configuration option or by creating rules that list files to be excluded from FIM alerts.

------------	Configuration		----------
Syscheck is configured in the ossec.conf file.
frequency
directories
ignore
alert_new_files

The check_all option checks file size, permissions, owner, last modification date, inode and all the hash sums (MD5, SHA1 and SHA256).

<The directories pushed from cetralized configuration are overwritten in the ossec.conf file if the directory path is the same.

<syscheck>
	<directories check_all="yes">/etc./usr/bin./usr/sbin</directories>
	<directories check_all="yes">/root/users.txt./bsd,/root/db.html</directories>
</syscheck>

---------	Configuring scheduled  scans
<syscheck>
	<frequency>36000</frequency>
	<directories>/etc,/usr/bin,/usr/sbin</directories>
	<directories>/bin,/sbin</directories>
</syscheck>


---------	Configuring realtime monitoring
Works with directories only rather then with individual files.Real-time change detection is paused during periodic syscheck scans and ractivates as soon as these scans are complete

<syscheck>
	<ditectories check_all="yes" realtim=="yes">c:/tmp</directories>

---------	Configuring who-data monitoring
whodata option
This option replaces the realtime option , which means that whodata implies real-time monitoring but adding the who-data information. This functionality uses Linux Audit subsystem and the Microsoft Windows SACL,so additional configurations might be necessary. Check the Auditing who-data entry to get further information

<syscheck>
	<directories check_all="yes" whodata="yes">/etc</directories>
</syscheck>



----------	Configure to report changes
Using the report_changes option , we can see what specifically changed in text files. Be carefull about which folders you set up to report_changes to , because in order to do this, Wazuh copies every single file you want to monitor to a private location.

---------	Configure to ignore files 
<syscheck>
	<ignore>/etc/random-seed</ignore>
	<ignore>/root/dir</ignore>
	<ignore type="sregex">.log$|.tmp</ignore>
</syscheck>

--------	Configure maximum recursioon level allowed
recursion_level option.
<syscheck>
	<directories check_all="yes">/etc,/usr/bin,/usr/sbin</directories>
	<directories check_all="yes">/root/users.txt,/bsd,/root/db.html</directories>
	<directories check_all="yes" recursion_level="3">folder_test</directories>


We will receive alerts for all files up to folder_test/l1/l2/l3 but we won't receive alerts from any directory deeper then l3

if recursion_level is not specified, it will be set to the default value defined by syscheck.default_max_depth in the internal options configuration file.

----------	Ignoring files via reles
<rule id="100345" level="0">
	<if_group>syscheck</if_group>
	<match>/var/www/htdocs</match>
	<description>Ignore changes too /var/www/htdocs</description>
</rule>

------	Changing severity
With a custom rule, the level of a syscheck alert can be altered when changes to a specific file or file pattern are detected.
<rule id="100345" level="12">
	<if_group>syscheck</if_group>
	<match>/var/www/htdocs</match>
	<description>Changes to /var/www/htdocs - Critical file!</description>
</rule>

-------  FIM ignoring files , to avoid false positives.
<ignore> 	option

Report changes in the content of a text file
It is possible whrn monitoring directories . Using the 
<report_changes> option gives the exact content that has been changed in text files within the directory being monitored. syscheck copy every single file you want to monitor with <report_changes>

-------		force an immediate syscheck scan
/var/ossec/bin/agent_control -r -a
/var/ossec/bin/agent_control -r -u <agent_id>

By default, syscheck scans when Wazuh starts, however, this behavior can be changed with the scan_on_start option

-------
alert_new_files option

==========	Auditing who-data	==============
This information contains the user who made the changes on the monitored files and also the program name or process used to carry them out.

----------		Linux systems
uses the Linux Audit subsystem to get the information about who made the changes in a monitored directory. These changes produce audit events that are processed by syscheck and reported to the manager.

apt install auditd
ossec.conf
<syscheck>
	<directories check_all="yes" whodata="yes">/etc</directories>
</syscheck>

service wazuh restart

check if the Audit rule for monitoring the selected folder is applied.
auditctl -l | grep wazuh_fim
-w /etc -p wa -k wazuh_fim  	#checks if the rule was added

when the agent is stopped , we can use the same command to check that the added rule was successfully removed.

=========	Anomaly and malware detection		===========
rootcheck
uses syscheck to detect anomalies.
Checks:
- Check running processes
- Check hidden ports
Rootcheck checks every port in the system using bind(). If it can not bind to a port and that port is not in the netstat output, malware may be present.
- Check unusual files and permissions
	scans entire FS looking for unusual files and permissions.owned by root with write permissions, or suid bit on.
- Check hidden files using system calls
comparing the differences between te stat size and the file size when using the fopen + read calls. The number of nodes in each directory is also compared with the output of opendir + readdir. If any results do not match, malware may be present.

- Scan the /dev directory
should only contain device-specific files. Any other should be inspected because malware uses thes partition to hide files.

- Scan network interfaces
if promiscuous mode enabled.

- Rootkit checks.
own database of rootkit signaturees: rootkit_files.txt,rootkit_trojans.txt and win_malware_rcl.txt.Unfortunately,these signatures are out of date.

-------------		Configuration
ossec.conf
<rootcheck>
	<rootkit_files>/var/ossec/etc/shared/rootkit_files.txt</rootkit_files>
	<rootkit_trojans>/var/ossec/etc/shared/rootkit_trojans.txt</rootkit_trojans>
</rootcheck>

Ignoring false positives
<rule id+"100100" level="0">
	<if_group>rootcheck</if_group>
	<match>/dev/.blkid.tab</match>
	<description>Ignore false positive for /dev/.blkid.tab</description>
</rule>


------------		By default rootcheck runs every 2 hours.
-------rootcheck inspects all running processes looking for discrepanies with different system calls.

=============		Monitoring security policies
Policy monitoring is the process of verifying that all systems conform to a set of predefined rules regarding configuration settings and approved application usage.

Wazuh uses three components to perform this task: Rootcheck , OpenSCAP and CIS-CAT.

1 Rootcheck
conf files - compliant with your sec policies, standards or hardening guides.
Agents perform periodic scans to detect applications that are known to be vulnerable, unpatched, misconfigured.

The rootcheck engine  can perform the following checks:
- check if a process is running
- check if a file is present
- check if the content of a file contains a pattern , or if a Windows registry key contains a string or is simply present.

following policies have been developed:
system_audit_rcl.txt - Web vulnerabilities and exploits
system_audit_ssh.txt	SSH Hardening
cis_debian_linux_rcl.txt	Based on CIS Benchmark for Debian Linux v1.0

Alerts related to policy monitoring:
512: win audit
514: win app
516: unix app

The policy and compliance monitoring databases are normally maintained on the manager , which distributes them to all the agents.

ex:
$sshd_file=/etc/ssh/sshd_config;

[SSH Configuration - 1:Root can log in] [any] [1]
f:$sshd_file -> !r:^# && r:PermitRootLogin\.+yes;
f:$sshd_file -> r:^#\s*PermitRootLogin;

-------		Basic usage
go to Rootcheck section
<rootcheck>
	<system_audit>./db/system_audit_rcl.txt</system_audit>
	<system_audit>./db/cis_debian_linux_rcl.txt</system_audit>
	<system_audit>./db/cis_rhel_linux_rcl.txt</system_audit>
</rootcheck>

-------		Configure periodic scans
<rootcheck>
	<frequency>36000</frequency>
	<system_audit>/var/ossec/etc/share/system_audit_rcl.txt</system_audit>
	<system_audit>/var/ossec/etc/shared/cis_debian_linux_rcl.txt</system_audit>
	<system_audit>/var/ossec/etc/shared/cis_rhel_linux_rcl.txt</system_audit>
	<system_audit>/var/ossec/etc/shared/cis_rhel5_linux_rcl.txt</system_audit>
</rootcheck>


-------		Root access to SSH
create your custom audit file (audit_test.txt):
# PermitRootLogin not allowed
# PermitRootLogin indicates if the root user can log in by ssh.
$sshd_file=/etc/ssh/sshd_config;

[SSH Configuration - 1: Root can log in] [any] [1]
f:$sshd_file -> !r:^# && r:PermitRootLogin\.+yes;
f:$sshd_file -> r:^#\s*PermitRootLogin;

ossec.conf
<rootcheck>
	<system_audit>/var/ossec/etc/shared/audit_test.txt</system_audit>
</rootcheck>

=================		OpenSCAP		===================
is an integration of OpenSCAP with Wazuh HIDS that provides the ability to perform configuration and vulnerability scans of an agent. It is primarily used for:
- Verifying security compliance: OpenSCAP policies define the requirements that all systems in an organization must meet in order to be in line with applicable security policies and/or security benchmarks.
- Performing vulnerability assessments: identifies and classifies vulnerabilities in a system
- Performing specialized assessments: OpenSCAP can perform specific custom system checks 

Security Content Automation Protocol (SCAP)
- specification for expressing and manipulating security data in standardized ways. Uses seceral specifications in order to automate continuous monitoring, vulnerability management , and reporting the results of security compliance scans.

Componnents of the security compliance evaluation process:
- SCAP scanner: This is an application that reads a SCAP policy and checks whether or not the system is compliant with it. There are many tools to scan your systems against SCAP policies. This wodle is an integration with the NIST-certified scanner called OpenSCAP.
- Security policies (SCAP content): This determine how a system must be set up and what to check for. These policies contain machine-readable descriptions of the rules which your system will be required to follow.
- Profiles: Each security policy can contain multiple profiles, which provide sets of rules and values in line with a specific security baseline. You can think of a profile as a particular subset of rules within the policy; the profile determines which rules defined in the policy will be actually used and what values will be used during the evaluation.
- Evaluation (scan): This is the process performed by the OpenSCAP scanner on an agent according ro a speccific security policy and profile . It usually takes only a few minutes, depending on the number of rules selected in the profile.

-----------		Requirements
rpm-based:
yum install openscap-scanner
debian:
apt-get install libopenscap8 xsltproc

default policies
CentOS
RedHat
Debian
Ubuntu (xenial;trusty;precise)
Fedora (24)

Manager and it will generate an alert if the status of the result is fail. It is possible to tuning the rules to send the pass result too.

-----------		Configuration
-----------		Basic usage
<wodle name="open-acap">
	<disabled>no</disabled>
	<timeout>1800</timeout>
	<interval>1d</interval>
	<scan-on-start>yes</scan-on-start>
	<content type="xccdf" path="ssg-centos-7-ds.xml">
		<profile>xccdf_org.ssgproject.content_profile_pci-dss</profile>
		<profile>xccdf_org.ssgproject.content_profile_common</profile>
	</content>
</wodle>

Evaluate PCI-DSS compliance on RHEL7
Payment Card Industry Data Security Standard (PCI-DSS) compliance on Red Hat Enterprise Linux 7 agents.
---------	Configuring agent ossec.conf:
<client>
	<server>
		<address>10.0.1.4</address>
		<port>1514</port>
		<protocol>tcp</protocol>
	</server>
	<config-profile>redhat7</config-profile>
</client>

--------	Configure manager
We want to execute the PCI-DSS profile of the SSGRH7 policy only on Red Hat 7 servers.
Manager /var/ossec/etc/shared/default/agent.conf  ( assuming that the agent is on the default group):
<agent_config profile="redhat7">
	<wodle name="open-scap">
		<content type="xccdf"" path="ssg-rhel7-ds.xml">
			<profile>xccdf_org.ssgproject.content_profile_pci-dss</profile>
		</content>
	</wodle>
</agent_config>


----------		Restart manager and agents
service wazuh-manager restart
/var/ossec/bin/agent_control -R -a

-u <id> - specific agent.

---------	See alerts
/var/ossec/logs/alerts/alerts.log

----------	Dashboards
Finally, you can explore all results using the OpenSCAP dashboards for Kibana.

----------	Auditing Security Vulnerabilities of Red Hat Products
RH Security Response Team probbifes OVAL definitions for all vulnerabilities (identified by CVE name) that affect RHEL 4-7. This enables users to perform a vulnerability scan and diagnose whether a system is vulnerable or not.

---------	Step 1. Configure agents.
ossec.conf:
<client>
	<server-ip>10.0.1.4</server-ip>
	<conffig-profile>redhat7</config-profile>
</client>

Step 2: Configure manager
shared/agent.conf:
<agent_config profile="redhat7">
	<wodle name="open-scap">
		<content type="xccdf" path="com.redhat.rhsa-RHEL7.ds.xml"/>
	</wodle>
</agent_config>

-------		Step 3: Restart manager and agents
service wazuh-manager restart
/var/ossec/bin/agent_control -R -a  (-u <id>)

-------		Step 4: See alerts
/var/ossec/logs/alerts/alerts.log

-- Kibana
See dashboard

------	Overwriting the timeout
<wodle name="open-scap">
	<timeout>1800</timeout>
	<content type="xccdf" path="ssg-centos7-ds.xml">
		<timeout>120</timeout>
	</content>
	<content type="xccdf" path="ssg-centos-6-ds.xml"/>
</wodle>

-------		Using profiles

<wodle name="open-scap">
	<content type="xccdf" path="ssg-centos-7-ds.xml">
		<profile>xccdf_org.ssgproject.content_profile_standard</profile>
		<profile>xccdf_org.ssgproject.content_profile_pci-dss</profile>
	</content>
	<content type="xccdf" path="ssg-centos-6-ds.xml/>
</wodle>


-----		Using CPE dictionary
<wodle name="open-scap">
	<content type="xccdf" path=policy="ssg-centos-7-ds.xml">
		<cpe>file.xml</cpe>
	</content>
	<content type="xccdf" path="ssg-centos-6-ds.xml" />
</wodle>

-----		Using IDs
You can select a specific ID of the datastream fiile:

<wodle name="open-scap">
	<content typ="xccdf" path="ssg-centos-7-ds.xml">
		<datastream-id>id</datastream-id>
	</content>
	<content typ="xccdf" path="ssg-centos-6-ds.xml" />
</wodle>

------
by default, policies are evaluated when the wodle starts.

-----
Each agent must have its policies in /var/ossec/wodles/oscap/content


=============	CIS-CAT integration
-----	Center for internet security - is an entity dedicated to safeguard private and public organizations against cyber threats.
This entity provides CIS benchmarks gurdelines, which are a recognized global standard and best practices for securing IT systems and data against cyberattacks.

In addition , CIS-CAT Pro is a "cross-platform Java app" tool developed for scanning target systems and generating a report compring the system settings to the CIS benchmarks. There are more than 80 CIS benchmarks that cover nearly all ASs , providing different profiles depending on the specific need.

This integration requires CIS-CAT Pro , which is proprietary software You can learn more about this tool and how to download it at the official cis WEBSITE.

-------		How it works.
The CIS-CAT Wazuh module integrates CIS benchmark assessments into Wazuh agents and reports the results of each scan in the form of an alert.

written in Java, so it requires a Java Runtime Environment in order to execute it. Currently, the JRE versions supported in CIS-CAT are JRE 6,7,8. Follow these steps to install the OpenJDK platform:
apt update && apt install openjdk-8-jre

-------		CIS-CAT must be reside on the local agent that runs the scans.JRE can be located on a removable disk or network drive for the purpose of sharing between multiple agents.

unix:
chmod +x CIS-CAT.sh

Once you have the requirements for running CIS evaluations, you can configure the wodle to check for specific benchmarks at a your chosen interval. The scan results from these checks are sent to the manager and can be included in the visualizations.

-------		Use case: Running a CIS evaluation
ossec.conf 
<wodle name="cis-cat">
 <disabled>no</disabled>
  <timeout>1800</timeout>
  <interval>1d</interval>
  <scan-on-start>yes</scan-on-start>

  <java_path>/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/bin</java_path>
  <ciscat_path>wodles/ciscat</ciscat_path>

  <content type="xccdf" path="benchmarks/CIS_Ubuntu_Linux_16.04_LTS_Benchmark_v1.0.0-xccdf.xml">
    <profile>xccdf_org.cisecurity.benchmarks_profile_Level_2_-_Server</profile>
  </content>

</wodle>

============		Monitoring system calls
------ Linux Audit system provides a way to track security-relevant information on your machine.Based on preconfigured rules, Audit proves detailed real-time logging about the events that are happening on your system. This information is crucial for mission-critical environments to determine the violator of the security policy and the actions they performed.

------		How it works
Audit uses a set of rules to define what is to be captured in the log files. There are three types of Audit rules that can be specified:
- Control rules allow the Audit system's  behavior and some of its configuration to be modified
- File system rules, also known as file watches, allow the auditing of access to a particular file or a directory.
- System call rules allow logging of system calls that specified programs makes.

Audit rules can be specified interactively with the auditctl command-line utility, but to make changes persistent, edit /etc/audit/audit.rules
------		Control rules
auditctl -b Set the maximum amount of existing Audit buffers in the kernel.
auditctl -e Enable/disable the Audit system or lock its configuration.
auditctl -s Report the status of the Audit system.
auditctl -l List all currently loaded Audit reles.
auditctl -D Delete all currently loaded Audit rules.

-----		File System Rules
To define a file system rule, use the following systax:
-w <path> -p <permissions> -k <key_name>
-w <path> Specify what file or dir to audit with <path>
-p <perm> are the perm that are to auditing, including the following:
	r - read access to a file or dir
	w - write access to afile or a dir
	x - execute access --||---
	a - change in the file's or dir's attr
-k <key_name> is an optional string to identify which rule/set of rules generates a particular log line.
This argument is required by Wazuh in order to analyze the logs more accurately.

ex:
defining a rule that logs all write access to , and every attr change of , the /etc/passwd file, exec:
auditctl -w etc/passwd -p wa -k passwd_changes

---------		System Call Rules
-a action, filter -S system_call -F field=value -k key_name
where:
Tells the kernel's rule matching engine to append a rule at the end of the rule list.
We must specify which rule list to append it to and what action to take when it triggers.
-a <action>,<filter>
	<action>	always 		- read access to a file or a dir.
			never		- write access to a file or a dir.
	The <filter> value specifies which kernel rule-matching filter is  applied to the enevt
			task 		- Only audit events fork or clone syscalls.
					- This is rarely used in practice.
			exit		- All syscall and file system audit requests are evaluated.
			user		- This is used to remove some events that originate in user space.
			exclude		- This is used to exclude certain events from being logged.
					- msgtype is used to tell the kernell which message to filter out.
					- For more granular control over which events to audit:
					  use the user and exit filters instead.
-S <system_call>		This specifies which system_call to audit . Multiple system calls can be specified in a single rule.
				A list of all system calls can be found with the connand :
				ausyscall --dump

-F <field=value>	Use field=value to specify additional criteria to narrow down which events to audit, based on:
			architecture, group ID, process ID, etc...,
			Multiple -F options can be used in a single rule.

-k <key_name> 		<key_name> is an optional string to identify which rule/set of rules generates a particular log line.
			This argument is required by Wazuh in order to analyze the logs more accurately.

Ex:
For example, to define a rule that creates a log entry every time a file is deleted or renamed by a system user whose ID is 500 or larger, use the following. Note thatt the -F auid!=4294967295 option is used to exclude users whose login UID is not set.

auditctl -a always,exit -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete

It is also possible to define a file system rule using the system call rule systax.
analg to the 	-w /etc/shadow -p wa 

auditctl -a always,exit -F path=/etc/shadow -F perm=wa

-----------		Confifuration
-----		Basic

Manager 
We will use a CDB list to determine the types of audit rule that has fire. This list will have the follwing syntax:
	key_name:value
	key_name is the string you used in the argument -k
	Value is one of the following values:
		write;read; execute;attribute;command
By default, OSSEC includes a CDB list with the following keys:

# cat /var/ossec/etc/lists/audit-keys

audit-wazuh-w:write
audit-wazuh-r:read
audit-wazuh-a:attribute
audit-wazuh-x:execute
audit-wazuh-c:command
You can add your own key with its value to the list like this:

# echo "my_key_write_type:write" >> /var/ossec/etc/lists/audit-keys
Each time you modify a CDB list, you must compile it:

# /var/ossec/bin/ossec-makelists

-----		Agent
Installing Audit
apt install auditd

ossec.conf
<localfile>
	<log_format>audit</log_format>
	<location>/var/log/audit/audit.log</location>
</localfile>

service wazuh-agent restart

--------
Now everything is ready to process audit events. You only need to create the proper audit rules (via auditctl or /etc/audit/audit.rules). In the next section we will describe some good use cases.

Monitoring accesses to a directory

In this example, we are going to monitor every kind of access under the /home directory:

auditctl -w /home -p w -k audit-wazuh-w
auditctl -w /home -p a -k audit-wazuh-a
auditctl -w /home -p r -k audit-wazuh-r
auditctl -w /home -p x -k audit-wazuh-x
Now we start getting alerts on account of the new audit rules:

--------	Monitoring user actions
# auditctl -a exit,always -F euid=0 -F arch=b64 -S execve -k audit-wazuh-c
# auditctl -a exit,always -F euid=0 -F arch=b32 -S execve -k audit-wazuh-c

-------- Privilege escalation

By default, Wazuh is able to detect privilege escalation by analyzing the corresponding log in /var/log/auth.log. The below example shows the homer user executing a root action:


In order to keep the track of the user after sudo, it is necessary to configure PAM.

Warning

Be very careful with PAM configuration, as a bad configuration could make your system inaccessible.

Add the following line to every PAM service that needs it:

session required        pam_loginuid.so

A common configuration should include: login, common-session, cron and sshd:

# grep -R "pam_loginuid.so" /etc/pam.d/

/etc/pam.d/login:session    required     pam_loginuid.so
/etc/pam.d/common-session:session required        pam_loginuid.so
/etc/pam.d/cron:session    required     pam_loginuid.so
/etc/pam.d/sshd:session    required     pam_loginuid.so

After configuring PAM, if we execute the previous command with the user homer we will see that the field auid is 1004, the id of the user homer.

# homer@springfield:/# sudo ls /var/ossec/etc

=============			Command monitoring

There are times when you may want to monitor things that are not in the logs. To address this, Wazuh incorporates the ability to monitor the output of specific commands and treat the output as though it were log file content.

Configure Wazuh agents to accept remote commands from the manager

Agents have the ability to run commands pushed from the manager (via the files in the shared directory). Before this feature can be used, however, the agents must be explicitly configured to accept remote commands. This can be done by setting the logcollector.remote_commands in the local_internal_options.conf file on each agent as shown below:

# Logcollector - Whether or not to accept remote commands from the manager
logcollector.remote_commands=1

Configure a command to monitor

The commands to run and monitor can be configured in the local the ossec.conf file of individual agents, however, the ideal location for this configuration is in the appropriate configuration section of the agent.conf file on the manager.

Example:

<localfile>
     <log_format>full_command</log_format>
     <command>.....</command>
     <frequency>120</frequency>
</localfile>

Process the output

After configuring the system to monitor the command’s output as if it were log data, custom rules can be created, like for Log analysis for instance, in order to process the output and trigger an alert when alert criteria are met.

============		Configuration 
------------		Basic
Command monitoring is configured in the localfile section of ossec.conf. It can be also be centrally configured in agent.conf.

Monitor running Windows processes

Let’s say you want to monitor running processes and alert if an important process is not running.

Example with notepad.exe as the important process to monitor:

1. Configure the agent in the agent’s local_internal_options.conf file to accept remote commands from the manager.

# Logcollector - Whether or not to accept remote commands from the manager
logcollector.remote_commands=1
2. Define the command in the manager’s agent.conf file to list running processes.

<localfile>
     <log_format>full_command</log_format>
     <command>tasklist</command>
     <frequency>120</frequency>
 </localfile>
The <frequency> tag defines how often the command will be run in seconds.

3. Define the rules.

<rule id="100010" level="6">
  <if_sid>530</if_sid>
  <match>^ossec: output: 'tasklist'</match>
  <description>Important process not running.</description>
  <group>process_monitor,</group>
</rule>
<rule id="100011" level="0">
  <if_sid>100010</if_sid>
  <match>notepad.exe</match>
  <description>Processes running as expected</description>
  <group>process_monitor,</group>
</rule>

The first rule (100010) will generate an alert (“Important process not running”), unless it is overridden by its child rule (100011) that matches notepad.exe in the command output. You may add as many child rules as needed to enumerate all of the important processes you want to monitor. You can also adapt this example to monitor Linux processes by changing the <command> from tasklist to a Linux command that lists processes, like ps -auxw.

Disk space utilization

The df command can be configured in the manager’s agent.conf file or in the agent’s ossec.conf file:

<localfile>
    <log_format>command</log_format>
    <command>df -P</command>
</localfile>
Wazuh already has a rule to monitor this:

<rule id="531" level="7" ignore="7200">
  <if_sid>530</if_sid>
  <match>ossec: output: 'df -P': /dev/</match>
  <regex>100%</regex>
  <description>Partition usage reached 100% (disk space monitor).</description>
  <group>low_diskspace,pci_dss_10.6.1,</group>
</rule>

Check if the output changed

In this case, the Linux “netstat” command is used along with the check_diff option to monitor for changes in listening tcp sockets.

This can be configured in either the agent.conf file or the ossec.conf file:

<localfile>
  <log_format>full_command</log_format>
  <command>netstat -tan |grep LISTEN|grep -v 127.0.0.1</command>
</localfile>
Wazuh already has a rule to monitor this:

<rule id="533" level="7">
  <if_sid>530</if_sid>
  <match>ossec: output: 'netstat -tan</match>
  <check_diff />
  <description>Listened ports status (netstat) changed (new port opened or closed).</description>
  <group>pci_dss_10.2.7,pci_dss_10.6.1,</group>
</rule>

If the output changes, the system will generate an alert indicating a network listener has disappeared or a new one has appeared. This may indicate something is broken or a network backdoor has been installed.

Load average

Wazuh can be configured to monitor the Linux uptime command and alert when it is higher than a given threshold, like 2 in this example.

This can be configured in agent.conf or ossec.conf:

<localfile>
    <log_format>command</log_format>
    <command>uptime</command>
</localfile>
And the custom rule to alert when “uptime” is higher than 2:

<rule id="100101" level="7" ignore="7200">
  <if_sid>530</if_sid>
  <match>ossec: output: 'uptime': </match>
  <regex>load averages: 2.</regex>
  <description>Load average reached 2..</description>
</rule>
Detect USB Storage

Wazuh can be configured to alert when a USB storage device is connected. This example is for a Windows agent.

Configure your agent to monitor the USBSTOR registry entry by adding the following to the manager’s agent.conf

<agent_config os="Windows">
  <localfile>
      <log_format>full_command</log_format>
      <command>reg QUERY HKLM\SYSTEM\CurrentControlSet\Enum\USBSTOR</command>
  </localfile>
</agent_config>
Next create a custom rule:

<rule id="140125" level="7">
    <if_sid>530</if_sid>
    <match>ossec: output: 'reg QUERY</match>
    <check_diff />
    <description>New USB device connected</description>
</rule>

============		Active response
 Active responses are either stateful or stateless responses. Stateful responses are configured to undo the action after a specified period of time while stateless responses are configured as one-time actions.

Where are active response actions executed?

Each active response specifies where its associated command will be executed: on the agent that triggered the alert, on the manager, on another specified agent or on all agents, which also includes the manager(s).

Active response configuration

Active responses are configured in the manager by modifying the ossec.conf file as follows:

Create a command

In order to configure an active response, a command must be defined that will initiate a certain script in response to a trigger.

Custom scripts that have the ability to receive parameters from the command line may also be used for an active response.

Example:

<command>
  <name>host-deny</name>
  <executable>host-deny.sh</executable>
  <expect>srcip</expect>
  <timeout_allowed>yes</timeout_allowed>
</command>
In this example, the command is called host-deny and initiates the host-deny.sh script. The data element is defined as srcip. This command is configured to allow a timeout after a specified period of time, making it a stateful response.

----------	Define the active response

The active response configuration defines when and where a command is going to be executed. A command will be triggered when a specific rule with a specific id, severity level or source matches the active response criteria. This configuration will further define where the action of the command will be initiated, meaning in which environment (agent, manager, local, or everywhere).

Example:

<active-response>
  <command>host-deny</command>
  <location>local</location>
  <level>7</level>
  <timeout>600</timeout>
</active-response>

<active-response>
  <command>host-deny</command>
  <location>local</location>
  <level>7</level>
  <timeout>600</timeout>
</active-response>
In this example, the active response is configured to execute the command that was defined in the previous step. The where of the action is defined as the local host and the when is defined as any time the rule has a level higher than 6. The timeout that was allowed in the command configuration is also defined in the above example.

---------	The active response log can be viewed at /var/ossec/logs/active-response.log.
---------	Default Active response scripts

Wazuh is pre-configured with the following scripts for Linux:

Script name	Description
disable-account.sh	Disables an account by setting passwd-l
firewall-drop.sh	Adds an IP to the iptables deny list
firewalld-drop.sh	Adds an IP to the firewalld drop list
host-deny.sh	Adds an IP to the /etc/hosts.deny file
ip-customblock.sh	Custom OSSEC block, easily modifiable for custom response
ipfw_mac.sh	Firewall-drop response script created for the Mac OS
ipfw.sh	Firewall-drop response script created for ipfw
npf.sh	Firewall-drop response script created for npf
ossec-slack.sh	Posts modifications on Slack
ossec-tweeter.sh	Posts modifications on Twitter
pf.sh	Firewall-drop response script created for pf
restart-ossec.sh	Automatically restarts Wazuh when ossec.conf has been changed
route-null.sh	Adds an IP to null route


----------	Configuration
Basic usage

An active response is configured in the ossec.conf file in the Active Response and Command sections.
This is a Stateless response as no timeout parameter is defined.

Command:

<command>
  <name>restart-ossec</name>
  <executable>restart-ossec.sh</executable>
  <expect></expect>
</command>
Active response:

<active-response>
  <command>restart-ossec</command>
  <location>local</location>
  <rules_id>10005</rules_id>
</active-response>

---------	Windows automatic remediation
In this example, the win_rout-null command is configured to use the route-null.cmd script using the data element srcip. The active response is configured to initiate the win_rout-null command on the local host when the rule has a higher alert level than 7. This is a Stateful response with a timeout set at 900 seconds.

Command:

<command>
  <name>win_route-null</name>
  <executable>route-null.cmd</executable>
  <expect>srcip</expect>
  <timeout_allowed>yes</timeout_allowed>
</command>
Active response:

<active-response>
  <command>win_route-null</command>
  <location>local</location>
  <level>8</level>
  <timeout>900</timeout>
</active-response>

--------	Block an IP with PF
Command:

<command>
  <name>pf-block</name>
  <executable>pf.sh</executable>
  <expect>srcip</expect>
</command>
Active response:

<active-response>
  <command>pf-block</command>
  <location>defined-agent</location>
  <agent_id>001</agent_id>
  <rules_group>authentication_failed,authentication_failures</rules_group>
</active-response>


Add an IP to the iptables deny list
----------   Windows automatic remediation
Command:

<command>
  <name>win_route-null</name>
  <executable>route-null.cmd</executable>
  <expect>srcip</expect>
  <timeout_allowed>yes</timeout_allowed>
</command>
Active response:

<active-response>
  <command>win_route-null</command>
  <location>local</location>
  <level>8</level>
  <timeout>900</timeout>
</active-response>

----------   PF
Active response:

<active-response>
  <command>pf-block</command>
  <location>defined-agent</location>
  <agent_id>001</agent_id>
  <rules_group>authentication_failed,authentication_failures</rules_group>
</active-response>

------------	Add an IP to the iptables deny list
Command:

<command>
  <name>firewall-drop</command>
  <executable>firewall-drop.sh</executable>
  <expect>srcip</expect>
</command>
Active response:

<active-response>
  <command>firewall-drop</command>
  <location>all</location>
  <rules_group>authentication_failed,authentication_failures</rules_group>
  <timeout>700</timeout>
  <repeated_offenders>30,60,120</repeated_offenders>
</active-response>

----------		Active response for a specified period of time
Command:

<command>
  <name>host-deny</name>
  <executable>host-deny.sh</executable>
  <expect>srcip</expect>
  <timeout_allowed>yes</timeout_allowed>
</command>
Active response:

<active-response>
  <command>host-deny</command>
  <location>local</location>
  <level>7</level>
  <timeout>600</timeout>
</active-response>

--------		Active response that will not be undone

In this example, the mail-test command is configured to use the mail-test.sh script with no data element. The active response is configured to initiate the mail-test command on the server when the rule with ID 1002 fires.

Command:

<command>
  <name>mail-test</name>
  <executable>mail-test.sh</executable>
  <timeout_allowed>no</timeout_allowed>
  <expect></expect>
</command>
Active response:

<active-response>
    <command>mail-test</command>
    <location>server</location>
    <rules_id>1002</rules_id>
 </active-response>

===============		Agentless monitoring

------The first step to using agentless monitoring is to enable it using the following command:

# /var/ossec/bin/ossec-control enable agentless

------	In order to connect the manager to the device using SSH authentication, the following register_host.sh script should be used. This script is located in the /var/ossec/agentless/ directory and has two options: list and add.

Using the list option will list all hosts already included.

# /var/ossec/agentless/register_host.sh list
Using the add option will specify a new device to be added to the manager. NOPASS may be entered as the password to use public key authentication rather than using a password. For Cisco devices, such as routers or firewalls, enablepass should be used to specify the enable password.

# /var/ossec/agentless/register_host.sh add root@example_address.com example_password [enablepass]
Public key authentication can be used with the following command:

# sudo -u ossec ssh-keygen
Once created, the public key must be copied into the remote device.

--------	Monitoring
ossec.conf
---	BSD integrity check
<agentless>
  <type>ssh_integrity_check_bsd</type>
  <frequency>20000</frequency>
  <host>root@test.com</host>
  <state>periodic</state>
  <arguments>/bin /var/</arguments>
</agentless>

---	Linux integrity check
<agentless>
  <type>ssh_integrity_check_linux</type>
  <frequency>36000</frequency>
  <host>root@test.com</host>
  <state>periodic</state>
  <arguments>/bin /etc/ /sbin</arguments>
</agentless>
---	Generic Diff
A set of commands can also be configured to run on a remote device. Wazuh will alert you if the output of those commands changes. In order to use this option, set the type as ssh_generic_diff, as shown below.

<agentless>
  <type>ssh_generic_diff</type>
  <frequency>20000</frequency>
  <host>root@test.com</host>
  <state>periodic_diff</state>
  <arguments>ls -la /etc; cat /etc/passwd</arguments>
</agentless>

---	Pix config
This option will alert if a Cisco PIX/router configuration changes. Set the type to ssh_pixconfig_diff, as shown below.

<agentless>
  <type>ssh_pixconfig_diff</type>
  <frequency>36000</frequency>
  <host>pix@pix.fw.local</host>
  <state>periodic_diff</state>
</agentless>

---	Checking the setup
Finally, the expect package must be present on the manager for this feature to work.

When the expect package is present and Wazuh is restarted, the following is shown in the /var/ossec/logs/ossec.log file:

ossec-agentlessd: INFO: Test passed for 'ssh_integrity_check_linux'.
When Wazuh has connected to the remote device, the following will be shown in the same log file:

ossec-agentlessd: INFO: ssh_integrity_check_linux: root@example_adress.com: Starting.
ossec-agentlessd: INFO: ssh_integrity_check_linux: root@example_adress.com: Finished.

---	Alert
Once configured as above, Wazuh alerts will be triggered when changes occur within the directories:

Sample alerts are as follows:

Integrity check BSD/Linux sample alert:

---------		Configuration

===============		Anti-flooding mechanism
Here are some misconfiguration scenarios that could lead to this problem:

Realtime FIM (Syscheck) of a directory with files that keep changing:
Events are generated every time a file under a Syscheck-monitored directory changes. If Syscheck monitors a directory which changes constantly, it will generate a large volume of events. In addition, if the monitored directory contains any file to which Wazuh writes when it generates an event, like /var/ossec/queue/, it will cause an infinite loop.

Windows Filtering Platform:
A Windows firewall event (ID 5156) is generated each time an outbound network connection is allowed. When this event is enabled in Windows, and Wazuh is configured to monitor all Windows Security Log events the result is an infinite loop. When the agent connects its manager, it generates a Windows firewall event that in turn causes the agent to connect again to its manager.

Applications that retry on errors with no rate limiting:
When certain applications encounter an error, like disk full for instance, they may generate an error log entry and retry given the task over and over again hundreds of times per second, generating a massive volume of events.

Each of these scenarios may well create such a high rate of events that the functioning of the agent, network, and/or manager may be significantly hampered.

In order to better handle these kinds of situations, the following controls have been deployed:

Agent-to-manager anti-flooding mechanism:
This provides event congestion control with an agent-side leaky bucket queue to guard against saturation of the network or of the manager by an agent.

Internal agent anti-flooding control:
This mechanism uses internal limits in different components of the agent, controlling the rate at which they generate events.

-------		How it works: Leaky bucket
Leaky bucket collects events in a buffer of a specified size (default 5000 events), and sends them to the manager at a rate no higher than a specified number, and network environment.(default 500 EPS).

-----			Buffer architecture
0-70% - normal working
70-90% - warning. Operation: Working properly.
Aler: Warning alert when reach 90%
100% - Operation: loss when is full
Alert: Full alert when buffer is filled.
Alert: Flood alert when is flooded.

-----	There are several levels of control:
Warning alert: The first control will trigger an alert on the manager when the occupied capacity of the buffer has reached a certain threshold. By default it is set at 90 percent.
Full alert: After the first control, if the buffer gets filled, another alert will be triggered on the manager. This new alert is more serious than a warning alert because a full bucket will drop incoming events.
Flood alert: This alert is generated if more than a configurable amount of time passes between a full alert event and the buffer level dropping below the warning level.
Normal alert: This alert is generated to announce that the buffer level has returned to normal (by default <= 70%) after having previously triggered a warning alert or higher.

-----	Measured configuration
In the <client_buffer> section of Local configuration it is possible to disable the buffer, configure the size of the buffer (in number of events), and configure its throughput limit measured in EPS, or event-per-second.

Disable buffer: This parameter disables the use of the leaky bucket, resulting in no restriction on the rate of events transmitted by the agent to the manger. This is how previous versions of the agent were set up.
Queue size: The queue size is the maximum number of events that can be held in the leaky bucket at one time. It should be configured according to the expected rate at which an agent may generate events. This value is set to 5000 events by default, which is a generous buffer size for most environments.
Events per second: This is the maximum rate at which events will be pulled from the agent’s buffer and transmitted to its manager. The default is a generous 500 EPS, but this should be set with consideration of the capacity of the network and the number of agents a manager is serving.

==========	Agent Labels
-------	Addition configuration information is available in the Internal configuration section. This includes information on analysisd.label_cache_maxage and analysisd.show_hidden_labels.

------		Use case.
AWS - large environment.
AWS instance-id
AWS Security group
Network IP address
Network MAC
Date of installation

To include these labels in alerts from a specific agent, the following configuration must be inserted into the ossec.conf file:

<labels>
  <label key="aws.instance-id">i-052a1838c</label>
  <label key="aws.sec-group">sg-1103</label>
  <label key="network.ip">172.17.0.0</label>
  <label key="network.mac">02:42:ac:11:00:02</label>
  <label key="installation" hidden="yes">January 1st, 2017</label>
</labels>
To set the labels at the manager level, the following configuration would be added to the agent.conf file:

<agent_config name="92603de31548">
  <labels>
    <label key="aws.instance-id">i-052a1838c</label>
    <label key="aws.sec-group">sg-1103</label>
    <label key="network.ip">172.17.0.0</label>
    <label key="network.mac">02:42:ac:11:00:02</label>
    <label key="installation" hidden="yes">January 1st, 2017</label>
  </labels>
</agent_config>
When an alert is fired for an agent with the above configuration applied from the manager, the defined labels will add information to alerts as shown below:

 ** Alert 1488922301.778562: mail  - ossec,syscheck,pci_dss_11.5,
 2017 Jun 07 13:31:43 (92603de31548) 192.168.66.1->syscheck
 aws.instance-id: i-052a1838c
 aws.sec-group: sg-1103
 network.ip: 172.17.0.0
 network.mac: 02:42:ac:11:00:02
 Rule: 550 (level 7) -> 'Integrity checksum changed.'
 Integrity checksum changed for: '/var/ossec/etc/ossec.conf'
 Size changed from '3663' to '3664'
 Old md5sum was: '98b351df146410f174a967d726f9965e'
 New md5sum is : '7f4f5846dcaa0013a91bd6d3ac4a1915'
 Old sha1sum was: 'c6368b866a835b15baf20976ae5ea7ea2788a30e'
 New sha1sum is : 'c959321244bdcec824ff0a32cad6d4f1246f53e9'

============		System inventory
The Wazuh agents are able to collect interesting system information and store it into an SQLite database for each agent on the manager side. The Syscollector module is in charge of this task.

Once the agent starts, Syscollector runs periodically scans of defined targets (hardware, OS, packages, etc.), forwarding the new collected data to the manager, which updates the appropriate tables of the database.

----	Available scans

The collected information from Wazuh agents is stored in different SQLite tables. Here the content of each available table is described .

At present, this module is available for Linux, Windows, MacOS, OpenBS and FreeBSD. See the compatibility matrix for more information.

- Hardware
- OS
	hostname
	architecture 
	os_name
	Os_version
	os_codename
	os_major
	os_minor
	os_build
	os_platform
	sysname
	release
	version

- Packages
	name
	priority
	section
	size
	vendor
	install_time
	version
	architecture
	multiarch
	source
	description
	location

- Network interfaces
sys_netiface table
	name
	adapter
	type 
	state
	mtu
	mac
	tx_packets
	rx_packets
	tx_bytes
	rx_bytes
	tx_errors
	rx_errors
	tx_dropped
	rx_dropped

sys_netaddr table
	proto
	address
	netmask
	broadcast

sys_netproto table
routing configuration for each interface
	iface
	type
	gateway
	dhcp

- Ports
	protocol
	local_ip
	local_port
	remote_ip
	remote_port
	tx_queue
	rx_queue
	inode
	state
	PID
	process

- Processes
List the current processes running in a system host.

	pid 
	name
	state
	ppid
	utime
	stime
	cmd
	argvs
	euser
	ruser
	suser
	egroup
	rgroup
	...

-Compatibility matrix

The following table shows the operating systems that this module currently supports.

Operating System	Syscollector scan
Hardware	OS	Packages	Network	Ports	Processes
Windows	✓	✓	✓	✓	✓	✓
Linux	✓	✓	✓	✓	✓	✓
macOS	✓	✓	✓	✓	✗	✗
FreeBSD	✓	✓	✓	✓	✗	✗
OpenBSD	✓	✓	✗	✓	✗	✗

--------Use case: Visualize system inventory in the Wazuh app

The Syscollector module is enabled by default in all compatible systems including all the available scans. Here we can see the default configuration block:

<!-- System inventory -->
<wodle name="syscollector">
  <disabled>no</disabled>
  <interval>1h</interval>
  <scan_on_start>yes</scan_on_start>
  <hardware>yes</hardware>
  <os>yes</os>
  <network>yes</network>
  <packages>yes</packages>
  <ports all="no">yes</ports>
  <processes>yes</processes>
</wodle>

Once the module starts, it will run periodically scans and send the new data in JSON events format to the manager, where it will be decoded and stored into a particular database for each agent.

The current inventory can be consulted in different ways. Let’s see an example querying for a particular package in a Debian agent:

Querying the Database directly on the manager side, located at $install_directory/queue/db/:agent_id.db.

=========		Vulnerability detection
=========		CVE - Common vulnarabilities and exposes.

This capability can be used to detect applications that are known to be vulnerable (affected by a CVE).

----	How it works
To be able to detect, now agents are able to natively collect a list of installed applications,
sending it periodically to the manager ( where it is stored in local sqlite databases, one per agent). 
In addition , the manager builds a global vulnerabilities database, using public OVAL CVE
repositories, using it later to cross correlate this information with agent's applications inventory data.

The global vulnerabilities database is created automatically, currently pulling data from the following repositories:
https://people.canonical.com # pull CVEs for Ubuntu Linux distriburions
https://www.refat.com	# pull CVEs for Red Hat and CentOS Linux distriburions
https://www.debian.com	#	pull CVEs for Debian Linux distributiona.

This database can be configured to be updated periodically, ensuring that the solution will check for the very latest CVEs.

Once the global vulnerability databse (with the CVEs( is created, the detection process will look for vvulnerable packages in the inventory databases (unique per agent). Alerts are generated when a CVE (Common Vulnerabilities and Exposures) affects a paxkage that is known to be installed in one of the monitored servers.

----		Compatibility matrix 
and the OVAL configuration needed for each distribution:

Distribution	Versions	Configuration OVALs
Red Hat & CentOS	5	Red Hat 5 OVAL
6	Red Hat 6 OVAL
7	Red Hat 7 OVAL
Ubuntu	12	Ubuntu 12 OVAL
14	Ubuntu 14 OVAL
16	Ubuntu 16 OVAL
18	Ubuntu 18 OVAL
Debian	7	Debian 7 OVAL
8	Debian 8 OVAL
9	Debian 9 OVAL
Amazon Linux	1	Red Hat 7 OVAL

--- Use case: Running a vulnerability scan
Config
1. Enable the agent module used to collect installed packages on the monitored system.
add to shared agent configuration file:
<wodle name="syscollector">
	<disabled>no</disabled>
	<interval>1h</interval>
	<packages>yes</packages>
</wodle>

 Enable the manager module used to detect vulnerabilities.
You can do this adding the following block of settings to your manager configuration file:

<wodle name="vulnerability-detector">
  <disabled>no</disabled>
  <interval>5m</interval>
  <run_on_start>yes</run_on_start>
  <feed name="ubuntu-18">
    <disabled>no</disabled>
    <update_interval>1h</update_interval>
  </feed>
</wodle>

service wazuh-manager restart

The following fields are captured in evry alert:
- CVE: The CVE identifier for the corresponding culnerability.
- Title: Short description of the impact of vulnerability.
- Severity: It specifies the impact of the vulnerability in terms of security.
- Published: Date when the vulnerability was included in the offical database.
- Reference: URL of the official database website with extra information of the vulnerability.
- Rationale: Broad description of the vulnerability.
- State: This field informs if it exists a patch for the vulnerability (fixed) or instead, its state.


=============		Virus Total Integration
scans monitored filed for malicious content.

Virus Total - powerful platform that aggregates multiple antivirus products along with an online scanningh engine.
Combining this tool with out FIM ingine provides a simple means of scanning the files that are monitored by syscheck to inspect them for malicious content.

----	Virus Total - is an online service that analyzes files and URLs for the detection of viruses, worms, trojans and other kinds of malicious content using antivirus engines and website scanners. It also has the ability to detect false positives.

VT - free sevice with numerous useful features.
- VT stores all of the analyses it performs which allows for the hash of a specific file to be searched. By sending the hash to the VirusTotal engine, it can be known if that specific file has already been scanned by VT and analyze its report.
- VT also provides an API that allows access to the inforrnation generated by VT without needing to utilize the HTML websit interface. This API is subject to its Terms of Service which are briefly discussed in the following section.

-----	ToS: Public API vs Private API
- Public API	-  has important limitations, 
	the request ratio limitation to no more than four requests of per minute, and
	low priority access of requests done by this API for the VT enfine.

	Users who run a honeyclient, honeypot or any other automation that provides resources to VT are rewarded with a higher request rate quota and special privileges when performing the calls to the API

- PRIVATE API
	premium . it provides high priority access for requests, along with additional advantages.

-------			HOW IT WORKS

syscheck monitored files , and they are checked by VT.
1. FIM fix change or deletion of files in the folders monitored by the syscheck module.
2. When the VT integration is enabled , it is triggered when a FIM alert occurs. From this alert, the module extracts the hash field of the file.
3. The module then makes an HTTP POST request to the VT database using the VT API for comparison between the extracted hash and the information contained in the database.
4. A JSON response is then received that is the result of this search which will trigger one of the following alerts:
	Pub API request rate limit reached
	check credentials
	no records in VT database
	no positives found
	x engines detected this file



----			Use case: scanning a gile with the VT integration
1. pip install requests
2. add to ossec.conf:
<integration>
	<name>virustotal</name>
	<api_key>API_KEY</api_key>
	<group>syscheck</group>
	<alert_format>json</alert_format>
</integration>
3. bin/ossec-control enable integrator
4. service wazuh-manager restart
After this is complete, and FIM alert automatically triggers the VT integration.

----		Using FIM to monitor a directory
1. The following must be added to the <syscheck> section of the configuration file:
<syscheck>
  <directories check_all="yes" realtime="yes">/media</directories>
</syscheck>

2. syscheck module must then be restarted.

----	VT integration alerts.
When a request to VT is sent bt the integrator module , as noted above, different alerts will be triggered depending on the situation. Below are examples and explanations of these alerts:

==========		Osquery
---	Wazuh module that allows to manage the Osquery tool from Wazuh agents, being able to set the Osquery configuration and collect the information generated by Osquery to send it to the manager, generating the corresponding alerts if necessary.

----	How it works 
Osquery can be used to expose an operating system as a high-performance relational database.
This allows you to write SQL-based queries to explore operating system data.

Below you can see some examples of the queries you can make:

List all the local users of the machine.

SELECT * FROM users;

Get the process name, port , and PID, for processes listening on all interfaces.
SELECT DISTINCT processes,name, listening_ports.port, processes.pid FROM listening_ports JOIN processes USING (pid) WHERE listening_ports.address = '0.0.0.0';

Check the processes that have a deleted executable.

SELECT * FROM processes WHERE on_disk = 0;

-------		Configuration
1. You need a working Osquery installation in your system. 
# export OSQUERY_KEY=1484120AC4E9F8A1A577AEEE97A80C63C9D8B80B
# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys $OSQUERY_KEY
# add-apt-repository 'deb [arch=amd64] https://pkg.osquery.io/deb deb main'
# apt-get update
# apt-get install osquery
2. cp /usr/share/osquery/osquery.example.conf /etc/osquery/osquery.conf
or 
copy custom configuration in /etc/osquery/osquery.conf:
{
    "options": {
        "config_plugin": "filesystem",
        "logger_plugin": "filesystem",
        "utc": "true"
    },

    "schedule": {
        "system_info": {
        "query": "SELECT hostname, cpu_brand, physical_memory FROM system_info;",
        "interval": 3600
        },
        "high_load_average": {
        "query": "SELECT period, average, '70%' AS 'threshold' FROM load_average WHERE period = '15m' AND average > '0.7';",
        "interval": 900,
        "description": "Report if load charge is over 70 percent."
        },
        "low_free_memory": {
        "query": "SELECT memory_total, memory_free, CAST(memory_free AS real) / memory_total AS memory_free_perc, '10%' AS threshold FROM memory_info WHERE memory_free_perc < 0.1;",
        "interval": 1800,
        "description": "Free RAM is under 10%."
        }
    },

    "packs": {
        "osquery-monitoring": "/usr/share/osquery/packs/osquery-monitoring.conf",
        "incident-response": "/usr/share/osquery/packs/incident-response.conf",
        "it-compliance": "/usr/share/osquery/packs/it-compliance.conf",
        "vuln-management": "/usr/share/osquery/packs/vuln-management.conf",
        "hardware-monitoring": "/usr/share/osquery/packs/hardware-monitoring.conf",
        "ossec-rootkit": "/usr/share/osquery/packs/ossec-rootkit.conf"
    }
}

as you can see in this sample configuration, system_info , high_load_average and low_free_memory queries will be executed every hour.

Furthermore, this configuration uses some default packs such as osquery-monitoring, hardware-monitoring or ossec-rootkit among others. You can define you own packs and use it with this wodle.

-----		Alert examples


==============		Ruleset
This documentation explains how to install, update, and contribute to Wazuh Ruleset. These rules are used by the system to detect 
attacks, 
intrusions, 
software misuse, 
configuration problems, 
application errors, 
malware, 
rootkits, 
system anomalies or 
security policy violations. 
OSSEC provides an out-of-the-box set of rules that we update and augment, in order to increase Wazuh detection capabilities.

----		Begin
The default number of rules and decoders is limited. For this reason, we centralize, test and maintain decoders and rules submitted by opensource contributors.
We also create new rules and rootchecks perodically and add them to this repository so they can be used by the user community.
Some examples are the new rules for Netscaler and Puppt.

----		GitHub repository
in the ruleset repository you will find:
- New rules, decoders and rootcheccks
	eliminate false positives and to increase accuracy. We map the rules to pci-dss compliance controls, making it easy to identify when an alert is related to a specific compliance requirement.
- Tools - we provide some useful tools for testing.

----		Resources
- Visit out repository to view the rules in detail at https://github.com/wazuh/wazuh-ruleset
- Find a complete description of the available rules at Wazuh Ruleset Summary https://www.wazuh.com/resources/OSSEC_Ruleset.pdf

--- 	Rule and Rootcheck example
<rule id="80102" level="10" frequency="6">
	<if_matched_sid>80101</if_matched_sid>
	<same_source_ip />
	<description> Netscaler: Multiple AAA failed to login the user </description>
	<group>authentication_failure, netscaler-aaa,pce_dss_10.2.4,pci_dss_10.2.5,pci_dss_11.4,</group>
</rule>


----		Directory layout
The ruleset folder structure is shown below:
/var/ossec/
        ├─ etc/
        │   ├─ decoders/
        |   |        └─ local_decoder.xml
        │   └─ rules/
        |         └─ local_rules.xml
        └─ ruleset/
                ├─ decoders/
                └─ rules/

Insede the ruleset/ folder you will find all the common rules and decoders. All files insede this ffolder will be overwritten or modified in the Wazuh update process, so please do not edit files or add custom files in this folder.

If we need to perform some custom changes, we will use the etc/ folder. You can add here your own decoders/rules files or use the default local_decoder.xml and local_rules.xml files.


-------		Update ruleset 
bin/update_ruleset
-----		Configure weekly updates
sudo crontab -e 
@weekly root cd /var/ossec/bin && ./update_ruleset -r

=======		JSON decoder
Wazuh now incorporates an integrated decoder for JSON logs enabling the extraction of data from any source in this format.

This decoder has the ability to extract the following data types:
Numbers
Strings 
Booleans
Null values
Arrays
Objects

Extracted fields are stored as Dynamic Fields and can be referred to by the rules.

The following example shows how Wazuh decodes a JSON log and generates an alert for Suricata.

Suricata event log:

{
   "timestamp": "2016-05-02T17:46:48.515262+0000",
   "flow_id": 1234,
   "in_iface": "eth0",
   "event_type": "alert",
   "src_ip": "16.10.10.10",
   "src_port": 5555,
   "dest_ip": "16.10.10.11",
   "dest_port": 80,
   "proto": "TCP",
   "alert": {
      "action": "allowed",
      "gid": 1,
      "signature_id": 2019236,
      "rev": 3,
      "signature": "ET WEB_SERVER Possible CVE-2014-6271 Attempt in HTTP Version Number",
      "category": "Attempted Administrator Privilege Gain",
      "severity": 1
   },
   "payload": "21YW5kXBtgdW5zIGRlcHJY2F0QgYWI",
   "payload_printable": "this_is_an_example",
   "stream": 0,
   "host": "suricata.com"
}

---	The JSON decodder extracts each the fields from the log data for comparison against the rules such that a apecific Suricata decoder is not needed. 
The rules will be used to identify the surce of the JSON event based on the existence of certain fields that are specific to the soutce that the JSON event was generated from.

The following example shows how the rules contained in the file 0470-suricata_rules.xml work.

Initially, there is a parent rule to check for the existence of the 'timestamp' and 'event_type' fields
to determine the type of log (Suricata), then the child rule displays the alert using the value of the extracted fields.

<rule id="86600" lebel="0">
	<decoded_as>json</decoded_as>
	<field name="timestamp">\.+</field>
	<field name="event_type">\.+</field>
	<description>Suricata messages.</description>
</rule>

<rule id="86601" level="3">
	<if_sid>86600</if_sid>
	<field name="event_type">^alert$</field>
	<description>Suricata: Alert - $(alert.signature)</description>
</rule>
...


-------
New in version 3.3.0.

Lets see another example where we use the JSON decoder to extract a JSON included as a part of an incoming log. This is possible thanks to the new attribute offset introduced to the decoder options, that allows to discard some parts of the input string.

If we use this input log:

2018 Apr 04 13:11:52 nba_program: this_is_an_example: " player_information: "{ "name": "Stephen", "surname": "Curry", "team": "Golden State Warriors", "number": 30, "position": "point guard"}
The decoder declaration using that new feature would be the following:

<decoder name="raw_json">
    <program_name>nba_program</program_name>
    <prematch>player_information: "</prematch>
    <plugin_decoder offset="after_prematch">JSON_Decoder</plugin_decoder>
</decoder>
The JSON decoder will extract the fields contained in the JSON event as dynamic fields, taking into account from the end of the prematch text. The output of the ossec-logtest is the following:

In addition, we could define a rule for these raw events decoded:

<rule id="100001" level="5">
    <decoded_as>raw_json</decoded_as>
    <description>Raw JSON event</description>
</rule>


--- Another new feature is the ability of mixing plugin decoders with regex expressions, take a look in the following incoming log:

2018 Jun 08 13:11:52 nba_email_db: json_data: { "name": "Stephen", "surname": "Curry", "email": "curry@gmail.com"}
We can set several children decoders from a parent specifying a plugin decoder as before, and also another one including a regex expression. For example, the following ones:

<decoder name="json_parent">
    <program_name>nba_email_db</program_name>
</decoder>

<decoder name="json_child">
    <parent>json_parent</parent>
    <prematch>json_data: </prematch>
    <plugin_decoder offset="after_prematch">JSON_Decoder</plugin_decoder>
</decoder>

<decoder name="json_child">
    <parent>json_parent</parent>
    <regex>@(\S+)"</regex>
    <order>email.domain</order>
</decoder>



-------		Custom rules and decoders
It is posseble to modify the default rules and decoders from the Wazuh Ruleset and also to add new ones in order to increase Wazuh's detection capabilities.

---		Adding new decoders and rules
- local_decoder.xml and local_rules.xml to implement small changes.

We are going to describe these procedures using an easy example. Here is a log from a program called example:
Dec 25 20:45:02 MyHost example[12345]: User 'admin' logged from '192.168.1.100'

1. Decode
add new decoder to 
/var/ossec/etc/decoders/local_decoder.xml

<decoder name="example">
  <program_name>^example</program_name>
</decoder>

<decoder name="example">
  <parent>example</parent>
  <regex>User '(\w+)' logged from '(\d+.\d+.\d+.\d+)'</regex>
  <order>user, srcip</order>
</decoder>

2. Rule:
/var/ossec/etc/rules/local_rules.xml

<rule id="100010" level="0">
  <program_name>example</program_name>
  <description>User logged</description>
</rule>

3. Check if it works.
/var/ossec/vin/ossec-logtest

--------	Changing an existing rule

You can modify the standard rules.

!Updating wazuh will rewrite all in /var/ossec/ruleset/rules folder

--- 	To change existing rule 
1. Open the rule file /var/ossec/ruleset/rules/0095-sshd_rules.xml
2. Find and copy the following code from the rule file:
<rule id="5710" level="5">
  <if_sid>5700</if_sid>
  <match>illegal user| invalid user</match>
  <description>sshd: Attempt to login using a non-existent user</description>
  <group>invalid_login,authentication_failed,pci_dss_10.2.4,pci_dss_10.2.5,pci_dss_10.6.1,</group>
</rule>
3. Paste the code into /var/ossec/etc/rules/local_rules.xml, modify the level value , and add 
overwrite="yes" to indicate that this rule is overwriting an already defined rule:

<rule id="5710" level="10" overwrite="yes">
  <if_sid>5700</if_sid>
  <match>illegal user|ivalid user </match>
  <description>sshd: Attempt to login using a non-existent user</description>
  <group>invalid_login,authentication_failed,pci_dss_10.2.4,pci_dss_10.2.5,pci_dss_10.6.1,</group>
</rule>

-------		Changing an existing decoder
You can also modify the standard decoders.

! Don't change in /var/ossec/ruleset/decoders

Different from the approach which we apply to rules

If we want to change something in the decoder file ..., we will do the following:
1. Copy the decoder file /var/ossec/ruleset/decoders/ssh_decod.xml from the default folder to the user folder /var/ossec/etc/decoders in order to keep the changes.
2. Exclude the original decoder file ruleset/decoders/0310-ssh_decoders.xml from the OSSEC loading list. To do this , use the tag 
<decoder_exclude> in the ossec.conf file. 
Thus , the specified decoder will not be loaded from the default decoder folder, and the decoder file saved in the user folder will be loaded instead.

<ruleset>
  <!-- Default ruleset -->
  <decoder_dir>ruleset/decoders</decoder_dir>
  <rule_dir>ruleset/rules</rule_dir>
  <rule_exclude>0215-policy_rules.xml</rule_exclude>
  <list>etc/lists/audit-keys</list>

  <!-- User-defined ruleset -->
  <decoder_dir>etc/decoders</decoder_dir>
  <rule_dir>etc/rules</rule_dir>
  <decoder_exclude>ruleset/decoders/0310-ssh_decoders.xml</decoder_exclude>
</ruleset>

3. Perform the changs in the file /var/ossec/etc/decoders/01310-ssh_decoders.xml.
!!!
Note that at this point, if updates o the public Wazuh Ruleset include changes to 0310-ssh..., 
they will not apply to you since you are no longer loading that decoder file from the standard
location that gets updates. At some point you may have to manually migrate your customized mterial from 0310-ssh_decoders.xml to a newer copy of that file.  Consider internally documenting your changes in 0310-ssh_decoders.xml so that they are easy to find if they have to be migrated later.

=========		Dynamic fields
---		Traditional decoders
An important step for the detection and processing of treats is the extraction of information from each event received. Wazuh uses decoders to identify event types and then extract the most relevant
fields, thus enriching events andd allowing them to be more deeply analyzed and indexed.

Traditionally, OSSEC has provided thirteen prdefined fields for storing extrcted information (user , srcip,dstip,srcport,dstport,protocol,action,id,url,data,extra_data,status,system,system_name),of which only eight can be extracted simultaneously.

Static fields:
<decoder name="web-accesslog">
  <type>web-log</type>
  <prematch>^\d+.\d+.\d+.\d+ - </prematch>
  <regex>^(\d+.\d+.\d+.\d+) - \S+ [\S+ -\d+] </regex>
  <regex>"\w+ (\S+) HTTP\S+ (\d+) </regex>
  <order>srcip,url,id</order>
</decoder>


-----			Dynamic decoders
It is often necessary to extract more than eight relevant fields from an evet, and often the actual
data items extracted have no relationship to the limited list of predefined field names. Knowing that we cannot afford to operate within these constraints, Wazuh has extende OSSEC to allow the decoding of an unlimited number of fields with field names that clearly relate to what is being extractes. Even nested field names are supported.

Dynamic Fields:
<decoder name="auditd-config_chane">
  <parent>auditd</parent>
  <regex offset="after_regex">^auid=(\S+) ses=(\S+) op="(\.+)"</regex>
  <order>audit.auid,audit.session,audit.op</order>
</decoder>

Wazuh transforms any field name included in the <order> tag into a JSON field.

The next example shows how the auditd decoder extracts the information from an alert:

** Alert 1486483073.60589: - audit,audit_configuration,
2017 Feb 07 15:57:53 wazuh-example->/var/log/audit/audit.log
Rule: 80705 (level 3) -> 'Auditd: Configuration changed'
type=CONFIG_CHANGE msg=audit(1486483072.194:20): auid=0 ses=6 op="add rule" key="audit-wazuh-a" list=4 res=1
audit.type: CONFIG_CHANGE
audit.id: 20
audit.auid: 0
audit.session: 6
audit.op: add rule
audit.key: audit
audit.list: 4
audit.res: 1

JSON Output:

{
  "rule": {
    "level": 3,
    "description": "Auditd: Configuration changed",
    "id": 80705,
    "firedtimes": 2,
    "groups": [
      "audit",
      "audit_configuration"
    ]
  },
  "agent": {
    "id": "000",
    "name": "wazuh-example"
  },
  "manager": {
    "name": "wazuh-example"
  },
  "full_log": "type=CONFIG_CHANGE msg=audit(1486483072.194:20): auid=0 ses=6 op=\"add rule\" key=\"audit-wazuh-a\" list=4 res=1",
  "audit": {
    "type": "CONFIG_CHANGE",
    "id": "20",
    "auid": "0",
    "session": "6",
    "op": "add rule",
    "key": "audit",
    "list": "4",
    "res": "1"
  },
  "decoder": {
    "parent": "auditd",
    "name": "auditd"
  },
  "timestamp": "2017 Feb 07 15:57:53",
  "location": "/var/log/audit/audit.log"
}


========		Decoders Syntax
- Decoder
The attributes list below defines a decoder.
id
name 
type 
status


- parent
It is used to link a subordinate codeblock to his parent.

- accumulate
allow wazuh to track events over multiple log messages based on a decoded id.

- program_name
It defines the name of the program with which the decoder is associated.

- prematch
It attempts to find a match within the log for the string defined.

- regex
The attribute below is optional, it allows to discard some of the content of the entry.

- The attribute below is optional , it allows to  dome of the content of the entry.

- order
It defines what the parenthesis groups contain and the order in which they were received.

	static fields
		srcuser, dstuser,user,srcip,dstip,srcport,dstport,protocol,id , url,action,status,
		extra_data
	Dynamic fields:
		Any string not included in the previous list.

- fts
	It is used to designate a decoder as one in which the first time it matches the administrator would like to be alerted.

	Allowed values
		location,srcuser,dstuser,user,srcip,dstip,srcport,dstport,protocol,id , url,action,
		status, extra_data

- ftscomment
	It adds a comment to a decoder when <fts> tag is used.

- plugin_decoder
Use a specific plugin decoder to decode the incoming fields. It is useful for particular cases where it would be tricky to extract the fields by using regexes.

Allowed values
	PF_Decoder,SymantecWS_Decoder,SonicWall_Decoder,SonicWall_Decoder,OSSECAlert_Decoder,JSON_Decoder

The attribute below is optional, it allows to start the decode process after a particular point of the log.

	offset = after_parent|after_prematch

An ex of its use is described at the JSON decoder section.

- use_own_name
Allows to set the name of the child decoder from tje name attribute instead of using the name of the parent decoder.
	Allowed values = true

- json_null_field
	Specify how to treat the NULL fields coing from the JSON events. Only for the JSON decoder.
	Allowed values
		string (it shows the NULL value as string)
		discard(It discard NULL fields and doesn't store them into the alert)
		empty(it shows the NULL field as an empty field)

27.11.2018
=======		Rules syntax
---		Rule 
	level 0 to 16
	id 	rule id		1 to 999999
	maxsize 	max event size		1 to 9999
	frequency 	Number of times the rule must have matched before firing	2 to 9999
	timeframe 	intended to be used with the frequency option.
			1 to 99999
	ignore 		ignore this rule after firing it (to avoid flood)
	overwrite	Used to supersede an OSSEC rule with local changes.
			yes,no
	noalert		Not trigger any alert if the rule matches.
			no value
---	match	any sregex expression
---	regex	--||--
---	decoded_as
---	category	decoded category to match: ids,syslog,firewall, web-log,squid or windows.
---	field		any regex to be compared to a field extracted by the decoder.
---	srcip		any ip address or CIDR block to be compared to an IP decoded as srcip. ! - negate it
---	dstip		--||--
---	extra_data	any string that is decoded into the extra_data field
---	user		any sregex expression
---	program_name	any sregex expression
---	hostname	any hostname (decoded as the syslog hostname) or log file.
---	time		any time range (hh:mm-hh:mm)
---	weekday		monday-sunday,weekdays,weekends
---	id 		any ID (decoded as the ID).
---	url		any URL (decoded as the URL).
---	if_sid		Matches if the ID has matched.
---	if_group	Matches if the group has matched before.
---	if_level	Matches if the level has matched before.
---	if_matched_sid	Matches if an alert of the defined ID has been triggered in a set nember of seconds.
			This option in conjunction with frequency and timeframe.
			Note
			Rules at level 0 are discarded immediately and will not be used with the if_matched_rules.The level must be at least 1, but the <no_log> option can be added to the rule to make sure it does not get logged.
---	if_matched_group	Matches if an alert of the defined group has been triggered in a set 
				number of seconds.
				in conjunction with frequency and timeframe.
---	same_id			Specifies that the decoded id must be the same. This option is used 
				with freq and timeframe.
---	same_source_ip		decoded source ip must be the same.used with freq and timeframe.
---	same_src_port		srcport must be the same.
---	same_dst_port		dstport must be the same. frq and timeframe needed.
---	same_location		location must be the same.freq and timeframe needed.
---	same_user		decoded user must be the same.--||--
---	different_url		url must be different.--||--
---	different_srcgeoip	src geoip location must be different.--||--
---	description		rule description.
---	list			perform a CDB lookup using an ossec list. This is a fast on disk database which will always find keys within two seeks of the file.
		Attribute:
			field 	key in the CDB:srcip,srcport,dstip,dstport,extra_data,user,url,id , hostname,program_name,status,action,dynamic field.
			lookup	match_key	- key to serch
				not_match_key key to search and will match if it is not present in the database.
				match_key_value - searched for in the cdb. it will be compared with regex from attribute check_value.
				address_match_key - IP and the key to search within the cdb and will match if they key is present.
				not_address_match_key - IP the key to search and will match if it IS NOT present in the database
				address_match_key_value - IP to search in the cdb. it will be compared with regex from attribute check_value.
			check_value	regex for matching on the value pulled out of the cdb when using types:address_matcch_key_value,match_key_value


--- info	Extra information may ne added through the following attributes:
		type:
			text	def when no type is selected . Additional, information about
			link	Link to more information about the alert/event.
			cve	The CVE Number related to this a/e
			ovsdb	The osvdb id related to this a/e.
--- options	Used one <options> tag for each option you want to add.
		alert_by_email
		no_email_alert	never allert by email.
		no_log 		do not log this alert
		no_full_log 	Do not include the full_log field in the alert.
		no_counter	Omit field rule.firedtimes in the JSON alert.
--- check_diff	Used to determine when the output of a command changes.
--- group	add additional groups to the alert.Are optional tags added to alerts.

==========		Regular Expression Syntax
There are two types of regular expressions:	regex - OS_Regex and sregex (OS_Match)
---		Regex (OS_Regex) syntax
This is a fast and simple library for regular expressions in C.
This library is designed to be simple while still supporting the most common regular expressions.
Supported expressions

Expressions	Valid characters
\w	A-Z, a-z, 0-9, ‘-‘, ‘@’, ‘_’ characters
\d	0-9 character
\s	Spaces ” “
\t	Tabs
\p	()*+,-.:;<=>?[]!”’#$%&|{}
\W	Anything not w
\D	Anything not d
\S	Anything not s
\.	Anything

Modifiers
+ To match one or more times
* To match zero or more times

- Special characters
Expressions	Actions
^	To specify the beginning of the text
$	To specify the end of the text
|	To create a logical or between multiple patterns

- Characters escaping
To utilize the following characters they must be escaped with: \
$	(	)	\	|	<
\$	\(	\)	\ \	\|	\<

-------		Sregex (OS_Match) syntax
This is faster than OS_Regex, but only supports simple string matching and the following special characters.

Special characters.
Expressions	Actions
^	To specify the beginning of the text
$	To specify the end of the text
|	To create a logic: or, between multiple patterns

===========		Testing decoders and rules
The tool ossec-logtest allow us to test how an event is decoded and if an alert is generated.
bin/ossec-logtest run and paste the following log:

	To show more info you can use -v option.
bin/ossec-logtest -v

==========		Using CDB lists
---	Wazuh is able to check if a field extrxted during the decoding phase is in a CDB list (constant database) . The main use case of this feature is to create a white/black list of users,IPs or domain names.
---	Creating a CDB list
This list file is a plain text file whereeach line has the following format:
key:value1
key2:value2

Each key must be unique and is terminated with a colon : .
For IP addresses the dot notation is used for subnet matches:
key	CIDR	Possible matches
192.168.:	192.168.0.0/16	192.168.0.0-192.168.255.255
172.16.19.:	172.16.19.0/24	172.16.19.0-172.16.19.255
10.1.1.1:	10.1.1.1/32	10.1.1.1

Ex of IP address list file:
192.168.: Matches 192.168.0.0 - 192.168.255.255
172.16.19.: Matches 172.16.19.0 - 172.16.19.255
10.1.1.1: Matches 10.1.1.1

---	Recommendation to store the lists on /var/ossec/etc/lists

---	Adding the list to ossec.conf
Each list must be defined in the ossec.conf file using the following syntax:
<ossec_config>
  <releset>
    <list>etc/lists/list-IP</list>

! Warn : The <list> setting uses a relative path to the Wazuh installation folder (/var/ossec/) so make sure to indicate the directory accordingly.

service wazuh-manager restart

---	Making the CDB list
THE LIST FILES MUST Be compiled before they can be used. The tool /var/ossec/bin/ossec-makelists
will process and compile all the lists if needed.

Remember to compile the lists every time that you update them . It is necessary to restart Wazuh to apply the changes.


---	Using the CDB list in the rules.
A rule would use the following syntax to look up a key within a CDB list.
---	Positive key match
This example is a search for the key stored in the field attribute and will match if it IS present in the database:
<list field="user" lookup="match_key">etc/lists/list-usr</list>

The lookup="match_key" is the default and can be left out as in this example:
<list field="user">etc/lists/list-user</list>

In case the field is an IP adress, you must to use address_match_key:
<list field="srcip" lookup="address_match_key">etc/lists/list-IP</list>

---	Negative key match
This example is a search for the key stored in the field attribute and will match if it IS NOT present in the database:
<list field="user" lookup="not_match_key">etc/lists/list-user</list>
In case the field is an IP address, you must use not_address_match_key:
<list field="srcip" lookup="not_address_match_key">etc/lists/list-IP</list>

---	Key and value match
This example is asearch for the key stored in the field attribute, and on  a positive match the returned value of the key will be processed using the regex in the check_value attribute:
<list field="user" lookup="match_key_value" vheck_value="^block">etc/lists/list-user</list>
In case the field i an IP address,you must use not_address_match_key:
<list field="srcip" lookup="address_match_key_value" check_value="^reject">etc/lists/list-IP</list>


=======		Contribute to the ruleset
In our repository you will find that most of the rules contain one or more groups called pci_dss_X
This is the PCI DSS control related to the rule. We have produced a document that can help you tag each rule with its corresponding PCI requirement: PCI tagging.

========		RESTful API
RA is an open source RESTful API that allows for interaction with the Wazuh manager from a web browser, command line tool like cURL or any script or program that can make web requests. The Wazuh Kibana app relies on this heavily and Wazuh's goal is to accommodate complete remote management of the Wazuh infrrastructure via the Wazuh Kibana app. Use the API to easily perform everyday actions like adding an agent, restarting the manager(s) or agent(s) or looking up syscheck details.


Wazuh API capabilities:
- Agent management
- Manager control & overiew
- Rootcheck control & search
- Syscheck control & serch
- Ruleset information
- Statistical information
- HTTPS and user authentication
- Error handling
- Query remote configuration


-------		Start
1. start/stop/restart
service wazuh-api start/status/stop/restart

2. Basic
The base URL for each request is https://IP:55000/ or http://IP:55000/, depending on whether or not SSL is enabled and set up in the API.
All responses are in JSON format with the following structure:

Field	Description
error	0 if everything was fine and an error code otherwise.
data	The data requested. Only if error is equal to 0.
message	The error description. Only if error is other than 0.

Responses containing collections of data will return a maximum of 500 elements. The offset and limit parameters may be used to iterate through large collections.
All responses have an HTTP status code: 2xx (success), 4xx (client error), 5xx (server error), etc.
All requests accept the parameter pretty to convert the JSON response to a more human-readable format.
The API log is stored on the manager as /var/ossec/logs/api.log. The API logs are rotated daily. The rotations are stored in /var/ossec/logs/api/<year>/<month> and compressed using gzip.
All API requests will be aborted if no response is received after a certain amount of time. The parameter wait_for_complete can be used to disable this timeout. This is useful for calls that could take more time than expected, such as PUT/agents/:agent_id/upgrade.

------		Use cases
---	Exploring the ruleset 
Often when an alert fires, it is helpful to know details about the rule itself. The following request enumerates the attibutes of rule 1002:
curl -u foo:bar -k -X GET "https://localhost:55000/rules/1002?pretty"

It can also be helpful to know what rules are available that match a specific criteria. For eample, all the rules with a group of web, a PCI tag of 10.6.1, and containing the word failures can be showed using the command bellow:
curl -u foo:bar -k -X GET "https://localhost:55000/rules?group=web&pci=10.6.1&search=failures&pretty"

---		Mining the file integrity monitoring database of an agent
The API can be used to show information about all monitored files by syscheck. The following exam
ple shows all modified .py files in agent 000(the manager):

curl -u foo:bar -k -X GET "https://localhost:55000/syscheck/000?event=modified&search=.py&pretty"
not working
You can find a file using its md5/sha1 hash. In the following wxamples, the same file is retrieved using both its md5 and sha1:

curl -u foo:bar "http://localhost:55000/syscheck/000?pretty&hash=17f51705df5b61c53ef600fc1fcbe031e4d53c20"

curl -u foo:bar "http://localhost:55000/syscheck/000?pretty&hash=39b88ab3ddfaf00db53e5cf193051351"

---	Listing outstanding rootcheck issues
Rootcheck requests are very similar to the syscheck requests. In order to gt all rootcheck issues with the outstanding status, run this request:

curl -u foo:bar "http://localhost:55000/rootcheck/000?status=outstanding&offset=10&limit=1&pretty"

---	Getting information about the manager
Some information about the manager can be retrieved using the API. Configuration, status, information,logs,etc. The following example retrieves the status of each daemon Wazuh runs:
curl -u foo:bar -k -X GET "https://localhost:55000/manager/status?pretty"

You can even dump the manager's current configuration with the request bellow (response shortened for brevity):

---
curl -u foo:bar -k -X GET "https://localhost:55000/manager/configuration?pretty"

---	Playing with agents
Here are some commands for working with the agents.
This enumerates active agents:
curl -u foo:bar -k -X GET "https://localhost:55000/agents?offset=1&limit=1&status=active&pretty"

---	Adding an agent is now easier than ever. Simply send arequest with the agent name and its IP.
curl -u foo:bar -k -X POST -d '{"name":"NewHost","ip":"10.0.0.9"}' -H 'Content-Type:application/json' "https://localhost:55000/agents?pretty"

----	Conclusion
We hope those examples have helped you to appreciate the potential ofthe Wazuh API.Remember to check out the reference document to discover all the available API requests . A nice summary can also be found here: https://documentation.wazuh.com/current/user-manual/api/reference.html#request-list

==========	Filtering data using queries
Advance filtering is possible using the Wazuh API's queries. Queries are specified using the q parameter. A query has the following structure:

. Field name: Field name to filter by. If an incorrect field name is used , anerror will be raised.
. Operator: Operator to filter by:
 - =: equality.
 - != : not equality 
 - <: smaller
 - >: bigger
 - ~: like as
.Value: Value to filter by.
.Separator: Operator to join multiple "queries":
 - ,: represents an OR.
 - ;: represents an AND.
Ex
Filtering agents by OS name and OS version
 For example, to filter Ubuntu agents with a version higher than 12:

curl -u foo:bar -k -X GET "https://localhost:55000/agents?pretty&q=os.name=ubuntu;os.version>12&select=id,name,os.name,os.version,os.codename,os.major"

---	Filtering rootcheck events by date
curl -u foo:bar -X GET "https://loclhost:55000/rootcheck/001?pretty&q=oldDay<3h25m&limit=2"

---------		Configuration
The API will bind to port 55000/tcp by default and requires userbane and password authentication. The default username and password is "foo" and "bar".
---	Configuration script
Run the script /var/ossec/api/scripts/configure_api.sh to configure the basic settings.

The script supports both unattended and attended configuration. To set the parameters of the unattended configuration use the file /var/ossec/api/configuration/preloaded_vars.conf.
This file will be removed after running the script to remove any sensitive information written there.

---	Configuration file 
You can configure certain API settings in the file /var/ossec/api/configuration/config.js

// Path 
config.ossec_path = "/var/ossec";
//The host to bind the API to.
config.host = "0.0.0.0";
// TCP Port used by the api.
CONFIG.PORT = "55000";
// USE http PROTOCOL over TLS/SSL. Values: yes, no.
config.https = "yes";
//Use HTTP authentication . Values: yes, no.
config.basic_auth = "yes";
// In case the API run behind a proxy server, turn to "yes" this feature. Values: yes, no.
config.BehindProxyServer = "no";

service wazuh-api restart

--- Basic Authentication
It is generally recommended that new credentials be created to replace foo:bar. This can be done very easily with the following steps, substituting your desired username for myUserName:


cd /var/ossec/api/configuration/auth
node htpasswd -c user myUserName
service wazuh-api restart

---	Manually enablee https support

cd /var/ossec/api/configuration/ssl
openssl genrsa -des3 -out server.key 1024
openssl req -new -key server.key -out server.csr

By default , the key's password must be entered every time you run the server. If you don't want to enter the password every time, you can remove it by running these commands:

cp server.key server.key.org
openssl rsa -in server.key.org -out server.key

- Next generate uour self-signed certificate:
opnssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt

----------		Reference
This API reference is organized by resources:
- Active Response
- Agents
- Cache
- Ciscat
- Cluster
- Decoders
- Experimental
- Manager
- Rootcheck
- Rules
- Syscheck
- Syscollector

---------		Request List
- Active Response
	PUT /active-response/:agent_id (Run an AR command in the agent)

- Agents
DELETE /agents (Delete agents)
DELETE /agents/:agent_id (Delete an agent)
DELETE /agents/:agent_id/group (Remove all agent groups.)
DELETE /agents/:agent_id/group/:group_id (Remove a single group of an agent)
DELETE /agents/groups (Delete a list of groups)
DELETE /agents/groups/:group_id (Remove group)
GET /agents (Get all agents)
GET /agents/:agent_id (Get an agent)
GET /agents/:agent_id/config/:component/:configuration (Get active configuration)
GET /agents/:agent_id/group/is_sync (Get sync status of agent)
GET /agents/:agent_id/key (Get agent key)
GET /agents/:agent_id/upgrade_result (Get upgrade result from agent)
GET /agents/groups (Get groups)
GET /agents/groups/:group_id (Get agents in a group)
GET /agents/groups/:group_id/configuration (Get group configuration)
GET /agents/groups/:group_id/files (Get group files)
GET /agents/groups/:group_id/files/:filename (Get a file in group)
GET /agents/name/:agent_name (Get an agent by its name)
GET /agents/no_group (Get agents without group)
GET /agents/outdated (Get outdated agents)
GET /agents/stats/distinct (Get distinct fields in agents)
GET /agents/summary (Get agents summary)
GET /agents/summary/os (Get OS summary)
POST /agents (Add agent)
POST /agents/insert (Insert agent)
POST /agents/restart (Restart a list of agents)
PUT /agents/:agent_id/group/:group_id (Add agent group)
PUT /agents/:agent_id/restart (Restart an agent)
PUT /agents/:agent_id/upgrade (Upgrade agent using online repository)
PUT /agents/:agent_id/upgrade_custom (Upgrade agent using custom file)
PUT /agents/:agent_name (Add agent (quick method))
PUT /agents/groups/:group_id (Create a group)
PUT /agents/restart (Restart all agents)
Cache
DELETE /cache (Clear group cache)
DELETE /cache (Delete cache index)
GET /cache (Get cache index)
GET /cache/config (Return cache configuration)
Ciscat
GET /ciscat/:agent_id/results (Get CIS-CAT results from an agent)
Cluster
GET /cluster/:node_id/configuration (Get node node_id’s configuration)
GET /cluster/:node_id/info (Get node_id’s information)
GET /cluster/:node_id/logs (Get ossec.log from a specific node in cluster.)
GET /cluster/:node_id/logs/summary (Get summary of ossec.log from a specific node in cluster.)
GET /cluster/:node_id/stats (Get node node_id’s stats)
GET /cluster/:node_id/stats/hourly (Get node node_id’s stats by hour)
GET /cluster/:node_id/stats/weekly (Get node node_id’s stats by week)
GET /cluster/:node_id/status (Get node node_id’s status)
GET /cluster/config (Get the cluster configuration)
GET /cluster/healthcheck (Show cluster health)
GET /cluster/node (Get local node info)
GET /cluster/nodes (Get nodes info)
GET /cluster/nodes/:node_name (Get node info)
GET /cluster/status (Get info about cluster status)
Decoders
GET /decoders (Get all decoders)
GET /decoders/:decoder_name (Get decoders by name)
GET /decoders/files (Get all decoders files)
GET /decoders/parents (Get all parent decoders)
Experimental
DELETE /experimental/syscheck (Clear syscheck database)
GET /experimental/ciscat/results (Get CIS-CAT results)
GET /experimental/syscollector/hardware (Get hardware info of all agents)
GET /experimental/syscollector/netaddr (Get network address info of all agents)
GET /experimental/syscollector/netiface (Get network interface info of all agents)
GET /experimental/syscollector/netproto (Get network protocol info of all agents)
GET /experimental/syscollector/os (Get os info of all agents)
GET /experimental/syscollector/packages (Get packages info of all agents)
GET /experimental/syscollector/ports (Get ports info of all agents)
GET /experimental/syscollector/processes (Get processes info of all agents)
Manager
GET /manager/configuration (Get manager configuration)
GET /manager/info (Get manager information)
GET /manager/logs (Get ossec.log)
GET /manager/logs/summary (Get summary of ossec.log)
GET /manager/stats (Get manager stats)
GET /manager/stats/analysisd (Get analysisd stats)
GET /manager/stats/hourly (Get manager stats by hour)
GET /manager/stats/remoted (Get remoted stats)
GET /manager/stats/weekly (Get manager stats by week)
GET /manager/status (Get manager status)
Rootcheck
DELETE /rootcheck (Clear rootcheck database)
DELETE /rootcheck/:agent_id (Clear rootcheck database of an agent)
GET /rootcheck/:agent_id (Get rootcheck database)
GET /rootcheck/:agent_id/cis (Get rootcheck CIS requirements)
GET /rootcheck/:agent_id/last_scan (Get last rootcheck scan)
GET /rootcheck/:agent_id/pci (Get rootcheck pci requirements)
PUT /rootcheck (Run rootcheck scan in all agents)
PUT /rootcheck/:agent_id (Run rootcheck scan in an agent)
Rules
GET /rules (Get all rules)
GET /rules/:rule_id (Get rules by id)
GET /rules/files (Get files of rules)
GET /rules/gdpr (Get rule gdpr requirements)
GET /rules/groups (Get rule groups)
GET /rules/pci (Get rule pci requirements)
Syscheck
DELETE /syscheck/:agent_id (Clear syscheck database of an agent)
GET /syscheck/:agent_id (Get syscheck files)
GET /syscheck/:agent_id/last_scan (Get last syscheck scan)
PUT /syscheck (Run syscheck scan in all agents)
PUT /syscheck/:agent_id (Run syscheck scan in an agent)
Syscollector
GET /syscollector/:agent_id/hardware (Get hardware info)
GET /syscollector/:agent_id/netaddr (Get network address info of an agent)
GET /syscollector/:agent_id/netiface (Get network interface info of an agent)
GET /syscollector/:agent_id/netproto (Get network protocol info of an agent)
GET /syscollector/:agent_id/os (Get os info)
GET /syscollector/:agent_id/packages (Get packages info)
GET /syscollector/:agent_id/ports (Get ports info of an agent)
GET /syscollector/:agent_id/processes (Get processes info)


---------		Python
You can also interact with the API using Python as shown below:
Code:
#!/usr/bin/env python
import json
import requests # to install requests, use: pip install requests

#Configuration
base_url = 'https://localhost:55000'
auth = requests.auth.HTTPBasicAuth('foo','bar')
verify = False
requests.packages.urllib3.disable_warnings()

# Request
url = '{0}{1}'.format(base_url, "/agents/000")
r = requests.get(url, auth=auth, params=None, verify=verify)
print(json.dumps(r.json(), indent=4, sort_keys=True))
print("status: {0}.format(r.status_code))


==============		Kibana app
==============
==============
The Wazuh app for Kibana lets you visualize and analyze Wazuh alerts stored in Elasticsearch. You can 
obtain statistics per agent, search alerts and filter using different visualizations. It integrates
with the Wazuh API to retrieve information about manager and agents configuration, logs, ruleset, groups and much more.

To install the app, you can follow our Elastic Stack installation guides (for Debian systems:https://documentation.wazuh.com/current/installation-guide/installing-elastic-stack/elastic_server_deb.html#install-kibana-app-deb )

This manual describes the configuration process to get it started and the different app features that you can use. In addition to this, you can find a troubleshooting and reference guide for quick access
 to some key solutions and configuration options.

---	Setting up the app
register the Wazuh RESTful API with the Wazuh app in Kibana:
1. 

==========	Kibana app
----------	Configuration file
The Wazuh app includes a configuration file 
/usr/share/kibana/plugins/wazuh/config.yml

----------	Basic option
def ind to use on the app. If there's no valid index patterns on Elasticsearch, the app will automatically create one with the name indicated in this option.
- def wazuh-alerts-3.x-*

--- timeout
max time the app will wait for an API response when making requests to it. It will be ignored if the value is set under 1500 milliseconds.
-def 8000

--- ip.selector
defines if the user is allowed to change the selected index pattern directly from the top menu bar.
- def true

--- ip.ignore
Disable certain index pattern names from neing available in index pattern selector from the Wazuh app. An empty list (the def value ) won't ignore any valid index pattern.
-def []
-allowed values: Array of strings. Eg:["wazuh-archives-*"]

--- xpack.rbac.enabled
en or disable x-pack RBAC security capabilities when using the app.

--- admin
en or dis adimn requests to the Wazuh API when using the app. This makes PUT, POST and DELETE requests available on the Dev tools tab.
- def: true

--- Monitoring
- wazuh.monitoring.enabled : true
en or dis the wazuh-monitoring index creation and/or visualization:
	. if true, the app will show the agents status visualization and will insert monitoring-related data.
	. if false, the app won't show the visualization and won't insert monitoring-related data.
	. if set to worker, the app will show the visualization, but won't insert monitoring- related data.

- wazuh.monitoring.frequency: 3600 ( any from 60 sec )
in seconds the app generates a new document on the wazuh-monitoring index.

--- Checks
- checks.pattern: true
en or dis the index pattern health check when opening the app.

- checks.template: true
template health check when opening the app

- checks.api : true
pai health check when opening the app.

- checks.setup : true
setup health check when opening the app.

-----	Extensions ( applied for newly inserted APIs on the Settings tab, not for the existing ones.

- extensions.pci : true
PCI DSS tab on Overview and agents

- extensions.gdpr: true
GDPR tan on Overview and Agents.

- extensions.audit: true
Audit tab on Overview and Agents.

- extensions.oscap: true
Open SCAP tab on Overview and Agents.

- extensions.ciscat: false
CIS-CAT tab on Overview and Agents.

- extensions.aws : false
AWS tab on Overview and Agents.

- extensions.virustotal: false
VirusTotal tab on Overview and Agents.

- extensions.osquery : false
Osquery tab on Overview and Agents.

--- Advanced index options. Calid if modified before starting the Kibana service for the very first time. (shards and replicas)
- wazuh.shards:1
starting from 1

- wazuh.replicas : 1
from 0

- wazuh-version.shards: 1
munber of shards to use for the wazuh-version index.
any from 1

- wazuh-version.replicas : 1
for the wazuh-version index

- wazuh.monitoring.shards: 5
mun of shards to use for the wazuh-monitoring-3.x-* indices.

- wazuh.monitoring.replicas: 1
number of replicas to use for the wazuh-monitoring-3.x-* indices.


==============	ossec.conf

---	active-response		manager,agent
	existing command is bound to one or more reles or rule types along with additional
	criteria for when to execute the command. No limit to the num of active responses 
	that can be used , however, each active resonse must be configured in its own
	separate <active-response> section.
	disabled
	Manager: command; 
	location - (n/a) local - runs command on the agent that generated the event;
			server - on the wazuh manager .
			defined-agent - on a specific agent id by agent_id.
			all - on all agents. Use with caution.
	agent_id - (n/a) - ID of the agent on which to execute the active response command; 
	level - ( n/ a ) minimum severity level required for the command to be executed;
	rules_group - (n/a) - defines rule group that a rule must belong to one for the 
	command to be executed;
	rules_id - (n/a) -Limits the command execution to only when one or more listed rules
	fire. When setting level, rules_group and rules_id together, the active response will be triggered always that any rule matches with one of these options. In other words, they are 
	accumultive options, not restrictive.; 
	timeout - how long in seconds before the reverse command is execcuted. 
		When repeated_offenders is used, timeout only applies to the first offense.
	Agent side : 
	repeated_offenders - (n/a) - timeouts in minutes for repeat offenders . This is a 
	comma-separated list of increasing timeouts that can contain a maximum of 5 entries;
		This option must be configured directly in the ossec.conf file of the agent, 
		even when using a manager/agent setup with centralized configuration
		of other settings via agent.conf . Apart from that, it has to be defined in the upper <active-response> section found in the configuration file .
	ca_store - ( wpk_root.pem) - Indicates the path to the root CA certificate.
	The agent needs the certificate with which the WPK was signed in order to be updated.;
	ca_verification - (yes) en or dis the WPK validation using the root CA certificate.
			If set to no the agent will accept any WPK package coming from the 
			manager.
	def: no
---	agentless		manager
		allows you to run integrity checks on systems without an agent installed.
		type - (n/a) - ssh_integrity_check_bsd [list of directories]
			[ssh_integrity_check_linux|ssh_generic_diff|ssh_pixconfig_diff] ;
		 frequency - (n/a) - controls the number of seconds between each check of the 
				agentless device.;
	host - (n/a) - defines the username and the name of the agentless host. ;
	state - (n/a) - Determines whether the type of check is periodic or periodic_diff ;
		[periodic|periodic_diff].
	arguments - (n/a) - Defines the arguments passed to the agentless check.;
Sample configuration 
<agentless>
	<type> ssh_integrity_check_linux</type>
	<frequency>300</frequency>
	<host>admin@192.168.1.108</host>
	<state>periodic_diff</state>
	<arguments>/etc /usr/bin/ /usr/sbin</arguments>
</agentless>


---	alerts			manager
		[log_alert_level|email_alert_level|use_geoip]
		-log_alert_level - (3) - minimum severity level for alerts that will be stored to alerts.log and / or alerts.json.
		-email_alert_level - (12) - min level for an alert to trigger an email.
		overrides granular email alert configuration.
		Individual rules can override this with the alert_by_email option which 
		forces an email alert regardless of gloval or granular alert level thresholds.
		-use-geoip -(n/a) - deprecated since version 2.0.
Default configuration
<alerts>
	<log_alert_level>3</log_alert_level>
	<email_alert_level>12</email_alert_level>
</alerts>

---	auth			manager
	[disabled|port|use_source_ip|force_insert|force_time|purge|use_password|ssl_agent_ca|
	ssl_verify_host|ssl_manager_cert|ssl_manager_key|ssl_auto_negotiate|ciphers|	
	limit_maxagents]
	-disabled (no) - Toggles the execution of the auth daemon on or off.
	-port -(1515) - tcp port number for listening to connections.
	-use_source_ip -(no) - Toggles the use of the client's source IP address or the
		use of "any" to add an agent.
	-force_insert -(no) Toggles whhether or not to force the insertion of an agent if there is a duplicate name or IP address.
	-force_time - (0) - When forcing to remove old agents with the same name or IP address
	, this options specifies that the deletion will be performed only if the agent's 
	keepalive has more than the defined number of seconds.
	0 - always force the deletion.
	-purge -(no) - Toggles the deletion of client keys on off when agents are removed.
	-use_password -(no) - Toggles shared password authentication on or off.
	When enabled, the shared password will be read from the /var/ossec/etc/authd.pass file
	If this file does not exist , a random password will be generated.
	-ssl_agent_ca (A full path) - Specifies the full path to the CA certificate used
		to verify clients.
	-ssl_verify_host - (no) - Toggles source host verification on and off when aCA certificate is specified. This means that the client source IP address will be validated using the Common Name field.
	-ssl_manager_cert - (/var/ossec/etc/sslmanager.cert) - specifies the full path to the server ssl certificate.
	-ssl_manager_key (/var/ossec/etc/sslmanager.key) - server's SSL key.
	-ssl_auto_negotiate (no) - Toggles whether or not to auto select the SSL/TLS method.
	By def only TLS v1.2 is allowed. When set to yes the system will negotiate the most secure common methd with the client. In older systems , where the manager does not support TLS v1.2, this option will be enabled automatically.
	-ciphers - (HIGH:!ADH:!EXXP:!MD5:!PC4:!3DES:!CAMELLIA:@STRENGTH) - sets the list of
		ciphers for network communication using SSL.
	-limit_maxagents - (yes) - Toggles whether or not to operatte based on the maximum number of agents.

Default configuration.
<auth>
	<disableed>no</disabled>
	<port>1515</port>
	<use_source_ip>no</use_source_ip>
	<force_insert>no</force_insert>
	<force_time>0</force_time>
	<purge>no</purge>
	<use_password>no</use_password>
	<limit_maxagents>yes</limit_maxagents>
	<ciphers>HIGH:!ADH:....</ciphers>
	<!--<ssl_agent_ca></ssl_agent_ca> -->
	<ssl_verify_host>no</ssl_verify_host>
	<ssl_manager_cert>/var/ossec/etc/sslmanager.cert</ssl_manager_cert>
	<ssl_manager_key>/var/ossec/etc/sslmanager.key</ssl_manager_key>
	<ssl_auto_negotiate>no</ssl_auto_negotiate>
</auth>

---	client			agent
	This section explatins how to configure the connection to the manager.
	-server - configures the connection parameters for each server an agent connects to.
		-address(n/a)|port(1514)|protocol(udp)
	Options:
	-server-ip|server-hostname|port|protocol|config-profile|notify_time|time-reconnect|local_ip|disable-active-response|auto_resart|crypto_method
	-server-ip (n/a) - any wazuh manager IP.
	-server-hostname - manager hostname.
	-port (1514) - 1..65535
	-protocol - Deprecated since version 3.0.0.
	-config-profile (n/a) - Specifies the agent.conf profile(s) to be used by the agent.
		Multiple profiles can be included, separated by a comma and a space.
	-notify_time (60) - time in sec between agent checkins to the manager.
			(Shared agent.conf)
	-time-reconnect (300) - time in sec before a reconnection is attempted. This should
		be set to a higher number than the notify_time parameter.
	-local_ip - (n/a) - which IP addr will be used to communicate with the manager when the agent has multiple network interfaces.
	-disable-active-response (no) - obsolete method to disable active response.
	-auto_restart - (yes) - Toggles on and off the automatic restart of agents when a new valid connfiguration is received from the manager.
	-crypto_method - (aes) - encryption of the messages that the agent sends to 
		the manager.
Sample configuration.
<client>
	<server>
		<address>192.168.1.100</address>
		<port>1514</port>
		<protocol>tcp</protocol>
	</server>
	<server>
		<address>ex.hostname</address>
		<protocol<udp</protocol>
	</server>
	<config-profile>webserver, debian8</config-profile>
	<notify_time>30</notify_time>
	<time-reconnect>120</time-reconnect>
	<auto_restart>yes</auto_restart>
</client>

---	client_buffer		agent
	Options:
	[disabled|disable|queue_size|length|events_per_second]
	disabled - (no) - agent buffer on and off. When set to yes, the agent will send 
		events to the manager without any congestion control.
	-disable (deprecated since version 3.1.0.)
	-queue_size - (5000) - Sets the capacity of the agent buffer in number of events.
	-length (5000) - deprecated since 3.0.0
	-events_per_second - (500) 
Deffault configuration
<client_buffer>
	<!-- Agent buffer options -->
	<disabled>no</disabled>
	<queue_size>5000</queue_size>
	<events_per_second>500</events_per_second>
</client_buffer>

---	cluster			manager
	Options:
	[name|node_name|node_type|key|port|bind_addr|nodes|hidden|disabled]
	-name - (wazuh) -Specifies the name of the cluster this node belongs to.
	-node_name - (node01) - Specifies the name of the current node of the cluster.
		Each node must have a unique name . Else will be rejected.
	-node_type - (master) [master,worker] - role
	-key - (n/a) - Defines the key used to encrypt the communication between the nodes.
		This key must be 32 characters long. Refer to the Deploying a Wazuh 
		cluster for information on how to generate a key.
	-interval - (2m) - Deprecated since version 3.2.3. Sets the interval between cluster
			synchronizations.
	-port - (1515) - Specifies the port use for the cluster communications.
	-bind_addr - (0.0.0.0) - which IP address will communicate with the cluster when 
			the node has multiple network interfaces.
	-nodes - (NODE_IP) - Lists all master modes in the cluster using the <node> 
				tag for each one.
	-hidden - ( no ) - Toggles whether or not to show information about the cluster that generated an alert. If this is set to yes, information about the cluster that generated the event won't be included in the alert.
	-disabled (yes) - en or dis cluster.
Sample configuration.
<cluster>
	<name>wazuh</name>
	<node_name>manager_01</node_name>
	<node_type>master</node_type>
	<key>ladfjkjavnadkfj</key>
	<port>1516</port>
	<bind_addr>0.0.0.0</bind_addr>
	<nodes>
		<node>master</node>
	</nodes>
	<hidden>no</hidden>
</cluster>

---	command			manager
	Defined command that will be used by one or more active responses.There is no limit on the number of commands that may be used by an active response , however, each one must be in 
		its own separate <command> section.
	Options:
	-name - (n/a) - name of the command which is called in the active-response section.
	-executable - (n/a) - [any file name] Name an executable file to run from the 
		/var/ossec/active-response/bin directory. It is not necessary to provide the
			path.
	-expect - (n/a) - list of extracted felds that are to be passed as parameters to the command . If any of the listed fields were not extracted in  a certain instance, those field values would be passed as a dash (-) instead of as no value at all.
	A good example is the firewall-block command which expects the srcip field in order to knows which IP address to block. Multiple expected field names are comma separated.

	-extra_args - (n/a) - allows the user to customize the parameters sent to the active response script living on the agent side. [any extra argument to be read by the active-esponse scripts].
	-timeout_allowed -(no) - whether the command is stateful or stateless. If yes, the command is stateful, it will undo its original action after the period of time specified in the active response.

Sample configuration
<command>
	<name>custom_command</name>
	<executable>custom_script.sh</executable>
	<extra_args>-arg1 --arg2 arg3 ; cat /etc/passwd</extra_args>
	<timeout_allowed<yes</timeout_allowed>
</command>
<command>
	<name>win_route-null</name>
	<executable>route-null.cmd</executable>	
	<expect>srcip</expect>
	<timeout_allowed>yes</timeout_allowed>
</command>

---	database_output		manager
	MySQL and PostgreSQL database output is supported. It is configured with the options below.
	Options:
	-hostname - (n/a) - IP addr of the database server.
	-username - (n/a) - for access the database.
	-password - (n/a) - 
	-database - which to store the alerts.
	-type - (n/a) - [mysql/postgresql]
	Wazuh must be compiled with the database type that is to be used.
Example of configuration
<database_output>
	<hostname>192.168.1.122</hostname>
	<username>MySQLadmin</username>
	<password>secret1234</password>
	<database>Alerts_DB</database>
</database_output>

---	email_alerts		manager
	This extends the email options configured in the <global> section.
	Options:
	-email_to - (n/a) - single email addr to which to send email alerts. If you want to send alerts to multiple addr , each addr must be listed in a separate <email_to> section. Lists are not allowed.
	-level - (n/a) - [0..16] This is the minimum alert severity level ffor which emails will be sent.
	The level option should be set at or above the email_alert_level in the <alerts> section of the configuration.
	-group - (n/a) - limits the sending of emails to only when rules are tripped that belongs to one of the listed groups. Observe that all groups must be finished by comma.
	-event_location - the alert must match this event location to be forwarded . Do not specify this option repeatedly, as only the last instance would be used.
	-format - (full) - specifies the email format.[default|full|sms]
	-rule_id - (n/a) - limits the sending of emails to only when rules are tripped that 
		have one of the listed rule IDs.
	-do_not_delay - (n/a) - causes email alerts to be sent right away, rather than to be delayed for the purpose of batching multiple alerts together.
	-do_not_group - (n/a) - disables grouping of multiple alerts into the same email.
		do_not_delay and do_not_group are special empty-element XML tags, so 
		they stand alone, not having a starting and ending version of the tag. 
		This is indicated by the tag name containing "/" at the end of the name.
Example of configuration 
<email_alerts>	
	<email_to>recipient@example.wazuh.com</email_to>
	<email_to>recip2@gmail.com</email_to>
	<level>12</level>
	<group>sshd,</group>
	<do_not_delay/>
</email_alerts>


---	global			manager
	Global configuration generally applies to features that affect the system as a whole, rather than a specific component.
	Options:
	-alerts_log -(yes) - toggles the writing of alerts to /var/ossec/logs/alerts/alerts.log
	-email_notification -(no) - use of email alerting.
	-email_to -(n/a) - specifies the email recipient for alerts. Base configuration must be included in the section in order to use granular email configurations,.
	This  section allow only one record, but can be repeated for each email addr you would wish include.
	-email_from -(n/a) source address contained in the email alerts.
	-email_reply_to - (n/a)  - specifies the "reply_to" address contained in the email alerts
	-smtp_server - (n/a) - This option defines what SMTP server to use to deliver alerts
	-helo_server (notify.ossec.net) - how the ossec server will identify itself when sending mail.
	-email_maxperhour - (12) - max number of email alerts that can be sent per hout.All emails beyond this hourly threshold are then queued to be sent together in a single email at the end of the hour.Whether mail grouping is turned on or not.
	-email_idsname (n/a) - name will be added to the email headers with the specified value.
	-custom_alert_output - The values below may be used with this option to specify the format of the alerts that are written to alerts.log:
	$TIMESTAMP - time the event was processed by OSSEC.
	$ftell - Unknown
	$RULEALERT - unknown
	$HOSTNAME - hostname of the system generating the event.
	$LOCATION - The file the log messages were saved to.
	$RULEID - The rule id of the alert.
	$RULELEVEL - The rule level of the alert.
	$RULECOMMENT - Unknown
	$SRCIP - The source IP specified in the log message.
	$DSTUSER - The destination user specified in the log message.
	$FULLLOG - The original log message. 
	$RULEGROUP - The group containing the rule.

	-stats - (8) - Thes sets the severity level for events that are generated by statistical analysis. [0 to 16]
	-logall - (no) - This toggles whether to store events even when they do not trip  a rule with results written to /var/ossec/logs/archives/archives.log
	-logall_json - (no) - whether to store events even when they do not trip a rule with results written to /var/ossec/logs/archives/archives.json.
	-memory_size (8192) - memory size for the event correlation engine.
	-white_list - IP that should never be blocked with an active response and , though only one IP address can be included in this section ,you may repeat this as many times as needed to include additional IP addresses. (n/a)
	-host_information - (8) - severity level for events generated by the host change monitor.
	-jsonout_output - (no) - This toggles the writing of JSON-formatted alerts to /var/ossec/logs/alerts/alerts.json which would include the same events that would be sent to alerts.log, only in JSON format.
	-prelude_output - (no) - prelude output.
	-prelude_log_level - (0) - minimum alert level requirred to trigger prelude output.
	-prelude_profile -(OSSEC) - client anlyzer name.
	-zeromq_output - (n/a) - enables ZeroMQ output
	-zeromq_uri -  (n/a) - ZeroMQ URI for the publisher socket to bind to.
	This will listen for ZeroMQ subscribers on IP address 127.0.0.1:11111
	<zeromq_uri>tcp://localhost:11111</zeromq_uri>
	This will listen on port 21212 for ZeroMQ subscribers, binding to the IP address assegned to eth0.
	<zeromq_uri>tcp://eth0:21212</zeromq_uri>
	This will listen for zeromq on the Unix Domain socket /alerts-zmq.
	<zeromq_uri>ipc:///alerts-zmq</zeromq_uri>

	-geoipdb -(n/a) - This indicates the full path of the MaxMind GeoIP IPv4 database file location
	<geoipdb>/etc/GeouLiteCity.dat</geoipdb>
	
	-rotate_interval - (0 disabled) - New in version 3.1.0. interval between file rotation with nim_rotate_interval the highest allowed value
	<rotate_interval>10h</rotate_interval>
	-max_output_size - (0 disabled ) - New in version 3.3.0. size of the message input buffer in Analysisd (number of events).
	-queue_size - (16384) - New in version 3.3.0. size of the message input buffer in Analysisd (number of events)
Example
<queue_size>16384</queue_size>
Default configuration
<global>
	<jsonout_outpu>yes</jsonout_output>
	<alerts_log>yes</alerts_log>
	<logall>no</logall>
	<logall_json>no</logall_json>
	<email_notification>yes</email_notification>
	<smtp_server>smtp.ex.com</smtp_server>
	<email_from>ossec@ex.com</email_from>
	<email_to>recipient@ex.com</email_to>
	<email_maxperhour>12</email_maxperhour>
</gloval>

---	integration		manager
	This configures the manager to connect Wazuh to external APIs and alerting tools such as Slack, PagerDuty and VirusTotal.
	Options:
	-name - (n/a) - This indicates the service to integrate with.
	-hook_url - (n/a) - This is the URL provided by Slack when integration is enabled on the Slack side. This is mandatory for Slack.
	-api_key - (n/a) - the key that you would have retrieved from the PagerDuty or VirusTotal API. This is mandatory for PagerDuty and VirusTotal.
	Optional filters:
	-level - (n/a) - filters alerts by rule level so that only alerts with the specified level or above are pushed.
	-rule_id - (n/a) - filters alerts by rule ID.
	-group - (n/a) - filters alerts by rules. For the Cirustotal integration, only rules from the syscheck group are available. OS_Regex Syntax.
	-event_location - (n/a) - filters alerts by where the event originated . OS_Regex Syntax.
	-alert_format - (n/a) - weites the alert file in the JSON format. The Integrator makes use this file to fetch fields values.
	-max_log - (165) - max length of an alert snippet that will be sent to the integrator. Longer strings will be truncated with ...
Configuration example
<!-- Integration with Slack -->
<integration>
	<name>slack</name>
	<hook_url>https://hooks.slack.com/services/T000/B000/XXXXX</hook_url>
	<level>10</level>
	Ngroup>multiple_drops|authentication_failures</group>
	<alert_format>json</alert_format>
</integration>

<!-- Integration with VirusTotal -->
<integration>
	<name>virustotal</name>
	<api_key>VirusTotal_API_Key</api_key>
	<group>syscheck</group>
	<alert_format>json</alert_format>
</integration>

---	labels			manager,agent
	The labels section of ossec.conf allows additional user-defined information about agents to be included in alerts. When email notifications are enables, this additional data is also contained in the email alerts without any further configutation.
	Options:
	-label - additional info that will appear in alerts . Labels can be nested in JSON formatted alerts by separating the "key" terms bt a period.
	key	The title that will describe the info of the label.
		allowed value - any string
	hedden	For labels that are hidden by default.
		def val - no
		allowed val - yes, no
	In internal_options.conf, hidden labels can be set to be displayed in alerts.
Example of configuration.
<labels>
	<label key="aws.instance-id">i-052a1838c</label>
	<label key="aws.sec-group">sg-1103</label>
	<label key="network.ip">172.17.0.0</label>
	<label key="network.mac">02:42:ac:11:00:02</label>
	<label key="installation" hidden="yes">January 1st, 2018</label>
</labels>


---	localfile		manager,agent
	used to configure the collection of log data from files, Windows events, and from  the output of commands.
	Options:
	-location - location of the log or wild-carded group of logs to be read. strftime format strings may be used for log file names.
	file.loog-%Y-%m-%d
	may be used on non-Windows systems, but if the log file doesn't exist at the time
	ossec-logcollector is started , it will be added after logcollector.vcheck_files seconfs.
	-command - (n/a) - designates a command to be run . All output from this command will be read as one or more messages depending on whether cammand or full_command is used
	-alias - (n/a) - used to assign an alias to a command that will replace the command name in the log message.
	example
	<alias>usb-check</alias> would replace:
	ossec: output: 'reg QUERY HKLM\SYSTEM\CurrentControlSet\Enum\USBSTOR':
	with:
	ossec" output: 'usb-check':
	
	-frequency - (n/a) - spec the min amount of time in sec between command runs. The command will likely not repeat in the exact the num of sec specified , however, the time between runs will be no less than the number of seconds specified.
	This can be used with command or full_command.
	-only-future-events - (n/a) - used only with the eventchannel log format. By def Wazuh will  read all log content from agiven Windows Event Channel since the last time Wazuh was stopped. If this is set to yes Wazuh would then only receive events that occurred after the agent was started .
	-query - (n/a) - only with the eventchannel log format.You can identify an XPATH query following the event schema that will filter the events that Wazuh will process.

Ex
	<localfile>
		<location>System</location>
		<log_format>eventchannel</log_format>
		<query>Event/System[EventID=7040]</query>
	</localfile>

	-label - New in 3.0.0 . allows for addition of custom data in JSON events and is available when log_format is set to json.
	can be used as follows to identify the source of each log entry when monitoring several feles simultaneously:
<localfile>
	<location>/var/log/myapp/log.json</location>
	<log_format>json</log_format>
	<label key="@source|>myapp</label>
	<label key="agent.type">webserver</label>
</localfile>
This is a sample JSON object from the log file:

{
  "event": {
    "type": "write",
    "destination": "sample.txt"
  },
  "agent": {
    "name": "web01"
  }
}
The additional fields configured above would appear in the resulting event as below:

{
  "event": {
    "type": "write",
    "destination": "sample.txt"
  },
  "agent": {
    "name": "web01",
    "type": "webserver"
  },
  "@source": "myapp"
}

	-target (agent) - New in 3.3.0 - spec the name of the socket where the output will
		be redirected. The socket must be defined previosly to use it with this option.
	-log_format - (n/a) - spec the format of the log being read . It is equired field.
		For most of the text log files that only have one entry per line , syslog may be used.
		syslog(plain text)|json(JSON files)|snort-full|snort-fast|squid|iis|eventlog(win)|eventchannel|audit(auditd)|mysql_log|postgresql_log|nmapg|apache|command| command (read output from the command ( as run by root) spec by the command tag , each line as separate log)|
	full_command(entire output as log)|djb-multilog(read in format produced by the multilog sevice logger)| multi-line (monitor applications that log multiple lines per event;num of lines must be consistent in order to use this value;num of lines in each log entry must be spec,
	each line will e comined with the previous lines until all lines are;
	may be multiple timestamps in the final event.
	format for this value is : <log_format> multi-line:
	!!! Agents will ignore command and full_command log sources unless they have logcollector.remote_commands=1 set in their /var/ossec/etc/internal_optionas.conf or /var/ossec/etc/local_internal_options.conf file. This is a security precaution to prevent the WM from running arbitraty commands on agents in their root security context.

	-out_format - new in v3.3.0 - allows formatting logs from Logcollector using field substitution . Sybtax is: $(parameter)
	list of available parameters is:
	log-Message from the log.
	output- Output from a command.Alias of log.
	location - Path to the source log file 
	command - command line or alias defined for the command. Alias of location.
	timestamp - Current timestamp (when the log is sent), in RFC3164 format.
	timestamp <format> Custom timestamp, in strftime string format.
	hostname - System's host name.
	Attributes:
	-target - selects a defined target to apply the output format.
Configuration examples
Linex configuration :
<!-- For monitoring log files -->
<localfile>
	<log_format>syslog</log_format>
	<location>/var/log/syslog</location>
</localfile>

<!-- For monitoring command output -->
<localfile>
	<log_format>command</log_format>
	<command>df -P</command>
	<frequency>360</frequency>
</localfile>

<!-- To use a custom target or format -->
<localfile>
	<log_format>syslog</log_format>
	<location>/var/log/auth.log</location>
	<target>agent,custom_socket</target>
	<out_format target="custom_socket">$(timestamp %Y-%m-%d %H:%M:%S): $(log)</out_format>
</localfile>

Windows configuration:
<!-- For monitoring Windows eventchannel -->
<localfile>
	<location>Security</location>
	<log_format>eventchannel</log_format>
	<only-future-events>yes</only-future-events>
	<query>Event/System[EventID != 5145 and EventID != 5156]</query>
</localfile>
 

---	logging			manager,agent
	Options:
	-log_format - (plain) - configure the format of internal logs.
	[json|plain,json|plain]
Default configuration
<logging>
	<log_format>plain</log_format>
</logging>

---	remote			manager
Example of configuration
<remote>
	<connection>syslog</connection>
	<port>514</port>
	<protocol>udp</protocol>
	<allowed-ip>192.168.1.0/24</allowed-ips>
	<local_ip>192.168.1.5</local_ip>
</remote>
<remote>
	<connection>secure</connection>
	<port>1514</port>
	<protocol>udp</protocol>
	<queue_size>16384</queue_size>
</remote>

---	reports			manager
	Configuration options for reporting of alerts.
	Options:
	-group|category|rule|level|location"srcip"|user|title|email_to|showlogs
	group - filter by group/category. It only accepts one group/category.
	-category - Filter by group/category.
	-rule - Rule ID to filter for.
	-level - (n/a) - alert level to filter for. The report will include all levels abeove and including level specified.
	-location - filter by the log location or agent name.
	- srcip - filter by the source ip of the event.
	- user - filter by the user name. This will match either the srcuser or dstuser
	-title - name of the report. Required field.
	-email_to - send to - required field.
	-showlogs - en or dis the inclusion of logs when creating the report
Example
<reports>
	<group>authentication_failed,</group>
	<srcip>192.168.1.10</srcip>
	<title>Auth_Report</title>
	<email_to>recip@example.com</email_to>
	<showlogs>yes</showlogs>
</reports>


---	rootcheck		manager,agent
	Conf options for policy monitoring and anomaly detection.
	OPtions:
	base_directory|ignore|rootkit_files|rootkit_trojans|windows_audit|system_audit|windows_apps|windows_malware|scanall|frequency|disabled|check_dev|check_files|check_if|check_pids|check_ports|check_sys|check_trojans|check_unixaudit|check_winapps|check_winaudit|check_winmalware|skip_nfs

	-base_directory    The base directory that will be prepended to the following options:
		rootkit_files
		rootkit_trojans
		systems_audit
	-ignore - files or dirs to be ignored.(one entry per line).
	-rootkit_files - DB (/var/ossec/etc/shared/rootkit_files.txt)
	-rootkit_trojans - DB (/var/ossec/etc/shared/rootkit_trojans.txt)
	-windows_audit - Win audit definition file.
	-system_audit - path to an audit definition file for Unix-like systems.
	-windows_apps - path to a win app definition file.
	-windows_malware - path to a win malware definitions file.
	-scanall - tells rootcheck to scan the entire system.May lead to some false positivies
	-frequency - (36000) - in sec
	-disabled - dis of execution of rootcheck.
	-check_dev - (yes) - en or dis checking of /dev
	-check_files - (yes) - en or dis the checking of files.
	-check_if - (yes) - en or dis the checking of network interfaces.
	-check_pids - (yes) - en or dis the checking of process ID's
	-check_ports - (yes) - en or dis checking of network ports
	-check_sys - (yes) - en or dis checking for anomalous file system objects.
	-check_trojans - (yes) - en or dis checking for trojans.
	-check_unixaudit - (yes) - en or dis checking of unixaudit.
	-check_winapps - (yes) -en or dis the checking of winapps.
	-check_winaudit - (yes) - en or dis the checking of winaudit.
	-check_winmalware - (yes) - en or dis checking for win malware.
	-skipnfs - (yes) - en or dis the scanning of network mounted filesystems (Works on Linux and FreeBSD).
	Currently,skip_nfs will exclude checking files on CIFS or NFS mounts.
Default Unix configuration
<@-- Policy monitoring -->
<rootcheck>
	<disabled>no</disabled>
	<check_unixaudit>yes</check_unixaudit>
	<check_files>yes</check_files>
	<check_trojans>yes</check_trojans>
	<check_dev>yes</check_dev>
	<check_sys>yes</check_sys>
	<check_pids>yes</check_pids>
	<check_ports>yes</check_ports>
	<check_if>yes</check_if>
	<!-- Frequency that rootcheck is executed - every 12 hours -->
	<frequency>43200</frequency>
	<rootkit_files>/var/ossec/etc/shared/rootkit_hiles.txt</rootkit_files>
	<rootkit_trojans>/var/ossec/etc/shared/rootkit_trojans.txt</rootkit_trojans>

	<system_audit>/var/ossec/etc/shared/system_audit_rcl.txt</system_audit>
	<system_audit>/var/ossec/etc/shared/system_audit_ssh.txt</system_audit>
	<system_audit>/var/ossec/etc/shared/cis_debian_linux_rcl.txt</system_audit>

	<skip_nfs>yes</skip_nfs>
</rootcheck>


---	ruleset			manager
	Conf for enabling or dis rules and decoders.
	-rule_include - load a single rule file.
	-rule_dir - load a dir of rules. files will be loaded in alphabetical order and any duplicate filenames will be skipped.
	-rele_exclude - exclude a single rule file.
	-decoder_include - load a single decoder file.
	-decoder_dir - load a directory of decoders . 
	-decoder_exclude - exclude a single decoder file
	-list - load a single CDB reference for use by other rules.
Example of configuration 
<ruleset>
	<rule_include>ruleset/rules/my_rules.xml</rule_include>
	<rule_dir pattern="+rules.xml$">ruleset/rules</rule_dir>
	<rule_exclude>0215-policy_rules.xml</rule_exclude>
	<decoder_include>ruleset/decoders/my_decoder.xml</decoder_include>
	<decoder_dir pattern=".xml$">ruleset/decoders</decoder_dir>
	<decoder_exclude>ruleset/decoders/my_decoder.xml</decoder_exclude>
	<list>etc/lists/blocked_hosts</list>
</ruleset>

---	socket			manager,agent
	Conf or defining output sockets.
	Options
	-name - required field.
	-location - required - path of the socket.
	-mode - unix SOCKET COMMUNICATION PROTOCOL.
	-prefix - (n/a) - The prefix is placed before the message.
Example
<socket>
	<name>custom_socket</name>
	<location>/var/run/custom.sock</location>
	<mode>tcp</mode>
	<prefix>custom_syslog:</prefix>
</socket>

---	syscheck		manager,agent
	Conf for file integrity monitoring.
	-directories - add or remove dirs to be monitored . Must be comma separated.
		all files and subdirs will be monitored too.
		Drive letter without dirs are not valid. At a minimum the '.' should be included (d:\.)
		def(/etc,/usr/bin,/usr/sbin,/bin,/sbin
		Attributes:
		realtime
		realtime	
This will enable real-time/continuous monitoring on Linux (using the inotify system calls) and Windows systems.

Real time only works with directories, not individual files.
Allowed values	yes, no
whodata	This will enable who-data monitoring on Linux and Windows systems.
Allowed values	yes, no
report_changes	Report file changes. This is limited to text files at this time.
Allowed values	yes, no
check_all	All attributes with the prefix check_ will be activated.
Allowed values	yes, no
check_sum	
Check the MD5, SHA-1 and SHA-256 hashes of the files.

Same as using check_md5sum="yes", check_sha1sum="yes" and check_sha256sum="yes" at the same time.
Allowed values	yes, no
check_sha1sum	Check only the SHA-1 hash of the files.
Allowed values	yes, no
check_md5sum	Check only the MD5 hash of the files.
Allowed values	yes, no
check_sha256sum	Check only the SHA-256 hash of the files.
Allowed values	yes, no
check_size	Check the size of the files.
Allowed values	yes, no
check_owner	
Check the owner of the files.

On Windows, uid will always be 0.
Allowed values	yes, no
check_group	
Check the group owner of the files/directories.

Available for UNIX. On Windows, gid will always be 0 and the group name will be blank.
Allowed values	yes, no
check_perm	
Check the UNIX permission of the files/directories.

On Windows, this will only check the POSIX permissions.
Allowed values	yes, no
check_mtime	
Check the modification time of a file.

New in version 2.0.
Allowed values	yes, no
check_inode	
Check the file inode.

Available for UNIX. On Windows, inode will always be 0.

New in version 2.0.
Allowed values	yes, no
restrict	
Limit checks to files containing the entered string in the file name.

Any directory or file name (but not a path) is allowed
Allowed value	sregex
tags	
Add tags to alerts for monitored directories.

New in version 3.6.0.
Allowed values	Tags list separated by commas
recursion_level	
Limits the maximum level of recursion allowed.

New in version 3.6.0.
Allowed values	Any integer between 0 and 320

	-ignore - files or dirs to be ignored (one entry per line). Multiple lines may be entered to include multiple files or dirs. These files and dirs are still checked,but the results are ignored.
		type - simple regex pattern to filter out files so alerts are not generated.
	-nodiff - (any file name) - list of files to not compute the diff (one per line). 
		could be used for sensitive files like a private key, credentials stored in a file or db conf , avoidinng data leaking by sending the file content changes through alerts.
		ex: /etc/ssl/private.key
		type - simple regex pattern to filter out files so alerts are not generated.
	-frequency - (21600) - Frequency that the syscheck will be run(in sec)
	-scan_time - (n/a) - time to run the scans. (9pm or 8:30)
	-scan_day - (n/a) - day of the week to run the scans (one per line).
	-auto_ignore - (no) - whether or not syscheck will ignore files that change too many times (manager only)
		Attributes:

frequency	Number of times the alert can be repeated in the’timeframe’ time interval.
Default value	10
Allowed values	Any number between 1 and 99.
timeframe	Time interval in which the number of alerts generated by a file accumulates.
Default value	3600
Allowed values	Any number between 1 and 43200.

	-alert_new_files - (no) - spec if syscheck should alert when new files are created.
	-scan_on_start - (yes) - spec if syscheck scans immediately when started.
	-windows_registry - (hkey_local_machine\Softwar) spec win reg entries . 
	-registry_ignore - (n/a) -list of registry entries to be ignored. 
	-prefilter_cmd - (n/a) - run to prevent prelinking from creating false positives.
		ex: <prefilter_cmd>/usr/sbin/prelink -y</prefilter_cmd>
	-skip_nfs - if sycheck should scan network mounted filesystems (on LIn and FreeBsd)
		Currently, skip_nfs will exclude checking files on CIFS or NFS mounts.
	-remove_old_diff - (yes) - New in 3.4.0 - spec if Syscheck should delete the local snapshots that are not currently being monitorized.
	-restart_audit - (yes) - new in 3.5.0 - allow the system to restart auditd after installing the plugin. Note that setting this field to no the new whodata rules won't be applied automatically.
	-windows_audit_interval - (5 min) - freq with which the win agent will check that the SACLs of the directories monitored in whodata mode are correct.
Default Unix configuration
<!-- File integrity monitoring -->
<syscheck>
	<disabled>no</disabled>
	<!-- Frequency that syscheck is executed default every 12 hours -->
	<frequency>43200</frequency>
	<scan_on_start>yes</scan_on_start>
	<alert_new_files>yes</alert_new_files>
	<auto_ignore frequency="10" timeframe="3600">no</auto_ignore>
	<directories check_all="yes">/etc,/usr/bin,/usr/sbin</directories>
	<directories check_all="yes">/bin,/sbin,/boot</directories>
	<ignore>/etc/mtab</ignore>
	<ignore>/etc/hosts.deny</ignore>
	<ignore ....
	<nodiff>/etc/ssl/pro=ivate.key</nodiff>
	<skip_nfs>yes</skip_nfs>
	<remove_old_diff>yes</remove_old_diff>
	<restart_audit>yes</restart_audit>
</syscheck>

	
---	syslog_output		manager
	conf for sending alerts to a syslog server
	-server - ip
	-port - (514)
	-level
	-group
	-rule_id
	-location
		The location field refers to the origin of the alert, that it could be:
		syscheck|rootcheck|File path|Command or its alias| command_tag(wodle)
		aws-cloudtrail|cis-cat|vulnerability-detector|syscollector
	-use_fqdn - (no) - toggle for full or truncated hostname configured on the server.By default, ossec truncates the hostname at the first period ('.') when generating syslog messages.
	-format - (default) - format of alert output. When jsonout_output in global section 
		is enabled, alerts are read from alerts.json instead of alerts.log for JSON format.
	[cef|splunk|json|default]
Example of configuration 
<syslog_output>
	<server>192.168.1.3</server>
	<level>7</level>
	<format>json</format>
</syslog_output>
---	wodle name="open-scap"	manager,agent
	conf of the OpenSCAP wodle.
		Options	Allowed values		Default
		disabled	yes, no		no
		timeout	A positive number (seconds)	1800
		interval	A positive number	1d
		scan-on-start	yes, no			yes
		content	N/A				define an evaluation.
		type:xccdf or oval
		path: use specified policy file (DataStream,XCCDF or OVAL)
		timeout: Timeout for the evaluation (in sec)
		xccdf-id:	XCCDF id.
		oval-id: 	OVAL id
		datastream-id:	
		cpe:	CPE dictionary file
			def path: /var/ossec/wodles/oscap/policies
		profile:	select profile.
example
<wodle name="open-scap">
	<timeout>1800</timeout>
	<interval>1d</interval>
	<scan-on-start>yes</scan-on-start>
	<content type="xccdf" path="ssg-cetos-7-ds.xml"/>
	<content type="xccdf" path="ssg-centos-6-ds.xml"/>
</wodle>


	
---	wodle name="command"	manager,agent
	conf of the command wodle.
	disabled - (no) - dis the command wodle.
	tag - (n/a) - descriptive name for the command.
	command - (n/a) - Path and arguments of the command to be executed.
	interval - (2s) - time between commands executions.
	run_on_start - (yes) - run command immediately when service is started.
	ignore_output - (no) - ignore the command output when executed.
	timeout - (n/a) - new in 3.2.2 - timeout for each command to wait for the end of the execution. Whether this parameter is set to 0 , it will wait indefinitely for the end of the process. However, if the timeout is other than 0, the execution will finished if it expires.
	verify_md5 - (n/a) - verify the binary MD5 sum.
	verify_sha1 - (n/a) - from 3.6.0
	verify_sha256
	skip_verification - (no) - run the command defined although the checksum does not match.
			Inthis case, the agent will log that the checksum verification failed
			but will run the application.
	---Centralized configuration
	Remote commands may be specified in the centralized configuration,however, they are disabled by default due to security reasons.
	When setting commands in a shared agent configuration, you must enable remote commands for Agent Modules.
	etc/local_internal_options.conf in the agent:
		wazuh_command.remote_commands=1
Example of configuration.
<wodle name="command">
	<disabled>no</disabled>
	<tag>test</tag>
	<command>/bin/bash /root/script.sh</command>
	<interval>1d</interval>
	<ignore_output>no</ignore_output>
	<run_on_start>yes</run_on_start>
	<timeout>0</timeout>
	<verify_md5>lakfj89249284w9..</verify_md5>
	<verify_sha1>d892dd39f9a8...</verify_sha1>
	<verify_sha256>283472...</verify_sha256>
</wodle>

---	wodle name="cis-cat"	--||--
	CIS-CAT wodle. From 3.1.0. 
	-Scheduling options:
	[scan-on-start|interval|day|wday|time]
		scan-on-start - (yes) - 
		interval - (1d) between CIS-CAT execution.
		day - (n/a) - from 3.5.0.
		wday - (n/a) - from 3.5.0. Not compatible with the dat option.
			[sun|mon|tue|wed|thu|fri|sat]
		time - (n/a) - from 3.5.0. Time of day to run execution.  [hh:mm]

	-Main options.
	disabled - (no)
	timeout - (1800) - IN case the execution takes longer that the specified timeout, it stops.
	java_path - ($PATH) - 
	ciscat_path - (wodles/ciscat) - where CIS-CAT is located.
	content - Define an evaluation.You can only run assessments for XCCDF policy files.
		Attributes:
		path - policy file.
		timeout - in sec. overwrites the generic timeout.
		profile - select pofile . 
Example configuration
<wodle name="cis-cat">
	<disabled>no</disabled>
	<timeout>1800</timeout>
	<wday>monday</wday>
	<time>04:00</time>
	<interval>2w</interval>
	<scan-on-start>yes</scan-on-start>
	<java_path>/usr/bin</java_path>
	<ciscat_path>wodles/ciscat</ciscat_path>
	<content type="xccdf" path="benchmarks/CIS_Ubuntu_Linux_16.04_LTS_Benchmark_v1.0.0-xccdf.xml">
		<profile>xccdf_org.cisecurity.benchmarks_profile_Level_2_-_Server</profile>
	</content>
</wodle>

---	wodle name="aws-s3"	--||--
	-disabled - (no) - dis the CloudTrail wodle.
	-bucket - (n/a) - Name of the S3 bucket from where logs are read.
	-interval - (10m) - reading from the S3 bucket.
	-acccess_key - access key ID for the IAM user with the perm to read logs from the bucket.
	-secret_key - (n/a) - key created for the IAM user with the perm to read logs from the bucket.
	-remove_from_bucket - (yes) - del logs after it was read  by the wodle.
	-run_on_start - (yes) - 
	-skip_on_error - (yes) - if unable to process and parse a CloudTrail log skip the log and continue processing .
	-bucket type - 
Bucket options
Options	Allowed values	Mandatory/Optional
type	cloudtrail, custom	Mandatory
bucket\name	Any valid bucket name	Mandatory
bucket\aws_account_id	Comma list of AWS Accounts	Optional (only works with CloudTrail buckets)
bucket\aws_account_alias	Any string	Optional
bucket\access_key	Alphanumerical key	Optional
bucket\secret_key	Alphanumerical key	Optional
bucket\aws_profile	Any string	Optional
bucket\iam_role_arn	IAM role ARN	Optional
bucket\path	Prefix for S3 bucket key	Optional
bucket\only_logs_after	Date (YYYY-MMM-DDD, for example 2018-AUG-21)	Optional
bucket\regions	Comma list of AWS regions	Optional (only works with CloudTrail buckets)

Example of configuration.
<wodle name="aws-s3">
	<disabled>no</disabled>
	<remove_from_bucket>no</remove_from_bucket>
	<interval>10m</interval>
	<run_on_start>no</run_on_start>
	<skip_on_error>no</skip_on_error>
	<bucket type="cludtrail">
		<name>s3-dec-bucket</name>
		<access_key> KEY </access_key>
		<secret_key> sec </secret_key>
		<only_logs_after>2018-JUN-01</only_logs_after>
		<regions>us-east-1,us-west-1,eu-central-1</regions>
		<path>/dev1/</path>
		<aws_account_id>1234456789012</aws_account_id>
		<aws_accout_alias>dev1-account</aws_account_alias>
	</bucket>
	<bucket type="cloudtrail">
		<name>s3-dev-bucket</name>
		<access_key>insert_key</access_key>
		<secret_key>ins_key</secret_key>
		<only_logs_after></only_logs_after>
		<refions>us-east-1,us-west-1,eu-central-1</regions>
		<path>/dev2</path>
		<aws_account_id>2323</aws_account_id>
		<aws_account_alias>dev2-account</aws_account_alias>
	</backet>
	<bucket type="custom">
		<name>s3-stage-bucket</name>
		<aws_profile>stage-creds</aws_profile>
		<aws_account_id>12314243</aws_account_id>
		<aws_account_alias>stage-account</aws_account_alias>
	</bucket>	
	<bucket type="custom">
		<name>s3-prod-bucket</name>
		<iam_role_arn>arn:aws:iam::010203040506:role/ROLE_SVC_Log-Parser</iam_role_arn>
		<aws_account_id>111122222333</aws_account_id>
		<aws_account_alias>prod-account</aws_account_alias>
	</bucket>
</wodle>


---	wodle name="syscollector"	--||--
		Conf options of the Syscollector wodle for system inventory 
	disabled - (no) - 
	interval - (1h) - between system scan
	scan_on_start - (yes) -
	hardware - (yes) - enables the hardware scan.
	os - (yes) - OS scan.
	network - (yes) - net scan
	packages - (yes) - packages scan 
	ports - (yes) - enables the ports scan.
		with option all='no' it will only scan listening ports.
	processes - (yes) - processes scan 
Example configuration
<wodle name="syscollector">
	<disabled>no</disabled>
	<interval>1h</intercal>
	<scan_on_start>yes</scan_on_start>
	<hardware>yes</hardware>
	<os>yes</os>
	<network>yes</network>
	<packages>yes</packages>
	<ports all="no">yes</ports>
	<processes>yes</processes>
</wodle>
		
---	wodle name="vulnerability-detector"	manager
	Configuration options of the Vulnerability detector wodle.
	disabled
	interval - (5m) - character indicating a time unit: s (seconds), m (minutes), h (hours) or d (days).
	run_on_start - (yes) - 
	ignore_time - (6hours) - Time during wwhich vulnerabilities that have already been alered will be ignored.
	feed - conf block to specify vulnerability updates.
	Allowed tags:
		name: ubuntu 12|14|16|18
			redhat 5|6|7
			debian 7|8|9
		disabled yes,no
		update_interval (1hour)
		url - link to alternative OVAL file.
		path - path to an alternative OVAL file.
		allow - allows you to use the vulnerability database with agents with different OS.
		List of OS that will allow the use of this OVVAL.ex: "linux mint-12,ubuntu-17"
Example configuration
<wodle name="vulnerability-detector">
	<disabled>no</disabled>
	<interval>5m</interval>
	<run_on_start>yes</run_on_start>
	<feed nmae="debian-9">
		<disabled>no</disabled>
		<path>/home/debian-9-oval.xml</path>
		<update_interval>1h</update_interval>
	</feed>
	<feed name="redhat-7">
		<disabled>no</disabled>
		<url port="443">https://myserver.com/redhat-7-oval.xml</url>
		<update_interval>1h</update_interval>
	</feed>
	<feed name="ubuntu-16">
		<disbled>no</disabled>
		<update_interval>1h</update_interval>
		<allow>linux mint-18, ubuntu-15</allow>
	</feed>
</wodle>


---	wodle name="osquery"	manager,agent
	Conf oprions of the osquery wodle.
	disabled
	run_daemon - (yes) - makes the module run osqueryd as a subprocess or lets the module monitor the results log without running Osquery.
	bin_path - (empty) - full path to the folder that contains the osqueryd executable
	log_path - (/var/log/osquery/osqueryd.results.log) - full path to the results log written bt Osquery.
	config_path - (/etc/osquery/osquery.conf) - conf file.Can be relative to the folder where the Wazuh agent is running.
	add_labels - (yes) - add the agent labels defined as decorators.
	pack -(empty) - add a query pack to the configuration. 
Example of configuration.
<wodle name="osquery">
	<disabled>no</disabled>
	<run_daemon>yes</run_daemon>
	<bin_path>/usr/bin</bin_path>
	<log_path>/var/log/osquery/osqueryd.results.log</log_path>
	<cnfig_path>/etc/osquery/osquery.conf</config_path>
	<add_labels>no</add_labels>
	<pack name="custom_pack">/path/to/custom_pack.conf</pack>
</wodle>

---	wodle name="docker"	agent
	Configuration options of the Docker wodle.
	interval - (10m) - waiting time to rerun the wodle in case it fails.
	attempts - (5) - attempts to execute the wodle.
	run_on_start - (yes) - run command immediately when sevice is started.
	disabled - (no) - dis docker wodle.
Example of configuration
<wodle name="docker-listener">
	<interval>10m</interval>
	<attempts>5</attempts>
	<run_on_start>no</run_on_start>
	<disabled>no</disabled>
</wodle>


---	wodle name="azure-logs"	manager
	Configuration options of the Azure-Logs wodle.
Options	Allowed values
disabled	yes, no
interval	A positive number + suffix
run_on_start	yes, no
day	A day of the month
wday	A day of the week
time	A time of the day [hh:mm]
timeout	A positive number (seconds)
log_analytics	N/A
log_analytics\application_id	Any string
log_analytics\application_key	Any string
log_analytics\auth_path	File path
log_analytics\tenantdomain	Any string
log_analytics\request	N/A
log_analytics\request\tag	Any string
log_analytics\request\query	Any string
log_analytics\request\workspace	Any string
log_analytics\request\timeout	A positive number (seconds)
log_analytics\request\time_offset	A positive number + suffix
graph	N/A |
graph\application_id	Any string
graph\application_key	Any string
graph\auth_path	File path
graph\tenantdomain	Any string
graph\request	N/A
graph\request\tag	Any string
graph\request\query	Any string
graph\request\timeout	A positive number (seconds)
graph\request\time_offset	A positive number + suffix
storage	N/A
storage\account_name	Any string
storage\account_key	Any string
storage\auth_path	File path
storage\tag	Any string
storage\container	N/A
storage\container name	Any string
storage\container\blobs	Extension
storage\container\content_type	text, json_file or json_inline
storage\container\timeout	A positive number (seconds)
storage\container\time_offset	A positive number + suffix

Example of log_analytics configuration
<wodle name="azure-logs">

    <disabled>no</disabled>
    <day>15</day>
    <time>02:00</time>
    <run_on_start>yes</run_on_start>

    <log_analytics>

        <application_id>8b7...c14</application_id>
        <application_key>w22...91x</application_key>
        <tenantdomain>wazuh.onmicrosoft.com</tenantdomain>

        <request>
            <tag>azure-activity</tag>
            <query>AzureActivity | where SubscriptionId == "2d7...61d </query>
            <workspace>d6b...efa</workspace>
            <time_offset>36h</time_offset>
        </request>

    </log_analytics>

</wodle>


	graph
<wodle name="azure-logs">

    <disabled>no</disabled>
    <wday>Friday</wday>
    <time>12:00</time>
    <run_on_start>no</run_on_start>
    <timeout>1800</timeout>

    <graph>

        <auth_path>/Azure/graph_auth.txt</auth_path>
        <tenantdomain>wazuh.onmicrosoft.com</tenantdomain>

        <request>
            <tag>azure-active_directory</tag>
            <query>activities/audit?api-version=beta</query>
            <time_offset>1d</time_offset>
        </request>

    </graph>

</wodle>

	Storage
Example of storage configuration
<wodle name="azure-logs">

    <disabled>no</disabled>
    <interval>1d</interval>
    <run_on_start>yes</run_on_start>

    <storage>

        <auth_path>/home/manager/Azure/storage_auth.txt</auth_path>
        <tag>azure-activity</tag>

        <container name="insights-operational-logs">
            <blobs>.json</blobs>
            <content_type>json_file</content_type>
            <time_offset>24h</time_offset>
        </container>

    </storage>
</wodle>
Example of all integration

<wodle name="azure-logs">

    <disabled>no</disabled>
    <day>15</day>
    <time>02:00</time>
    <run_on_start>yes</run_on_start>

    <log_analytics>

        <application_id>8b7...c14</application_id>
        <application_key>w22...91x</application_key>
        <tenantdomain>wazuh.onmicrosoft.com</tenantdomain>

        <request>
            <tag>azure-activity</tag>
            <query>AzureActivity | where SubscriptionId == "2d7...61d </query>
            <workspace>d6b...efa</workspace>
            <time_offset>36h</time_offset>
        </request>

    </log_analytics>

    <graph>

        <auth_path>/Azure/graph_auth.txt</auth_path>
        <tenantdomain>wazuh.onmicrosoft.com</tenantdomain>

        <request>
            <tag>azure-active_directory</tag>
            <query>activities/audit?api-version=beta</query>
            <timeout>7200</timeout>
            <time_offset>1d</time_offset>
        </request>

    </graph>

    <storage>

        <auth_path>/home/manager/Azure/storage_auth.txt</auth_path>
        <tag>azure-activity</tag>

        <container name="insights-operational-logs">
            <blobs>.json</blobs>
            <content_type>json_file</content_type>
            <time_offset>24h</time_offset>
        </container>

    </storage>
</wodle>



Verifying configuration 
Syscheck/Rootcheck	/var/ossec/bin/ossec-syscheckd -t
local files 		/var/ossec/bin/ossec-logcollector -t
Wodles			/var/ossec/bin/wazuh-modulesd -t
global/rules/decoders (manager only)	/var/ossec/bin/ossec-analysisd -t
Client (agent only) 	/var/ossecc/bin/ossec-agentd -t


=================	Agent
	-	introduction
	A can be conf remotely by using the agent.conf file. Following capabilities can be conf remotely:
	FIC|RootKit detection|Log data collection(localfile)|Security policy monitoring (rootcheck, wodle name="open-scap",wodle name="cis-cat")|remote commands(wodle name="command")|anti-flooding mechanism(bucket options)|labels for agent alerts(labels)
	!
	When setting up remote commands in the shared agent configuration, you must enable remote commands for Agent Modules. This is enabled by adding the following line to the 
/var/ossec/etc/local_internal_options.conf file in the agent:
	wazuh_command.remote_commands=1

=================	Agent group
A can be grouped together in order to send them unique centralized conf that is group specific.
Each a can belong to more than one group and unless otherwise configured, all a belong to a 
group called default.

Manager pushes all files included in the group folder to the agents belonging this group.
Ex,all files in /var/ossec/etc/shared/default will be pushed to all A belonging to default group.

In case an agent is assigned to multiple groups, all the files contained in each group folder will be merged into one , and subsequently ent to the agents, being the last one the group with the highest priority.

The file ar.conf (active response status) will always be sent to agents even if it is not present in the group folder.

The agent will store the shared files in /var/ossec/etc/shared, not in a group folder.  

Below are the files that would be found in this folder on an agent assigned to the debian group. Notice that these files are pushed to the agent from the manager's /var/ossec/etc/shared/debian folder.

Manager
/var/ossec/etc/shared/
├── ar.conf
├── debian
│   ├── agent.conf
│   ├── cis_debian_linux_rcl.txt
│   ├── cis_rhel5_linux_rcl.txt
│   ├── cis_rhel6_linux_rcl.txt
│   ├── cis_rhel7_linux_rcl.txt
│   ├── cis_rhel_linux_rcl.txt
│   ├── cis_sles11_linux_rcl.txt
│   ├── cis_sles12_linux_rcl.txt
│   ├── custom_rootcheck.txt
│   ├── debian_ports_check.txt
│   ├── debian_test_files.txt
│   ├── merged.mg
│   ├── rootkit_files.txt
│   ├── rootkit_trojans.txt
│   ├── system_audit_rcl.txt
│   ├── system_audit_ssh.txt
│   ├── win_applications_rcl.txt
│   ├── win_audit_rcl.txt
│   └── win_malware_rcl.txt
└── default
    ├── agent.conf
    ├── cis_debian_linux_rcl.txt
    ├── cis_rhel5_linux_rcl.txt
    ├── cis_rhel6_linux_rcl.txt
    ├── cis_rhel7_linux_rcl.txt
    ├── cis_rhel_linux_rcl.txt
    ├── cis_sles11_linux_rcl.txt
    ├── cis_sles12_linux_rcl.txt
    ├── merged.mg
    ├── rootkit_files.txt
    ├── rootkit_trojans.txt
    ├── system_audit_rcl.txt
    ├── system_audit_ssh.txt
    ├── win_applications_rcl.txt
    ├── win_audit_rcl.txt
    └── win_malware_rcl.txt

Agent (Group: ‘debian’)
/var/ossec/etc/shared/
├── ar.conf
├── agent.conf
├── cis_debian_linux_rcl.txt
├── cis_rhel5_linux_rcl.txt
├── cis_rhel6_linux_rcl.txt
├── cis_rhel7_linux_rcl.txt
├── cis_rhel_linux_rcl.txt
├── cis_sles11_linux_rcl.txt
├── cis_sles12_linux_rcl.txt
├── custom_rootcheck.txt
├── debian_ports_check.txt
├── debian_test_files.txt
├── merged.mg
├── rootkit_files.txt
├── rootkit_trojans.txt
├── system_audit_rcl.txt
├── system_audit_ssh.txt
├── win_applications_rcl.txt
├── win_audit_rcl.txt
└── win_malware_rcl.txt

agent.conf is shown below along with the process for pushing the configuration from the manager to the agent.

agent.conf
The agent.conf is only valid on server installations.
The agent.conf may exist in each group folder at /var/ossec/etc/shared.
For example, for the group1 , it is in /var/ossec/etc/shared/group1. Each of these files 
	should be readable by the ossec user.

Options
	name	allows assegnment of the block to one particular agent.
	os allows assignmment of the block to an OS
	profile		profile name to a block.
Examples

<agent_config name=”agent01”>
...
<agent_config os="Linux">
...
<agent_config profile="UnixHost">

================	Centralized configuration process
Example
1. Configure the agent.conf file:
	Edit the file corresponding to the agent group.
<agent_config name="agent_name">
    <localfile>
        <location>/var/log/my.log</location>
        <log_format>syslog</log_format>
    </localfile>
</agent_config>

<agent_config os="Linux">
    <localfile>
        <location>/var/log/linux.log</location>
        <log_format>syslog</log_format>
    </localfile>
</agent_config>

<agent_config profile="database">
    <localfile>
        <location>/var/log/database.log</location>
        <log_format>syslog</log_format>
    </localfile>
</agent_config>

The profile option uses the values defined on the <config-profile> setting from the client configuration.

2. Run /var/ossec/bin/verify-agent-conf:

Each time you make a change to the agent.conf file, it is important tocheck for configuration errors. If any errors are reported by this check, they must be fixed before the next step. Failure to perform this step may allow errors to be pushed to agents which may prevent the agents from running. At that point, it is very likely that you will be forced to visit each agent manually to recover them.

3. Push the configuration to the agents:
Every 10 min , agent looks to see if a new version of agnet.conf is available from the manager. When a new version is, it pulls the new file.But it is not used by the agent until the next time the agent is restarted, as in step 5.

Restarting the manager will make the new agent.conf file available to the agents more quickly.

4. Confirm that the agent received the configuration:

The agent_groups tool or the API can show whether the group is synchronized in the agent:
curl -u foo:bar -X GET "http:/localhost:55000/agents/001/group/is_sync?pretty"

/vat/ossec/bin/agent_groups -S -i 001

5. Restart the agent:
By def , The agent restarts by itself when it receives a new shared config.

If auto_restart has been disabled (in the <client> section of Local configuration), the agent
	will have to be manually restarted so that the new agent.conf file will be used.
manager:
	/var/ossec/bin/agent_control -R -u 1032

=================	Precedence
1. When central conf is utilized, the local and the shared configuration are merged, however, the ossec.conf file is read before the shared agent.conf
2. last conf of any setting will overwrite the previous.
3. If file path for a particular setting is set in both , both paths will be included in the final conf

For example:

Let’s say we have this configuration in the ossec.conf file:

<rootcheck>
  <disabled>no</disabled>
  <check_unixaudit>no</check_unixaudit>
  <check_files>yes</check_files>
  <check_trojans>no</check_trojans>
  <check_dev>yes</check_dev>
  <check_sys>yes</check_sys>
  <check_pids>yes</check_pids>
  <check_ports>yes</check_ports>
  <check_if>yes</check_if>
  <system_audit>/var/ossec/etc/shared/system_audit_rcl.txt</system_audit>
</rootcheck>
and this configuration in the agent.conf file.

<rootcheck>
  <check_unixaudit>yes</check_unixaudit>
  <rootkit_files>/var/ossec/etc/shared/rootkit_files.txt</rootkit_files>
  <rootkit_trojans>/var/ossec/etc/shared/rootkit_trojans.txt</rootkit_trojans>
  <system_audit>/var/ossec/etc/shared/cis_debian_linux_rcl.txt</system_audit>
  <system_audit>/var/ossec/etc/shared/cis_rhel_linux_rcl.txt</system_audit>
  <system_audit>/var/ossec/etc/shared/cis_rhel5_linux_rcl.txt</system_audit>
</rootcheck>
The final configuration will overwrite check_unixaudit to “yes” because it appears in the agent.conf file. However, the path listed with the system_audit option will be repeated with both settings in the final configuration. In other words, system_audit_rcl.txt (from ossec.conf) and cis_debian_linux_rcl.txt (from agent.conf) will be included.

================	How to ignore shared configuration.
don't want to apply the shared conf in a specific agent, it can be disabled by adding the following line to the /var/ossec/etc/local_internal_options.conf file in that agent:
agent.remote_conf=0

===============	Download configuration files from remote location.
Wazuh manager has the capability to download configuration files like merged.mg as well as other files to be merged for the groups that you want to.

Need to put a yaml file named files.yml under the directory 
/var/ossec/etc/shared/.
groups:
    my_group_1:
        files:
            agent.conf: https://example.com/agent.conf
            rootcheck.txt: https://example.com/rootcheck.txt
            merged.mg: https://example.com/merged.mg
        poll: 15

    my_group_2:
        files:
            agent.conf: https://example.com/agent.conf
        poll: 200

agents:
    001: my_group_1
    002: my_group_2
    003: another_group

Here we can distinct the two main blocks: groups and agents
1. In the groups block we define the group name from which we want to download the files.
	- If the group doesn't exists, it will be created.
	- If a file has the name merged.mg, only this file will be downloaded. Then it will be calidated.
	- The poll label indicates the download eate in sec of the specified files.
2. In the agents block, we define for each agent the group to which we want it to belong.

This conf can be changed on the fly . The manager will reload the file and parse it again so there is no need to restart the manager every time

The info about the parsing is shown on the /var/ossec/logs/ossec.log file.
Ex:
Parsing is successful:
INFO: Successfully parsed of yaml file: /etc/shared/files.yml
File has been changed:
INFO: File '/etc/shared/files.yml' changed. Reloading data
Parsing failed due to bad token:
INFO: Parsing file '/etc/shared/files.yml': unexpected identifier: 'group'
Download of file failed:
ERROR: Failed to download file from url: https://example.com/merged.mg
Downloaded merged.mg file is corrupted or not valid:
ERROR: The downloaded file '/var/download/merged.mg' is corrupted.

==============	Internal configuration.
The main conf is located in the ossec.conf file, however some internal conf features are located in the /var/ossec/etc/internal_options.conf file.

Generally,this file is reserved foe debugging issues and for troubleshooting. Any error in this file may cause your installation to malfunction or fail to run.

!
This file will be overwritten during upgrades. In order to maintain custom changes, you must use the /var/ossec/etc/local_internal_options.conf file. 

	---Agent
	agent.tolerance
	agent.warn_level
	agent.normal_level
	agent.min_eps
	agent.rexv_timeout
	agent.state_interval
	agent.debug
	agent.remote_conf
	---Analysisd
	analysisd.default_timeframe (360)
	alakysisd.stats_maxdiff (stats max diff) 10..999999
	analysisd.stats_mindiff (1250) 10..999999
	analysisd.stats_percent_diff (150) 5..9999
	analysisd.fts_list_size (32) 12..512
	analysisd.fts_min_size_for_str (14) 6..128
	analysisd.log_fw (1) 0,1
	analysisd.decoder_order_size (64) 10..64
	analysisd.geoup_jsonout (0) 0,1
	analysisd.label_cache_maxage (0) 0..60
	analysisd.show_hidden_labels (0) 0,1
	analysisd.rlimit_nofile (16384) 1024..1048576
	analysisd.debug (0) 1-std 2-verbose
	analysisd.min_retate_interval (600) - min interval between log retate
	analysisd.event_threads (0) 0..32
	analysisd.syscheck_threads (0) 0..32
	analysisd.syscollector_threads (0) 0..32
	analysisd.rootcheck_threads (0) 0..32
	analysisd.hostinfo_threads (0) 0..32
	analysisd.rule_matching_threads(0) 0..32
	analysisd.decode_event_queue_size (16384) 128..2000000
	analysisd.decode_syscheck_queue_size (16384) 128..200000
	analysisd.decode_syscollector_queue_size (16384) 128..200000
	analysisd.decode_rootcheck_queue_size (16384) 128..200000
	analysisd.decode_rootcheck_queue_size
	analysisd.decode_hostinfo_queue_size (16384) 128..200000
	analysisd.decode_output_queue_size (16384) 128..200000
	analysisd.archives_queue_size (16384) 128..200000
	analysisd.statistical_queue_size (16384) 128..200000
	analysisd.alerts_queue_size (16384) 128..200000
	analysisd.firewall_queue_size (16384) 128..200000
	analysisd.state_interval (5) 0..86400

	---Authd
	authd.debug (0) [012]
	auth.timeout_seconds (1) 1..2147483647
	auth.timeout_microseconds (0) 0..999999
	
	---DBD
	dbd.reconnect_attempts (10) 1..9999
	
	---Execd
	excd.request_timeout (60) 1..3600
	execd.max_restart_lock (600) 0..3600
	execd.debug (0) [012]
	
	---Integrator
	integrator.debug (0) [012]
	
	---Logcollector
	logcollector.loop_timeout (2) 1..120
	logcollector.open_attempts (8) 0..998
	logcollector.remote_commands (0) 1- enable
	logcollector.vcheck_files (64) 0..1024
	logcollector.max_lines (10000) 100..100000
	logcollector.sample_log_length (64) 1..4096
	logcollector.debug (0) 1-std 2-verbose
	logcollector.input_threads (4) 1..128
	logcollector.queue_size (1024) 128..220000
	logcollector.max_files (1000)1..100000
	logcollector.rlimit_nofile (1100) 1024 .. 1048576
	logcollector.force_reload (0) 1-enable
	logcollector.reload_interval (64) 1..86400
	logcollector.reload_delay (1000) 0..30000

	---Maild
	maild.strict_checking (1) 0,1
	maild.grouping (1) 0,1
	maild.fill_subject (0) 0,1
	maild.geoup (1) 0,1

	---Monitord 
	monitord.day_wait (10) 0..600
	monitord.compress (1) 0,1
	monitord.sign (1) 0,1
	monitord.monitor_agents (1) 0,1
	monitord.rotate_log (1) 0,1
	monitord.keep_log_days (31) 0..500
	monitord.size_retate (512) 0..4096
	monitord.dily_rotations (12) 1..256
	monitord.debug (0) 1-std 2-verbose
	
	---Remoted 
	remoted.recv_counter_flush (128) 10..999999
	remoted.comp_average_printout (19999) 10..999999
	remoted.verify_msg_id (0) 0,1
	remoted.pass_empty_keyfile (1) 0,1
	remoted.secder_pool (8) 1..64
	remoted.request_pool (8) 1..64
	remoted.request_timeout (10) 1..600
	remoted.response_timeout (60) 1..3600
	remoted.request_rto_sec (1) 0..60
	remoted.request_rto_msec (0) 0..999
	remoted.max_attempts (4) 1..16
	remoted.shared_reload (10) 1..18000
	remoted.rlimit_nofile (16384) 1024..1048576
	remoted.recv_timeout (1) 1..60
	remoted.send_timeout (1) 1..60
	remoted.worker_pool
	remoted.keyupdate_interval (10) 1..3600
	remoted.debug (0) 1-std 2-verbose
	remoted.keyupdate_interval (10) 1..3600
	remoted.worker_pool (4) 1..16
	remoted.state_interval (5) 0 -disable , 1..86400
	remoted.guess_agent_group (0) 0,1

	---Syscheck
	syscheck.sleep (1) 0..64
	syscheck.sleep_after (100) 1..9999
	syscheck.rt_delay (10) 1..1000
	syscheck.max_fd_win_rt (256) 1..1024
	syscheck.default_max_depth (256) 1..320
	syscheck.debug (0) , 1-std , 2-verbose debug

	---Rootcheck
	root.check.sleep (50) 0..1000
	
	---Wazuh
	wazzuh.thread_stack_size (8192) 2048..65536
	
	---Wazuh Database
	W DB synchronization Module starts automatically on the server and local profiles and requires no configuration, however,some optional settings are available.

The module uses inotify from Linux to monitor changes to every log file in real-time. Db will be updated as soon as possible when a change is detected. If inotify is not supported, every log file will be scanned continuously, looking for changes, with a default delay of one minute between scans.
	
	---How  to disable the module 
	etc/local_internal_options.conf :
	wazuh_database.sync_agents=0
	wazuh_database.sync_syscheck=0
	wazuh_database.sync_rootcheck=0

	After conf saved --> wazuh-manager restart
	With the above settings, the Database synchronization Module will not be loaded when Wazuh starts.

	wazuh_database.sync_agents (1) 0,1
	wazuh_database.sync_syscheck (0) 0,1
	wazuh_database.sync_rootcheck (1) 0,1
	wazuh_database.full_sync (0) 0,1
	wazuh_database.real_time (1) 0,1
	wazuh_database.interval (60) 0..86400
	wazuh_database.max_queued_evnts (0) 0..2147483647
	
	---Wazuh Modules
	wazuh_modules.task_nice (10) -20..19
	wazuh_modules.max_eps (100) 1..1000
	wazuh_modules.debug (0) 1-std, 2- verbose debug 
		
	---Wazuh Command (0) 1-en remote commands

	---Wazuh-db (128) 1..1024
	wazuh_db.sock_queue_size (128) 1..1024
	wazuh_db.worker_pool_size (8) 1..32
	wazuh_db.commit_time (60) 1..3600
	wazuh_db.open_db_limit (64) 1..4096
	wazuh_db.rlimit_nofile (65536) 1024..10485776
	wazuh_db.debug (0) 1-std, 2-verbose

	---Windows
	windows.debug (0) 1-std , 2-verbose

===========	Daemons
	ossec-agentd(agent) client side daemon that communicates with the server.
	ossec-agentlessd(manager) runs integrity checking on systems where no agent is installed
	ossec-analysisd(manager) - receives log messages and compares them to the rules 
	ossec-authd(manager) -  Adds agents to the Wazuh manager 
	ossec-csyslogd(manager) - Forwards Wazuh alerts via syslog 
	ossec-dbd(manager) - Inserts alert logs into a database
	ossec-execd(manager,agent) - Executes active responses
	ossec-logcollector(manager,agent) - Monitors configured files and commands for new log messages 
	ossec-maild(manager) - sends Wazuh alerts via email 
	ossec-monitord(manager) - Monitors agent connectivity 
	ossec-remoted(manager) - Communicates with agents 
	ossec-reportd(manager) - Creates reports from Wazuh alerts 
	ossec-syscheckd(manager,agent) - Checks configured files for security changes 
	wazuh-clusterd(manager) - Manages the Wazuh cluster manager
	wazuh-modulesd(manager,agent) - Manages the Wazuh modules
	wazuh-db(manager) - Manages the Wazuh database
	ossec-integratord(manager) - Allows Wazuh to connect to external APIs and alering tools

-----		ossec-agentd
	The  ossec-agentd program is the client-side daemon that communicates with the server. It runs as ossec and is chrooted to /var/ossec
-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-D <dir>	Chroot to <dir>
Default value	/var/ossec
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a group.
-h	Display the help message.
-t	Test configuration.
-u <user>	Run as a specific user.
Default value	ossecm
-V	Display the version and license information

-----		ossec-agentlessd -allows integrity checks to be run on systems without an agent installed.

-c <config>	Read the configuration from file <config>
-D <dir>	Chroot to <dir>
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a group.
-h	Display the help message.
-t	Test configuration.
-u <user>	Run as a specific user.
-V	Display the version and license information

-----		ossec-analysisd - program receives the log messages and compares them to the rules. It then creates an alert when a log message matches an applicable rule.

-c <config>	Run using <config> as the configuration file.
-D <dir>	Chroot to <dir>.
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a group.
-h	Display the help message.
-t	Test configuration.
-u	Run as a specific user.
-V	Display the version and license information.

	How this works 
	1. The socket receives the message and sends it to the respective decoder queue. They can be one of the following:
	a. Syscheck event decoder queue.
	b. syscollector event 
	c. Rootchexk
	d. Hostinfo
	e. Event decoder queue.
	If the selected queue is full ,the event is dropped.
	2. Each decoder thread:
	a. Takes out the event from  it's queue.
	b. Cleans the event.
	c. Decodes the event.
	d. Sends the event to the rule matching queue.
		3. Each rule matching thread:
	a. Takes the event from the queue.
	b. Runs rule matching
	c. If the event is a firewall event, it is sended to the firewall queue.
	d. If the event has statistical flag, it is sended to the statistical queue.
	e. If the event has the fts FLAG, IT IS SENDED TO THE fts QUEUE.
	F. If an alert is generated , it is sended to the alert queue.
	g. If logall is activated, the event is sended to the archives queue.
		4. Each writer thread :
	a. Takes the event from the queue.
	b. Stores the element in memory to be written on it's own log file.
		4. Logging:
	a. Every 1 second , all the log files are writted to the HDD.
	b. Every 5 sec (by def, if not overrided), the status file for Analysisd is generated.

-----		Automatic leveling of the threads
	By default, when Analysisd starts it will spawn the number of threads based on the nunber of CPU cores of the machine where it's running. For example, if the machine has 4 physical cores, the following threads will be created:
	-4 threads for decoders (4 for Syscheck , 4 for Syscollector, 4 for Rootcheck, 4 for Hostinfo aand 4 for others)	
	-4 threads for rule matching.
	This def cinf can be changed on the internal_options.conf file by changing the fields from the :
analysisd.event_threads	Description	Number of event decoder threads.
Default value	0
Allowed value	0: Sets the number of threads according to the number of cpu cores.
Any integer between 0 and 32.
analysisd.syscheck_threads	Description	Number of Syscheck event decoder threads.
Default value	0
Allowed value	0: Sets the number of threads according to the number of cpu cores.
Any integer between 0 and 32.
analysisd.syscollector_threads	Description	Number of Syscollector event decoder threads.
Default value	0
Allowed value	0: Sets the number of threads according to the number of cpu cores.
Any integer between 0 and 32.
analysisd.rootcheck_threads	Description	Number of Rootcheck event decoder threads.
Default value	0
Allowed value	0: Sets the number of threads according to the number of cpu cores.
Any integer between 0 and 32.
analysisd.hostinfo_threads	Description	Number of hostinfo event decoder threads.
Default value	0
Allowed value	0: Sets the number of threads according to the number of cpu cores.
Any integer between 0 and 32.
analysisd.rule_matching_threads	Description	Number of rule matching threads.
Default value	0
Allowed value	0: Sets the number of threads according to the number of cpu cores.
Any integer between 0 and 32.

========		ossec-authd 
	THe ossec-authd program can automatically add an agent to a Wazuh manager and provide the key to the agent. The agent-auth application is the client application used with ossec-authd

ossec-authd creates an agent with an IP address of "any"instead of using a specific IP address.

!
By default, there is no authentication or authorization involved in this transaction, so it is recommended that this daemon only be run when a new agent is being added.

-V	Version and license message.
-h	This help message.
-d	Debug mode. Use this parameter multiple times to increase the debug level.
-t	Test configuration.
-f	Run in foreground.
-F <time>	Remove old agent with same name or IP if its keepalive has more than the specified number of seconds.
-g <group>	Group to run as.
Default	ossec
-D <dir>	Directory to chroot into.
Default	/var/ossec
-p <port>	Manager port.
Default	1515
-P	Enable shared password authentication, at /var/ossec/etc/authd.pass or random.
-c <ciphers>	SSL cipher list. The format of this parameter is described in SSL ciphers.
Default	HIGH:!ADH:!EXP:!MD5:!RC4:!3DES:!CAMELLIA:@STRENGTH
-v <path>	Full path to CA certificate used to verify clients.
-s	Used with -v, enable source host verification.
-x <path>	Full path to server certificate.
Default	/var/ossec/etc/sslmanager.cert.
-k <path>	Full path to server key.
Default	/var/ossec/etc/sslmanager.key.
-a	Auto negotiate the most secure common SSL/TLS method with the client.
Default	TLS v1.2 only (if supported by the server).
-L	Force insertion even though agent limit has been reached.

==========		ossec-csyslogd
	The ossec-csyslogd program forwards alerts via syslog.
-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-D <dir>	Chroot to <dir>
Default value	/var/ossec
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a group.
-h	Display the help message.
-t	Test configuration.
-u <user>	Run as a specific user.
Default value	ossecm
-V	Display the version and license information

===========		ossec-dbd
	The ossec-dbd program inserts the alert logs into a database . these alerts can be inserted into either postgresql or mysql.
	-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-D <dir>	Chroot to <dir>
Default value	/var/ossec
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a group.
-h	Display the help message.
-t	Test configuration.
-u <user>	Run as a specific user.
Default value	ossecm
-V	Display the version and license information

===========		ossec-execd
	The ossec-execd program runs active responses by initiating the configured scripts. It also handles the socket needed to perform remote upgrades in the agents.
-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a specific group.
-h	Display the help message.
-t	Test configuration.
-V	Display the version and license information

========			ossec-logcollector 
	monitors configured files and commands for new log messages.
	is now multi-threaded, achieving an improvement in overall performance. Each of the threads will read the first log that is not already handled by other threads and when it finishes reading, it will try to read the next available log (file or command)so that all the threads are always occupied

In addition, the intelocking problem that existed in the one-threaded version when it took a long time to read a log  while the rest were left unattended, is avoided. 

	The advantages of the multithreaded logcollector are only available from version 3.6.0
	and higher.

-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a specific group.
-h	Display the help message.
-t	Test configuration.
-V	Display the version and license information

========			ossec-maild 
	ossec-maild program sends alerts via email. It is started by ossec-control.

-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-D <dir>	Chroot to <dir>
Default value	/var/ossec
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a specific group.
-h	Display the help message.
-t	Test configuration.
-u <user>	Run as a specific user.
Default value	ossecm
-V	Display the version and license information

=========			ossec-monitord 
	monitors agent connectivity. In addition , it rotates and compresses internal logs daily or when they reach a certain configurable size.

-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-D <dir>	Chroot to <dir>
Default value	/var/ossec
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a group.
-h	Display the help message.
-n	Disable agent monitoring.
-t	Test configuration.
-u <user>	Run as a specific user.
Default value	ossecm
-w <sec>	Time in seconds to wait before rotating logs and alerts.
-V	Display the version and license information


==========			ossec-remoted 
		is the server side daemon that communicates with the agents . It runs as ossecr and is chrooted to /var/ossec by default.

-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-D <dir>	Chroot to <dir>
Default value	/var/ossec
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-g <group>	Run as a specific group.
-h	Display the help message.
-t	Test configuration.
-u <user>	Run as a specific user.
Default value	ossecm
-V	Display the version and license information
-m	Avoid creating shared merged file (read only)


===========			ossec-reportd 
		creates reports from Wazuh alerts. It accepts alerts on stdin and outputs a report on stderr.

!
Since the ossec-reportd daemon output to stderr, some utilities like less will not work if the
	output is not redirected. To do this, end the ossec-reportd with 2>&1 to redirect stderr to stdout. 
	Following this redirect, more or less can be used with ease.

-D <dir>	Chroot to <dir> .
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f <filter> <value>	Filter the results.
Allowed values	group
rule
level
location
user
srcip
filename
-g <group>	Group to run as (default: ossec).
-h	Display the help message.
-n <string>	Create a description for the report.
-r <filter> <value>	Show related entries.
-s	Show the alerts related to the summary.
-t	Test configuration.
-u <user>	User to run as (default: ossec).
-V	Display the version and license information




============			ossec-syscheckd 
	checks configured files for changes to the checksums, permisssions and ownership. It is run using ossec-control.

-c <config>	Run using <config> as the configuration file.
Default value	/var/ossec/etc/ossec.conf
-d	Run in debug mode. This option may be repeated to increase the verbosity of the debug messages.
-f	Run in the foreground.
-h	Display the help message.
-t	Test configuration.
-V	Display the version and license information


==============			wazuh-clusterd 
	manages the Wazuh cluster communications between the managers belonging to the cluster and synchromizes all files.

-h	Display the help message.
-d	Run in debug mode. Use twice to increase verbosity.
-f	Run in the foreground.
-r	Run as root. Use only for debugging purposes.
-V	Print version.


==============			wazuh-modulesd 
	manages the Wazuh modules described below.
	
	Database wodle
	Wazuh core uses list-based db to store info related to agent keys, and FIM/Rootcheck 
	event data. This info is highly optimized to be handled by the core.

	to provide well-sttructured data that can be accessed by the user or the Wazuh API ,
	 new SQLite-based db have been introduced in the Wazuh manager. The DB sync Module
	is a user-transparent component that collects th following info from the core:
	
	-Agent info : name, address, incryption key, last connection time, os, version 
		and shared conf hash
	-FIM data:creation, modification and deletion of regulat files and Win registry entries.
	-Rootcheck detected defects: issue message, first detection date and last alert time .
	-Static core settings: max peritted agents or SSL being enabled for Authd.

	OpenSCAP wodle 
	OSCAP module integrates a SCAP scanner into the wazuh agents providing security compliance under OpenSCAP policies as well as velnerability assessments, identification and classification of vulnerabilities.
	
	CIS-CAT wodle
	allows you to run CIS policy scans visualizing the results of assessments in the Wazuh App.

	Command wodle
	allows running external commands asynchronously, one in each thread
	
	Syscollector wodle
	performs periodic scans in the system to obtain info related to the installed hardware,os info , net info , installed packages, active ports, and running processes.

	AWS S3 wodle
	allows you to gather and parse logs from multiple AWS sevices , such as Guard Duty, Macie, VPC Flow , etc. 

	Vulnerability detector wodle
	this module detects applications that are known to be vulnerable (affected by a CVE)

	Osquery wodle 
	provides the user an os intrumentation tool that makes low-level os analytics and monitoring both efficient and intuitivae using SQL-based queries . 

-d	Basic debug mode.
-dd	Verbose debug mode.
-f	Run in the foreground.
-h	Display the help message.
-t	Test configuration.



===========			 wazuh-db

	Wazuh core uses list-based db to store info related to agent keys, and FIM/Rootcheck event data.

-d	Basic debug mode.
-dd	Verbose debug mode.
-f	Run in foreground.
-h	Display the help message.
-V	Version and license message.
-t	Test configuration.

----	Tables available for wazuh-db

scan_info
---------
Field	Description	Example
module	Module name	fim
first_start	First scan begin date	1538558233
first_end	First scan end date	1538556788
start_scan	Last scan start date	1538558233
end_scan	Last scan end date	1538558192
fim_first_check	Start date of first scan	1538558233
fim_second_check	Start date of two scans ago	1538556779
fim_third_check	Start date of three scans ago	1538555325

fim_entry
---------
Field	Description	Example
file	File name	/root/file
type	Type (file or registry)	file
date	Event timestamp	1538556788
changes	CPU name	0
size	File size	28179
perm	File permissions	100664
uid	User ID	1000
gid	Group ID	1000
md5	File MD5	6d9bd718faff778bbeabada6f07f5c2f
sha1	File SHA1	3ad067d8949ab0e20c220d7b1acb338190967acc
uname	Unix name	cervi
gname	Group name	cervi
mtime	Modify time	1536059852
inode	Inode number	14946484
sha256	File SHA256	09aaf47929660c513332aa2349bc66ce7ae710


metadata
--------
Data needed to upgrade the agent’s database

Field	Description	Example
key	Field name	version_major
value	Field value	3
Syscollector tables

Table	Description
sys_hwinfo	Stores information about the hardware of the system
sys_netiface	Stores information about the existing network interfaces of the system
sys_netaddr	Stores information about the IPv4 and IPv6 of the existing network interfaces
sys_netproto	Stores information about routing configuration for each interface
sys_osinfo	Stores information about the operating system
sys_ports	Stores information about the opened ports of a system
sys_processes	Stores information about the current processes running in the system
sys_programs	Stores information about the packages installed in the system


CIS-CAT table

Results of a CIS-CAT scan of an agent

Field	Description	Example
id	Unique identifier	12372
scan_id	Scan identifier	1701467600
scan_time	Scan time	2018-02-08T11:47:28.066-08:00
benchmark	Executed benchmark	CIS Ubuntu Linux 16.04 LTS Benchmark
profile	Profile inside benchmark executed	xccdf_org.cisecurity.benchmarks_profile_Level_2_-_Server
pass	Number of checks passed	98
fail	Number of fails	85
error	Number of errors	0
notchecked	Number of not checked	36
unknown	Number of unknown	1
score	Final score	53%


===========			ossec-integratord
	is a daemon that allows Wazuh to connect to external APIs and alerting tools such as Slack, VirusTotal and PagerDuty.

==========			ossec-integratord options
-d	Basic debug mode.
-dd	Verbose debug mode.
-f	Run in foreground.
-h	Display the help message.
-V	Version and license message.
-t	Test configuration.
-u <user>	Run as ‘user’
-g <group>	Run as ‘group’
-c <config>	Read the ‘config’ file
-D <dir>	Chroot to ‘dir’

===========		Tools
Tools	Descriptions	Supported installations
ossec-control	Manages the status of Wazuh processes	manager, agent
agent-auth	Adds agents to a Wazuh manager	agent
agent_control	
Allows queries of the manager to get information about

any agent
manager
manage_agents	
Provides an interface to handle authentication

keys for agents
manager, agent
ossec-logtest	Allows testing and verification of rules against provided log records	manager
ossec-makelists	Compiles cdb databases	manager
rootcheck_control	
Allows management of policy monitoring

and system auditing database
manager
syscheck_control	
Provides an interface for managing the integrity checking database

Deprecated since version 3.7.
manager
syscheck_update	
Updates the integrity check database

Deprecated since version 3.7.
manager
clear_stats	Clears the events stats	manager
ossec-regex	Validates a regex expression	manager
update_ruleset	Update Decoders, Rules and Rootchecks	manager
util.sh	Adds a file to be monitored by ossec-logcollector	manager agent
verify-agent-conf	Verifies the Wazuh agent.conf configuration	manager
agent_groups	Manages and assigns groups	manager
agent_upgrade	List outgraded agent and upgrade them	manager
cluster_control	Manages and retrieves cluster information	manager
fim_migrate	Migrates older FIM databases to Wazuh-DB	m

--------			agent-auth
	is the client app used with ossec-authd to add A to a WM

-A <A name> (hostname)
-a (TLS V1.2)
-c <ciphers> (HIGH:!ADH:!EXP:!MD5:!RC4:!3DES:!CAMELLIA:@STRENGTH)
-D (/var/ossec) - dir where Wazuh is installed
-d 	run in debug mode , to increase repeated it (-ddd)
-g <group> - run as a group
-G <gr> - set the group for centralized configuration.
-i 	Let A IP addr be set by the manager connection.
-I	agent IP set
-k <path> 	A key
-m <man_ip>	
-P <pass> 	use specified pass instead of searching for it at authd.pass
		If not provided in the file nor on the console 
		the client will connict to the server without a pass
-p <port> 	port ossec-authd is running on. (1515)
-t 	test conf
-V	version
-v <path>	full path to the CA ccertificate used to verify the srv.
-x <path> 		full path to the agent cert.

----------			agent_control
	allow to query the manager for info about A, or initiate syscheck/rootcheck scan on an agent 
	the next time it checks in.

	status [active|pending|disconnected|never connected]

-h	Display the help message
-l	List available agents whether they are active or not.
-lc	List only the currently connected agents.
-ln	List only the currently disconnected agents.
-i <agent_id>	Extract information from an agent
-R <agent_id>	Restart the Wazuh processes on the agent
-r	
Run the integrity/rootcheck checking on agents.

This must be used in conjunction with options -a or -u.
-a	Utilizes all agents
-u <agent_id>	Perform the requested action on the specified agent.
agent_control options for Active Response

-b <IP>	Blocks the specified IP address.
-f <ar>	Used with -b, specifies which response to run.
-L	List available active responses.
-m	Show the limit of agents that can be added.
-s	Change the output to CSV format (comma delimited).
-j	Change the output to JSON format.

-----------			manage_agents
	available in both a version for srv and A installations.
	easy-to-use interface to handle auth keys for Wazuh agents.

------------			ossec-control
used to start,stop,configure,or check on the status of Wazuh processes. This script can enable or disable client-syslog, the authentication daemon, cluster daemons , database logging, agentless configurations, integration with slack and pagerduty, and debug mode.

Recommend to use  systemctl| service for start^stop^restart the Wazuh servie. This will avoid inconsistencies between the service status and the processes status.

--------------			ossec-logtest
	tool for testing and verification of rules against provided log examples in a way that simulates the action of ossec-analysisd . Can assist with writing and debugging custom rules and troubleshooting false positives and negatives.

-a	Analysis of input lines as though they are live events.
-c <config>	Run using config as the configuration file.
Default Value	/var/ossec/etc/ossec.conf
-D <dir>	
Specifies the chroot before it completes loading all rules,decoders,

and lists and processing standard input.
-d	
Run as a Print debug output to the terminal. This option may be repeated

to increase the verbosity of the debug messages.group.
-h	Display the help message.
-t	
Test configuration. This will display file details on the rules to be loaded

by ossec-analysisd, decoders, and lists as they are loaded and the order

they were processed.
-U <rule-id:alert-level:decoder-name>	
This option will cause ossec-logtest to return a zero exit status if the test

results for the provided log line match the criteria in the arguments.

Only one log line should be supplied for this to be useful.
-V	Display the version and license information for Wazuh and ossec-logtest.
-v	Display the verbose results.

U ossec-logtest code requires access to all ossec configuration files.

-v is the key option to troubleshoot a rule or decoder problem.

-----------------		ossec-makelists
	to compile cdb db. This will scan ossec.conf for db files check the mtime, and recompile all out of date db.

-c <config>	Run with configuration file of config.
Default Value	/var/ossec/etc/ossec.conf
-D <dir>	Directory to chroot into.
Default value	/var/ossec
-d	Run in debug mode, may be repeated to increase the verbosity of the debug messages.
-F	Force the rebuild of all configured databases.
-g <group>	Run as a group.
-h	Display the help message.
-t	Test configuration.
-u <user>	Run as a user.
-V	Display the version and license information.

----------------		rootcheck_control

	allows for the management of the policy monitoring and system auditing db that is stored on the srv side.

	Anomalies detected by the rootcheck functionality can be listed, and categorized into resolved and outstanding issues.

	can also display the last time that ossec-rootcheck was run

-h	Display the help message.
-l	List the available agents.
-lc	List only the currently connected agents.
-ln	List only the currently disconnected agents.
-u <id> / -u all	Update the database for the identified or all agents.
-i <agent_id>	Print the database for the agent.
-r	Used with -i to print all the resolved issues.
-q	Used with -i to print all the outstanding issues.
-L	Used with -i print the last scan.
-s	Change the output to CSV format.
-j	Change the output to JSON format.

-----------		syscheck_update
	wipes the integrity check db. All info about files that were added to the integrity check db
	will be deleted leaving an empty db which will be populated again the mext time the syscheck
	daemon runs on the agents or the server.

-h	Display the help message.
-l	List the available agents.
-a	Update the database for all agents.
-u <id> / -u local	Update the database for the specified agent or the local database.

------------		clear_stats
	clears the events stats.

-h	Display the help message.
-a	Clear all the average stats.
-d	Clear the daily averages.
-w	Clear the weekly averages.

------------		ossec-regex 
	used to validate aregex expression.
	pattern should be enclosed in single quotes to help prevent any unintended interactions with the shell.

/var/ossec/bin/ossec-regex '<pattern>'

It then reads strings from stdin and outputs matches to stdout

+OSRegex_Execute and +OS_Regex are displayed if a match is successful.

-----------		update_ruleset
	updates decoders , rules and rootchecks.

-r	Restart Wazuh when needed.
-R	Do not restart Wazuh.
-b	Restore the last backup.
-h	Display the help message.
-f	Force Wazuh to update the ruleset.
-o	Set Wazuh path.
Default	/var/ossec
-s	Select ruleset source path (instead of downloading it).
-j	JSON output. Must be used in conjunction with the ‘-s’ option.
-d	Run in debug mode.
-n	Branch name (default: stable).

------------		util.sh

util.sh shell script can add a log file to be monitored by ossec-logcollector.
	It can also add a full_command to check for changes to a website, or for changes to the nameserver of a domain.

addfile <filename> [<format>]	
Add a log file to be monitored by ossec-logtest

A local file will be added to the ossec.conf
addsite <domain>	
Monitor a website for changes.

A full_command will be added to the ossec.conf using lynx to dump the initial page.

A rule can be written to monitor this output for changes.

Requires lynx
adddns <domain>	
Monitor the nameserver of a domain for changes.

A full_command will be added to the ossec.conf using the host command.

!
addsite may not be useful on pages with dynamic content.
!
addns requires the host command.

----------		verify-agent-conf
	verifies the Wazuh agent.conf configuration.
searches in /var/ossec/etc/shared
or
verify-agent-conf [-f <agent.conf file>]

-----------		agent_groups
	list A assigned to a G, 
	assigne A to G
	manage A G.

-h	Displays the help message
-q	Quiet mode (outputs no confirmation)
-d	Debug
-l	Lists all groups
-l -g group_id	Lists the agents in the group
-c -g group_id	Lists the configuration files in group
-a -g group_id [-q]	Creates a group
-r -g group_id [-q]	Removes a group (affects to all agents assigned to it)
-a -i agent_id -g group_id [-q]	Assigns group_id to the agent’s group list
-a -f -i agent_id -g group_id [-q]	Replaces the agent’s groups to group_id
-r -i agent_id [-q]	Remove an agent from all its groups
-r -i agent_id -g group_id [-q]	Remove an agent from a specific group
-s -i agent_id	Shows the groups of an agent
-S -i agent_id	Shows the shared files sync status of an agent

Examples
-create G
./agent_groups -a -g debian
-Assign G 'debian' to agent 002
./agent_groups -s -i 002

-list all A in G 'debian'
./agent_groups -l -g debian

-list configuration files in group 'debian':
./agent_groups -c -g debian

-remove A 002 from all G except the default:
./agent_groups -r -i 002

-remove A 003 from a specific group
./agent_groups -r -i 003 -g group2

-remove the group 'debian' from every agent:
./agent_groups -r -g debian

-add an agent to more than one group:
./agent_groups -a -i 001 -g group1
./agent_groups -a -i 001 -g group2

--------------		agent_upgrade
	agent_upgrade program allows you to list outdated agents and upgrade them . 

-h, –help	Display the help message.
-l, –list_outdated	Generates a list with all outdated agents.
-a AGENT_ID, –agent AGENT_ID	Agent ID to upgrade.
-d, –debug	Debug mode.
-F, –force	Allows reinstall same version and downgrade version.
-s, –silent	Do not show output.
-v VERSION, –version VERSION	Version to install.
-r REPOSITORY, –repository REPOSITORY	Specify a repository URL.
-f FILE, –file FILE	Custom WPK filename.
-x EXECUTE, –execute EXECUTE	Executable filename in the WPK custom file. By default it will try to launch upgrade.sh.
-t TIMEOUT, –timeout TIMEOUT	Timeout where the agent cannot restart while updating.
-c CHUNK_SIZE, –chunk_size CHUNK_SIZE	Chunk size sending WPK file.

	!
	By default, the timeout will be the maximum allowed by the agent with the execd.max_restart_lock
	option in internal_options.conf.
	
Examples:
-list outdated agents:
./agent_upgrade -l

-upgrade agent:
./agent_upgrade -a 002

-Downgrade agent using a custom repository:
./agent_upgrade -a 002 -dF -v v3.0.0 -r http://mycompany.wpkrepo.com/ -t 500

-Install custom WPK file:
./agent_upgrade -a 002 -d -f /root/upgrade_openscap_debian.pwk -x install.sh

!
When the agent finishes updating, it is automatically restarted to apply the new confifuration.

---------		cluster_control
	allow to manage the cluster from any manager.
	wazuh-clusterd must be running in order to use this tool.

Options:
-h, --help	Display the help message.
-i, --health [more] [-fs]	Display the cluster’s healthcheck.
-l, --list-nodes [-fn]	Display connected nodes in the cluster.
-d, --debug	Show debug messages.
-a, --list-agents [-fs] [-fn]	Display agents in the cluster.
-fn, --filter-node [NODE_NAME]	Display information of specified node(s) only
-fs, --filter-agent-status [STATUS]	Display agents with the specified status(es) only


Examples of use
---	Get cluster healthcheck
-summarized version
./bin/cluste_control -i

-extended version
bin/cluster_control -i more

-Getting healthcheck of multiple modes
bin/cluster_control -i more -fn node02 node01

---	Get connected nodes 
-Get all connected nodes 
bin/cluster_control -l

-Filter connected nodes by name

---		Get agents in cluster
-Get all agents 
bin/cluster_control -a

-Get all agents reporting to a node
bin/cluster_control -a -fn node02

-Get all active disconnected reporting to a node
bin/cluster_control -a -fn node02 -fs Disconnected 

--------------			fim_migrate 
	allow to migrate FIM db older than W v3.7.0 to the new format included in Wazuh--DB. This tool
	must be executed after the upgrading process has been completed .

---	Usage.
This tool is not included in the Wazuh installation, but you can download it from the Wazuh repository on GitHub:
 curl -so fim_migrate https://raw.githubusercontent.com/wazuh/wazuh/3.7/tools/migration/fim_migrate.py

./fim_migrate
!
After completing the migration process, the old FIM db won't be removed automatically.
remove the /var/ossec/queue/syscheck folder, manualy

Options:
-h	Display the help message.
-p <path>	Change the default installation path (/var/ossec).
-f	Force insertion. By default, the tool checks if the file or registry is already added and skips the insertion. Using this option, the tool adds and overwrites the entry.
-q	Quiet mode.
-d	Debug mode.

Example of use:
./fim_migrate

-----------			Unattended Installation
	saves time deplying agents , allowing the user to predefine several installation variables instead of waiting for them to be prompted. This can be made modifying the preloaded-vars.conf file and incommenting the configuration lines that you want to automate during the installation process.

---	Global
USER_LANGUAGE	Defines the language to be used.
Allowed values	“en”, “br”, “cn”, “de”, “el”, “en”, “es”, “fr”, “hu”, “it”, “jp”, “nl”, “pl”, “ru”, “sr”, “tr”
USER_NO_STOP	If it is set to anything, the confirmation messages are not going to be asked for.
USER_INSTALL_TYPE	Defines the role for the Wazuh instance that is being installed.
Allowed values	“local”, “agent”, “server”
USER_DIR	Defines the location to install Wazuh.
Allowed values	Any path
USER_DELETE_DIR	If it is set to “y”, the directory to install Wazuh will be removed if exists.
Allowed values	“y”, “n”
USER_ENABLE_ACTIVE_RESPONSE	If it is set to “n”, active response will be disabled.
Allowed values	“y”, “n”
USER_ENABLE_SYSCHECK	If it is set to “n”, syscheck will be disabled.
Allowed values	“y”, “n”
USER_ENABLE_ROOTCHECK	If it is set to “n”, rootcheck will be disabled.
Allowed values	“y”, “n”
USER_ENABLE_OPENSCAP	If it is set to “n”, OpenSCAP will be disabled.
Allowed values	“y”, “n”
USER_ENABLE_AUTHD	If it is set to “y”, Authd will be enabled.
Allowed values	“y”, “n”
USER_GENERATE_AUTHD_CERT	If it is set to “y”, the Authd certificate will be auto generated.
Allowed values	“y”, “n”
USER_UPDATE	If it is set to anything, the update installation will be done.
USER_BINARYINSTALL	If it is set to anything, the installation is not going to compile th

---	Agent
USER_AGENT_SERVER_IP	Specifies the IP address of the Wazuh server.
USER_AGENT_SERVER_NAME	Specifies the hostname of the Wazuh server.
USER_AGENT_CONFIG_PROFILE	Specifies the agent’s config profile name. This is used to create a configuration profiles for this particular profile name.

Example:
USER_LANGUAGE="en"
USER_NO_STOP="Y"
USER_INSTALL_TYPE="agent"
USER_DIR="/var/ossec"
USER_ENABLE_SYSCHECK="y"
USER_ENABLE_ROOTCHECK="y"
USER_ENABLE_OPENSCAP="y"
USER_ENABLE_ACTIVE_RESPONSE="y"

---		Manager/local
USER_ENABLE_EMAIL	Enables or disables alerts by e-mail.
Allowed values	“y”, “n”
USER_AUTO_START	Enables or disables the auto-start of Wazuh.
USER_EMAIL_ADDRESS	Defines the destination e-mail for the alerts.
Allowed values	A valid e-mail address.
USER_EMAIL_SMTP	Defines the SMTP server to send the e-mails.
Allowed values	A valid SMTP server.
USER_ENABLE_SYSLOG	Enables or disables remote syslog.
Allowed values	“y”, “n”
USER_WHITE_LIST	List of IPs or networks that are going to be set to never be blocked.
USER_CA_STORE	Assign the path to a X509 certificate or to a folder containing certificates to verify incoming WPK packages for remote upgrades.

Example:
USER_LANGUAGE="en"
USER_NO_STOP="y"
USER_INSTALL_TYPE="server"
USER_DIR="/var/ossec"
USER_ENABLE_EMAIL="n"
USER_ENABLE_SYSCHECK="y"
USER_ENABLE_ROOTCHECK="y"
USER_ENABLE_OPENSCAP="y"
USER_WHITE_LIST="n"
USER_ENABLE_SYSLOG="y"

---		API
Parameters for install_api.sh:
REINSTALL	Reinstall Wazuh.
Allowed values	“y”, “n”
REMOVE	Remove current installation.
Allowed values	“y”, “n”
DIRECTORY	Installation directory.
Allowed values	Any path

Parameters for configure_api.sh
PORT	The port used to connect to the Wazuh API.
Allowed values	Any valid port.
HTTPS	Enable HTTPS.
Allowed values	“y”, “n”
AUTHD	Enable Authd authentication.
Allowed values	“y”, “n”
PROXY	Change proxy.
Allowed values	“y”, “n”

Parameters for certificate generation:
COUNTRY	Certificate country.
STATE	Certificate state.
LOCALITY	Certificate locality.
ORG_NAME	Organization name.
ORG_UNIT	Organization unit name.
COMMON_NAME	Common Name.
PASSWORD	Certificate password.


Parameters for basic auth:
USER	API user.
PASS	API password.


!
To automate deployments in Windows you can use the parameters of its installer.

=========			Statistics files 
	are useful to troubleshoot some problems you may encouter like not receiving enough alerts, agents not sending any events to the manager , a flooded agent's buffer, etc.
	You can also make use of these statistics to have abetter perspective of your environment and how's everything working.

Wazuh provides three statistical files, listed below
ossec-agentd state file 
ossec-remoted state file 
ossec-analysisd state file

---	ossec-agentd state file
/var/ossec/var/run/ossec-agentd.state 
info about the agent like its current status or the num of generated events, among others. 
By default this file is updated every 5 sec but this interval can be change with the agent.state_interval
variable in the internal_options.conf file.

!
The ossec-agentd.state statistical file is only available in agents.

status='connected'
last_keepalive='2018-08-21 12:11:21'
last_ack='date'
msg_count='5614'
msg_sent='5801'



---			ossec-remoted state file
/var/osec/var/run/ossec-remoted.state

provides info aboutthe ossec-remoted daemon like the queue size , discarded messages or the number of TCP sessions among others.(5sec)
remoted.state_interval variable in the internal_options.conf file.

!
Available in managers.
queue_size='0'
total_queue_size='131072'
tcp_sessions='0'
evt_count='7383'
ctrl_msg_count='270'
discarded_count='0'
msg_sent='1267'

---			ossec-analysisd state file 
/var/ossec/var/run/ossec-analysisd.state
help to analyse situations where you need to troubleshoot problems related to getting less events or alerts as expected.

internal_options.conf file:
analysisd.state_interval 

total_events_decoded='5'

# Syscheck events decoded
syscheck_events_decoded='0'
syscheck_edps='0'

# Syscollector events decoded
syscollector_events_decoded='0'
syscollector_edps='0'

# Rootcheck events decoded
rootcheck_events_decoded='0'
rootcheck_edps='0'

# Hostinfo events decoded
hostinfo_events_decoded='0'
hostinfo_edps='0'

# Other events decoded
other_events_decoded='5'
other_events_edps='1'

# Events processed (Rule matching)
events_processed='5'
events_edps='1'

# Events received
events_received='5'

# Events dropped
events_dropped='0'

# Alerts written to disk
alerts_written='0'

# Firewall alerts written to disk
firewall_written='0'

# FTS alerts written to disk
fts_written='0'

# Syscheck queue
syscheck_queue_usage='0.00'

# Syscheck queue size
syscheck_queue_size='16384'

# Syscollector queue
syscollector_queue_usage='0.00'

# Syscollector queue size
syscollector_queue_size='16384'

# Rootcheck queue
rootcheck_queue_usage='0.00'

# Rootcheck queue size
rootcheck_queue_size='16384'

# Hostinfo queue
hostinfo_queue_usage='0.00'

# Hostinfo queue size
hostinfo_queue_size='16384'

# Event queue
event_queue_usage='0.00'

# Event queue size
event_queue_size='16384'

# Rule matching queue
rule_matching_queue_usage='0.00'

# Rule matching queue size
rule_matching_queue_size='16384'

# Alerts log queue
alerts_queue_usage='0.00'

# Alerts log queue size
alerts_queue_size='16384'

# Firewall log queue
firewall_queue_usage='0.00'

# Firewall log queue size
firewall_queue_size='16384'

# Statistical log queue
statistical_queue_usage='0.00'

# Statistical log queue size
statistical_queue_size='16384'

# Archives log queue
archives_queue_usage='0.00'

# Archives log queue size
archives_queue_size='16384'









=============== Monitoring security policies
Wazuh uses three components to perform this task: Rootcheck, OpenSCAP and CIS-CAT.

Alerts related to policy monitoring:

512: Windows Audit
514: Windows Application
516: Unix Audit

================OpenSCAP
Overwriting the timeout

It is possible to overwrite the timeout for a specific evaluation:

<wodle name="open-scap">

    <timeout>1800</timeout>

    <content type="xccdf" path="ssg-centos-7-ds.xml">
        <timeout>120</timeout>
    </content>

    <content type="xccdf" path="ssg-centos-6-ds.xml"/>

</wodle>
Using profiles

We can limit the evaluation to only specific profiles of a policy:

<wodle name="open-scap">

    <content type="xccdf" path="ssg-centos-7-ds.xml">
        <profile>xccdf_org.ssgproject.content_profile_standard</profile>
        <profile>xccdf_org.ssgproject.content_profile_pci-dss</profile>
    </content>

    <content type="xccdf" path="ssg-centos-6-ds.xml"/>

</wodle>

-----Using CPE dictionary

You can also optionally specify the CPE dictionary file, which is used to determine which checks are relevant to specific platforms.

<wodle name="open-scap">

    <content type="xccdf" path=policy="ssg-centos-7-ds.xml">
        <cpe>file.xml</cpe>
    </content>

    <content type="xccdf" path="ssg-centos-6-ds.xml" />

</wodle>
































































